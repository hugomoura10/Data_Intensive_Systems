{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation import *\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,concat_ws, collect_list, lit,split, size, avg, udf\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy import average\n",
    "import numpy as np \n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import resource\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "#import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "################################################# Question 1 ###################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "def shingle(text, k=7):\n",
    "    shingle_set = []\n",
    "    for i in range(len(text)-k +1):\n",
    "        shingle_set.append(text[i:i+k])\n",
    "    return list(set(shingle_set))\n",
    "\n",
    "def jaccard_similarity(list1, list2):   \n",
    "    return len(set(list1).intersection(set(list2))) / len(set(list1).union(set(list2)))\n",
    "\n",
    "def minhash_lsh(df, k_shingle, threshold):\n",
    "\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=128)\n",
    "    minhashes = {}\n",
    "\n",
    "    for features in df.collect():\n",
    "        shingles = shingle(features[\"features\"], k_shingle)\n",
    "        m = MinHash(num_perm=128)\n",
    "        for shingle_item in shingles:\n",
    "            m.update(shingle_item.encode(\"utf8\"))\n",
    "        minhashes[int(features[\"user_id\"])] = m\n",
    "        lsh.insert(int(features[\"user_id\"]), m)\n",
    "\n",
    "    replacement_candidates = {}\n",
    "    for key in lsh.keys: \n",
    "        replacement_candidates[key] = lsh.query(minhashes[key]) \n",
    "\n",
    "    #Key: New representative, value: Similar items\n",
    "    return replacement_candidates,minhashes\n",
    "\n",
    "#Iteratively bucket unique processes together\n",
    "def bucketing(replacement_candidates):\n",
    "    visited_processes = set()\n",
    "    new_process_dictionary = {}\n",
    "    for key, values in replacement_candidates.items():\n",
    "        new_values = []\n",
    "        for value in values:\n",
    "            if value not in visited_processes:\n",
    "                visited_processes.add(value)\n",
    "                new_values.append(value)\n",
    "        if new_values:  # Only add non-empty lists\n",
    "            new_process_dictionary[key] = sorted(new_values)\n",
    "    return new_process_dictionary\n",
    "\n",
    "def get_memory_usage(): \n",
    "    return resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024\n",
    "\n",
    "def get_cpu_usage(): \n",
    "    return psutil.cpu_percent(interval=None)\n",
    "\n",
    "def get_performance(func1,func2, vals):\n",
    "    #k_values = [2, 3, 4, 5, 6, 7, 8]\n",
    "    results = []\n",
    "\n",
    "    for k in vals:\n",
    "        start_time = time.time()\n",
    "        start_mem = get_memory_usage()\n",
    "        start_cpu = get_cpu_usage()\n",
    "\n",
    "        replacement_candidates, minhashes = func1(df_grouped, k, 0.98)\n",
    "        new_process_dictionary = func2(replacement_candidates)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        end_mem = get_memory_usage()\n",
    "        end_cpu = get_cpu_usage()\n",
    "\n",
    "        duration = end_time - start_time\n",
    "        mem_used = end_mem - start_mem\n",
    "\n",
    "        results.append({\n",
    "            'k': k,\n",
    "            'time_seconds': duration,\n",
    "            'memory_mb': mem_used,\n",
    "            'unique_processes': len(new_process_dictionary),\n",
    "            'cpu': end_cpu\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def plot_results(results):\n",
    "    k_values = [result['k'] for result in results]\n",
    "    time_seconds = [result['time_seconds'] for result in results]\n",
    "    cpu_percentages = [result['cpu'] for result in results]\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax1.set_xlabel('k values')\n",
    "    ax1.set_ylabel('Time (seconds)', color='tab:blue')\n",
    "    ax1.plot(k_values, time_seconds, marker='o', color='tab:blue', label='Time')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('CPU Usage (%)', color='tab:red')\n",
    "\n",
    "    ax2.plot(k_values, cpu_percentages, marker='^', color='tab:red', linestyle='--', label='CPU Usage')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "    plt.title('Performance Metrics for Different k Values')\n",
    "    fig.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_performances(results):\n",
    "    k_values = [result['k'] for result in results]\n",
    "    time_seconds = [result['time_seconds'] for result in results]\n",
    "    cpu_percentages = [result['cpu'] for result in results]\n",
    "\n",
    "    # Calculate the performance metric (Product of time_seconds and cpu)\n",
    "    performance_metric = [time_seconds[i] * cpu_percentages[i] for i in range(len(results))]\n",
    "\n",
    "    # Create a figure and axis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the performance metric\n",
    "    plt.plot(k_values, performance_metric, marker='o', linestyle='-', color='purple', label='Time * CPU')\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel('k values')\n",
    "    plt.ylabel('Performance Metric (Time * CPU)')\n",
    "    plt.title('Combined Metric of Time and CPU Usage vs. k Values')\n",
    "    plt.xticks(k_values)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_case(caseID,data=):\n",
    "    data1 = data.filter(data.user_id.isin([caseID]))\n",
    "    data1.show()\n",
    "\n",
    "   def compare_cases(case1,case2,data):\n",
    "    data1 = data.filter(data.user_id.isin([case1]))\n",
    "    data2 = data.filter(data.user_id.isin([case2]))\n",
    "    desired_column_list1 = data1.select(\"to\").rdd.flatMap(lambda x: x).collect()\n",
    "    desired_column_list2 = data2.select(\"to\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    common_elements = np.intersect1d(desired_column_list1, desired_column_list2)\n",
    "    union_elements = np.union1d(desired_column_list1, desired_column_list2)\n",
    "    print(len(common_elements)/len(union_elements))\n",
    "\n",
    "def get_traces(user_id,df =df_grouped):\n",
    "    result = df.filter(col(\"user_id\") == user_id).select(\"features\").collect()\n",
    "    if result:\n",
    "        return result[0][\"features\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_shingles(user_id,df = df_shingles):\n",
    "    result = df.filter(col(\"user_id\") == user_id).select(\"shingles\").collect()\n",
    "    if result:\n",
    "        return result[0][\"shingles\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def write_df(df,file_name):\n",
    "    os.makedirs('Output', exist_ok=True)\n",
    "    os.makedirs('temp', exist_ok=True)\n",
    "    df.write.csv('temp/temp_outoput', header=True, mode=\"overwrite\")\n",
    "    part_file = [f for f in os.listdir('temp/temp_outoput') if f.startswith(\"part-\")][0]\n",
    "\n",
    "    shutil.move(os.path.join('temp/temp_outoput', part_file), file_name)\n",
    "    shutil.rmtree('temp/temp_outoput')\n",
    "    shutil.rmtree('temp')\n",
    "\n",
    "def output_part1(dataset,k,threshold):\n",
    "    data = spark.read.csv(dataset, header=True, inferSchema=True)\n",
    "    df = data.withColumn(\"arrayColumn\", concat_ws(\"\",\"from\", \"to\")).withColumn(\"Minhash\", lit(\"\"))\n",
    "    df_grouped = df.groupBy(\"user_id\").agg(\n",
    "                                            concat_ws(\"\",collect_list(\"arrayColumn\")).alias(\"features\"))\n",
    "    \n",
    "    replacement_candidates = minhash_lsh(df_grouped,k,threshold)\n",
    "    new_process_dictionary = bucketing(replacement_candidates)    \n",
    "\n",
    "    user_ids = list(new_process_dictionary.keys())\n",
    "    max_user_id = max(user_ids)\n",
    "    output_df = data.filter(df.user_id.isin(user_ids))\n",
    "    final_df = output_df.coalesce(1)\n",
    "    return write_df(final_df,'Output/part1Output.csv')\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "################################################# Question 2 ###################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "def kmeans_clustering(df, n_clusters, max_iter):\n",
    "    minhashes = []\n",
    "    #for jaccard verification\n",
    "    minhash_dict = {}\n",
    "    user_ids = []\n",
    "    final_buckets = {}\n",
    "    for features in df.collect():\n",
    "        shingles = shingle(features[\"features\"], 5)\n",
    "        m = MinHash(num_perm=128)\n",
    "        for shingle_item in shingles:\n",
    "            m.update(shingle_item.encode(\"utf8\"))\n",
    "        minhashes.append(m.hashvalues)\n",
    "        minhash_dict[int(features[\"user_id\"])] = m\n",
    "        user_ids.append(int(features[\"user_id\"]))\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, max_iter=max_iter).fit(minhashes)\n",
    "\n",
    "    user_clusters = dict(zip(user_ids, kmeans.labels_))\n",
    "    final_buckets = {}\n",
    "    for key, value in user_clusters.items():\n",
    "        if value in final_buckets:\n",
    "            final_buckets[value].append(key)\n",
    "        else:\n",
    "            final_buckets[value] = [key]\n",
    "\n",
    "    return final_buckets, minhash_dict\n",
    "\n",
    "def get_averege_jaccard_sim(final_buckets, minhashes,get = True):\n",
    "    sims = {}\n",
    "    for key, value in final_buckets.items():\n",
    "        for user_id_1 in final_buckets[key]:\n",
    "            for user_id_2 in final_buckets[key]:\n",
    "                if user_id_1 != user_id_2:\n",
    "                    sig_1 = minhashes[int(user_id_1)]\n",
    "                    sig_2 = minhashes[int(user_id_2)]\n",
    "                    sim = MinHash.jaccard(sig_1, sig_2)\n",
    "                    if key not in sims:\n",
    "                        sims[key] = [sim]\n",
    "                    else:\n",
    "                        sims[key].append(sim)\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "    sims = dict(sorted(sims.items()))\n",
    "    if get == True:\n",
    "        for key, value in sims.items():\n",
    "            avg_sim = average(value)\n",
    "            print(key, avg_sim)\n",
    "            total_sum += sum(value)\n",
    "            total_count += len(value)\n",
    "        \n",
    "        overall_average = total_sum / total_count if total_count != 0 else 0\n",
    "        print(\"Overall Average Jaccard Similarity:\", overall_average)\n",
    "\n",
    "    return sims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "data = spark.read.csv(\"data/SDG_dataset2.csv\", header=True, inferSchema=True)\n",
    "df_filtered_m = data.filter(data.type.isin(['Req']))\n",
    "df_grouped = df_filtered_m.groupBy(\"user_id\").agg(concat_ws(\"\",collect_list(\"to\")).alias(\"features\"))\n",
    "#data.show()\n",
    "#df_filtered_m.show()\n",
    "#df_grouped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramter-tuning for k-shingles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we're going to see which k is the best for the k-shingles. We gonna do such a thing by investigating how computational expensive it is to compute such minhash for different values of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_performance(minhash_lsh,bucketing, [3,4,5,6,7,8,9])\n",
    "plot_results(results)\n",
    "plot_performances(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running this a considerable amount of times we saw that the value that get a better balance between time and CPU usage is when k=7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter-tuning for the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|            shingles|\n",
      "+-------+--------------------+\n",
      "|      1|[_3S5S5_, 1S4S4_3...|\n",
      "|     12|[2S2_4S2, S1_1S2S...|\n",
      "|     22|[_3S2_5S, S1_1S2S...|\n",
      "|     26|[S5S5_2S, S5_2S5_...|\n",
      "|     27|[S2_2S1S, S5_1S5_...|\n",
      "|     28|[S5S5_2S, S4S4_4S...|\n",
      "|     31|[1_2S2S2, S0S4S4_...|\n",
      "|     34|[_2S5S5_, S5S5_2S...|\n",
      "|     44|[_3S5S5_, S5_1S5_...|\n",
      "|     47|[S5S5_2S, _2S3S3_...|\n",
      "|     52|[S5S5_2S, _3S2_2S...|\n",
      "|     53|[S5_1S5_, 5_1S5_1...|\n",
      "|     65|[S3S3_1S, _1S3_2S...|\n",
      "|     76|[_3S5S5_, S5S5_2S...|\n",
      "|     78|[_3S5S5_, S5_1S5_...|\n",
      "|     81|[_3S5S5_, S5_1S5_...|\n",
      "|     85|[_3S5S5_, S5S5_2S...|\n",
      "|     91|[_3S5S5_, 2S2_4S2...|\n",
      "|     93|[2S2_4S2, S1_1S2S...|\n",
      "|    101|[S5S5_2S, _5S5S5_...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.36436335225314"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shingles_udf = udf(shingle, ArrayType(StringType()))\n",
    "\n",
    "df_shingles = df_filtered_m.groupBy(\"user_id\").agg(concat_ws(\"\", collect_list(\"to\")).alias(\"trace\")) \\\n",
    "    .withColumn(\"shingles\", shingles_udf(col(\"trace\"))) \\\n",
    "    .select(\"user_id\", \"shingles\")\n",
    "#df_shingles.show()\n",
    "average_num_shingles = df_shingles.withColumn(\"list_length\", size(col(\"shingles\"))) \\\n",
    "                     .agg(avg(\"list_length\").alias(\"average_list_length\")).collect()[0][0]\n",
    "average_num_shingles\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the average number of 7-shingles is 32, and we want to group processes with only small variations, we want that 31/32 shingles to be the same, so that we still allow for some small variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of cases: 43517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique processes after merging them with 0.97 threshold using 7-shingles: 29729\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial number of cases: {df_grouped.count()}\")\n",
    "ans = minhash_lsh(df_grouped,7,0.97)\n",
    "replacement_candidates7, minhash_dic = ans[0],ans[1]\n",
    "new_process_dictionary7= bucketing(replacement_candidates7)\n",
    "print(f\"Number of unique processes after merging them with 0.97 threshold using 7-shingles: {len(new_process_dictionary7)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After merging the processes with a threshold of 97%, using 7-shingles, we obtain 29729 candidate unique cases. In order to investigate if further analysis into the similarities needs to be done, to make sure that the false positives do not result in cases where the cases are not small variations of each other, we are going to compute the average similarities of all buckets and investigate the mininum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = get_averege_jaccard_sim(replacement_candidates7, minhash_dic,get=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to mention that we're still just computing the approximate jaccard similarities provided by MinHashLSH, so, in order to investigate the cases that have the smallest approximate jaccard similarities, we're going to compute the actual similarities between those cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = min(set(value for key,values in sims.items() for value in values if value != 1.0))\n",
    "final_values = []\n",
    "for key,values in sims.items():\n",
    "    for value in values:\n",
    "        if value == ans:\n",
    "            final_values.append(key)\n",
    "\n",
    "dissimilar = set(final_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sims = []\n",
    "for key in dissimilar:\n",
    "    for value in replacement_candidates7[key]:\n",
    "        new_sims.append((key,value,jaccard_similarity(get_shingles(value),get_shingles(key))))\n",
    "investigate = [case for case in new_sims if case[-1]!=1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_2\n",
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_4\n",
      "#####################################################################\n",
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_2\n",
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_4\n",
      "#####################################################################\n",
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_4\n",
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_2\n",
      "#####################################################################\n",
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_4\n",
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_2\n",
      "#####################################################################\n",
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_4\n",
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_2\n",
      "#####################################################################\n",
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_2\n",
      "S0S4S4_1S3S3_1S3_2S3_3S2S2_4\n",
      "#####################################################################\n"
     ]
    }
   ],
   "source": [
    "for case in investigate:\n",
    "    print(get_traces(case[0]))\n",
    "    print(get_traces(case[1]))\n",
    "    print('#####################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_part1(\"data/SDG_dataset2.csv\",3,0.95)\n",
    "# output_part1(\"data/SDG_dataset2.csv\",5,0.95)\n",
    "output_part1(\"data/SDG_dataset2.csv\",7,0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning for Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "minhashes = []\n",
    "user_ids = []\n",
    "final_buckets = {}\n",
    "for features in df_grouped.collect():\n",
    "    shingles = shingle(features[\"features\"], 5)\n",
    "    m = MinHash(num_perm=128)\n",
    "    for shingle_item in shingles:\n",
    "        m.update(shingle_item.encode(\"utf8\"))\n",
    "    minhashes.append(m.hashvalues)\n",
    "    user_ids.append(int(features[\"user_id\"]))\n",
    "\n",
    "param_grid = {\n",
    "    'n_clusters': [100, 250, 500],\n",
    "    'max_iter': [100, 500, 1000],\n",
    "}\n",
    "\n",
    "kmeans = KMeans()\n",
    "\n",
    "grid_search = GridSearchCV(kmeans, param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(minhashes)\n",
    "\n",
    "best_param = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"The best parameters are: \" , best_param )\n",
    "print(\"The best model is: \", best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Find and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_candidates = minhash_lsh(df_grouped,5,0.7)\n",
    "new_process_dictionary = bucketing(replacement_candidates)\n",
    "print(len(replacement_candidates))\n",
    "print(len(new_process_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Find/cluster similar items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "users = []\n",
    "for key in new_process_dictionary:\n",
    "    users.append(key)\n",
    "\n",
    "filtered_df = df_grouped[df_grouped['user_id'].isin(users)]\n",
    "\n",
    "final_buckets, minhashes = kmeans_clustering(filtered_df,500,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_averege_jaccard_sim(final_buckets, minhashes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Initial number of cases: {df_grouped.count()}\")\n",
    "# replacement_candidates3 = minhash_lsh(df_grouped,3,0.98)\n",
    "# new_process_dictionary3 = bucketing(replacement_candidates3)\n",
    "#print(f\"After merging cases with threshold 3-shingles: {len(new_process_dictionary3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_split = df_grouped.withColumn(\"feature_length\", size(split(col(\"features\"), \"S\")))\n",
    "# average_length = df_split.agg(avg(\"feature_length\")).collect()[0][0]\n",
    "\n",
    "# windowSpec = Window.partitionBy(F.lit(1)).orderBy(\"feature_length\")\n",
    "# df_split = df_split.withColumn(\"row_number\", F.row_number().over(windowSpec))\n",
    "# total_count = df_split.count()\n",
    "\n",
    "# if total_count % 2 == 0:\n",
    "#     median_index1 = total_count // 2\n",
    "#     median_index2 = median_index1 + 1\n",
    "#     median_value = df_split.filter(col(\"row_number\").isin([median_index1, median_index2])) \\\n",
    "#                                   .agg(avg(\"feature_length\")).collect()[0][0]\n",
    "# else:\n",
    "#     median_index = (total_count // 2) + 1\n",
    "#     median_value = df_split.filter(col(\"row_number\") == median_index) \\\n",
    "#                                   .select(\"feature_length\").collect()[0][0]\n",
    "    \n",
    "# print(f\"Average number of requests: {average_length}\")\n",
    "# print(f\"Median number of requests: {median_value}\")\n",
    "\n",
    "\n",
    "#Given that both the average and the median are close to 13, which shows that the dataset is symetricly distributed when it comes to how many \n",
    "#requests are performed, we gonna assume that two cases have a small variation iif the number of different requests is around 1. To get an \n",
    "# #approximation of the threshold, we're going to use the resutls shown before, so we assume that 12/13 are the same. Given this, we decided \n",
    "# to use a threshold of 95%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
