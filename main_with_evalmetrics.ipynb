{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,concat_ws, collect_list, lit,split, size, avg\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy import average\n",
    "import numpy as np \n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "################################################# Question 1 ###################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "def shingle(text, k):\n",
    "    shingle_set = []\n",
    "    for i in range(len(text)-k +1):\n",
    "        shingle_set.append(text[i:i+k])\n",
    "    return set(shingle_set)\n",
    "\n",
    "def minhash_lsh(df, k_shingle, threshold):\n",
    "\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=128)\n",
    "    minhashes = {}\n",
    "\n",
    "    for features in df.collect():\n",
    "        shingles = shingle(features[\"features\"], k_shingle)\n",
    "        m = MinHash(num_perm=128)\n",
    "        for shingle_item in shingles:\n",
    "            m.update(shingle_item.encode(\"utf8\"))\n",
    "        minhashes[int(features[\"user_id\"])] = m\n",
    "        lsh.insert(int(features[\"user_id\"]), m)\n",
    "\n",
    "    replacement_candidates = {}\n",
    "    for key in lsh.keys: \n",
    "        replacement_candidates[key] = lsh.query(minhashes[key]) \n",
    "\n",
    "    #Key: New representative, value: Similar items\n",
    "    return replacement_candidates, minhashes\n",
    "\n",
    "#Iteratively bucket unique processes together\n",
    "def bucketing(replacement_candidates):\n",
    "    visited_processes = set()\n",
    "    new_process_dictionary = {}\n",
    "    for key, values in replacement_candidates.items():\n",
    "        new_values = []\n",
    "        for value in values:\n",
    "            if value not in visited_processes:\n",
    "                visited_processes.add(value)\n",
    "                new_values.append(value)\n",
    "        if new_values:  # Only add non-empty lists\n",
    "            new_process_dictionary[key] = sorted(new_values)\n",
    "    return new_process_dictionary\n",
    "\n",
    "def show_case(caseID,data):\n",
    "    data1 = data.filter(data.user_id.isin([caseID]))\n",
    "    data1.show()\n",
    "\n",
    "def get_servers(caseID, data):\n",
    "    data1 = data.filter(data.user_id.isin([caseID]))\n",
    "    user_id_list = data1.select(\"to\").rdd.flatMap(lambda x: x).collect()\n",
    "    print(user_id_list)\n",
    "    \n",
    "def compare_cases(case1,case2,data):\n",
    "    data1 = data.filter(data.user_id.isin([case1]))\n",
    "    data2 = data.filter(data.user_id.isin([case2]))\n",
    "    desired_column_list1 = data1.select(\"to\").rdd.flatMap(lambda x: x).collect()\n",
    "    #desired_column_list1\n",
    "    desired_column_list2 = data2.select(\"to\").rdd.flatMap(lambda x: x).collect()\n",
    "    #desired_column_list2\n",
    "    common_elements = np.intersect1d(desired_column_list1, desired_column_list2)\n",
    "    union_elements = np.union1d(desired_column_list1, desired_column_list2)\n",
    "    print(len(common_elements)/len(union_elements))\n",
    "\n",
    "\n",
    "def write_df(df,file_name):\n",
    "    os.makedirs('Output', exist_ok=True)\n",
    "    #temporary folder to save all the temporaty files created by write.csv\n",
    "    os.makedirs('temp', exist_ok=True)\n",
    "    df.write.csv('temp/temp_outoput', header=True, mode=\"overwrite\")\n",
    "    part_file = [f for f in os.listdir('temp/temp_outoput') if f.startswith(\"part-\")][0]\n",
    "\n",
    "    shutil.move(os.path.join('temp/temp_outoput', part_file), file_name)\n",
    "    shutil.rmtree('temp/temp_outoput')\n",
    "    shutil.rmtree('temp')\n",
    "\n",
    "def output_part1(dataset,k,threshold):\n",
    "    data = spark.read.csv(dataset, header=True, inferSchema=True)\n",
    "    df = data.withColumn(\"arrayColumn\", concat_ws(\"\",\"from\", \"to\")).withColumn(\"Minhash\", lit(\"\"))\n",
    "    df_grouped = df.groupBy(\"user_id\").agg(\n",
    "                                            concat_ws(\"\",collect_list(\"arrayColumn\")).alias(\"features\"))\n",
    "    \n",
    "    replacement_candidates = minhash_lsh(df_grouped,k,threshold)\n",
    "    new_process_dictionary = bucketing(replacement_candidates)    \n",
    "\n",
    "    user_ids = list(new_process_dictionary.keys())\n",
    "    output_df = data.filter(df.user_id.isin(user_ids))\n",
    "    final_df = output_df.coalesce(1)\n",
    "    return write_df(final_df,'Output/part1Output.csv')\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "################################################# Question 2 ###################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "def kmeans_clustering(df, n_clusters, max_iter):\n",
    "    minhashes = []\n",
    "    #for jaccard verification\n",
    "    minhash_dict = {}\n",
    "    user_ids = []\n",
    "    final_buckets = {}\n",
    "    for features in df.collect():\n",
    "        shingles = shingle(features[\"features\"], 5)\n",
    "        m = MinHash(num_perm=128)\n",
    "        for shingle_item in shingles:\n",
    "            m.update(shingle_item.encode(\"utf8\"))\n",
    "        minhashes.append(m.hashvalues)\n",
    "        minhash_dict[int(features[\"user_id\"])] = m\n",
    "        user_ids.append(int(features[\"user_id\"]))\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, max_iter=max_iter).fit(minhashes)\n",
    "\n",
    "    user_clusters = dict(zip(user_ids, kmeans.labels_))\n",
    "    final_buckets = {}\n",
    "    for key, value in user_clusters.items():\n",
    "        if value in final_buckets:\n",
    "            final_buckets[value].append(key)\n",
    "        else:\n",
    "            final_buckets[value] = [key]\n",
    "\n",
    "    return final_buckets, minhash_dict\n",
    "\n",
    "\n",
    "#Get averege jaccard value per bucket\n",
    "\n",
    "def get_averege_jaccard_sim(final_buckets, minhashes,get = True):\n",
    "    sims = {}\n",
    "    for key, value in final_buckets.items():\n",
    "        for user_id_1 in final_buckets[key]:\n",
    "            for user_id_2 in final_buckets[key]:\n",
    "                if user_id_1 != user_id_2:\n",
    "                    sig_1 = minhashes[int(user_id_1)]\n",
    "                    sig_2 = minhashes[int(user_id_2)]\n",
    "                    sim = MinHash.jaccard(sig_1, sig_2)\n",
    "                    if key not in sims:\n",
    "                        sims[key] = [sim]\n",
    "                    else:\n",
    "                        sims[key].append(sim)\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "    sims = dict(sorted(sims.items()))\n",
    "    if get == True:\n",
    "        for key, value in sims.items():\n",
    "            avg_sim = average(value)\n",
    "            print(key, avg_sim)\n",
    "            total_sum += sum(value)\n",
    "            total_count += len(value)\n",
    "        \n",
    "        overall_average = total_sum / total_count if total_count != 0 else 0\n",
    "        print(\"Overall Average Jaccard Similarity:\", overall_average)\n",
    "    else:\n",
    "        return sims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"spark_session_1\").getOrCreate()\n",
    "data = spark.read.csv(\"data/SDG_dataset2.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df_filtered_m = data.filter(data.type.isin(['Req']))\n",
    "df_grouped = df_filtered_m.groupBy(\"user_id\").agg(concat_ws(\"\",collect_list(\"to\")).alias(\"features\"))\n",
    "#data.show()\n",
    "#df_filtered_m.show()\n",
    "#df_grouped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter-tuning for k-shingles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we're going to see which k is the best for the k-shingles. We gonna do such a thing by investigating how computational expensive it is to compute such minhash for different values of k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of cases: 41833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging cases with threshold 3-shingles: 31954\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial number of cases: {df_grouped.count()}\")\n",
    "replacement_candidates3 = minhash_lsh(df_grouped,3,0.98)\n",
    "new_process_dictionary3 = bucketing(replacement_candidates3)\n",
    "print(f\"After merging cases with threshold 3-shingles: {len(new_process_dictionary3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Initial number of cases: {df_grouped.count()}\")\n",
    "# replacement_candidates5 = minhash_lsh(df_grouped,5,0.98)\n",
    "# new_process_dictionary5 = bucketing(replacement_candidates5)\n",
    "# print(f\"After merging cases with threshold 5-shingles: {len(new_process_dictionary5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Initial number of cases: {df_grouped.count()}\")\n",
    "# replacement_candidates5 = minhash_lsh(df_grouped,7,0.98)\n",
    "# new_process_dictionary5 = bucketing(replacement_candidates5)\n",
    "# print(f\"After merging cases with threshold 5-shingles: {len(new_process_dictionary5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Initial number of cases: {df_grouped.count()}\")\n",
    "# replacement_candidates5 = minhash_lsh(df_grouped,9,0.98)\n",
    "# new_process_dictionary5 = bucketing(replacement_candidates5)\n",
    "# print(f\"After merging cases with threshold 5-shingles: {len(new_process_dictionary5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for k=2:\n",
      "Time: 46.36475396156311 seconds\n",
      "Memory: 0.0 MB\n",
      "CPU Percent: 22.2%\n",
      "Unique Processes: 2839\n",
      "Average Jaccard Similarity: 0.996801688826587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for k=3:\n",
      "Time: 44.927558183670044 seconds\n",
      "Memory: 9812.0 MB\n",
      "CPU Percent: 28.7%\n",
      "Unique Processes: 31954\n",
      "Average Jaccard Similarity: 0.9999502062626213\n",
      "Results for k=4:\n",
      "Time: 45.257112979888916 seconds\n",
      "Memory: 100.0 MB\n",
      "CPU Percent: 18.0%\n",
      "Unique Processes: 32205\n",
      "Average Jaccard Similarity: 0.999978414830818\n",
      "Results for k=5:\n",
      "Time: 45.34848117828369 seconds\n",
      "Memory: 0.0 MB\n",
      "CPU Percent: 17.5%\n",
      "Unique Processes: 32827\n",
      "Average Jaccard Similarity: 0.9999868140627494\n",
      "Results for k=6:\n",
      "Time: 44.7147581577301 seconds\n",
      "Memory: 0.0 MB\n",
      "CPU Percent: 17.1%\n",
      "Unique Processes: 32840\n",
      "Average Jaccard Similarity: 0.9999937171565558\n",
      "Results for k=7:\n",
      "Time: 44.9187548160553 seconds\n",
      "Memory: 0.0 MB\n",
      "CPU Percent: 17.8%\n",
      "Unique Processes: 32834\n",
      "Average Jaccard Similarity: 0.9999957553165861\n",
      "Results for k=8:\n",
      "Time: 44.33317232131958 seconds\n",
      "Memory: 0.0 MB\n",
      "CPU Percent: 18.9%\n",
      "Unique Processes: 32849\n",
      "Average Jaccard Similarity: 0.9999963154818965\n",
      "\n",
      "Summary of results:\n",
      "{'k': 2, 'time_seconds': 46.36475396156311, 'memory_mb': 0.0, 'unique_processes': 2839, 'cpu': 22.2}\n",
      "{'k': 3, 'time_seconds': 44.927558183670044, 'memory_mb': 9812.0, 'unique_processes': 31954, 'cpu': 28.7}\n",
      "{'k': 4, 'time_seconds': 45.257112979888916, 'memory_mb': 100.0, 'unique_processes': 32205, 'cpu': 18.0}\n",
      "{'k': 5, 'time_seconds': 45.34848117828369, 'memory_mb': 0.0, 'unique_processes': 32827, 'cpu': 17.5}\n",
      "{'k': 6, 'time_seconds': 44.7147581577301, 'memory_mb': 0.0, 'unique_processes': 32840, 'cpu': 17.1}\n",
      "{'k': 7, 'time_seconds': 44.9187548160553, 'memory_mb': 0.0, 'unique_processes': 32834, 'cpu': 17.8}\n",
      "{'k': 8, 'time_seconds': 44.33317232131958, 'memory_mb': 0.0, 'unique_processes': 32849, 'cpu': 18.9}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import resource\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat_ws, collect_list, lit\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import shutil\n",
    "import os\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def average_jaccard_sim(new_process_dictionary, minhashes):\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for key, values in new_process_dictionary.items():\n",
    "        for i in range(len(values)):\n",
    "            for j in range(i + 1, len(values)):\n",
    "                sig_1 = minhashes[values[i]]\n",
    "                sig_2 = minhashes[values[j]]\n",
    "                sim = sig_1.jaccard(sig_2)\n",
    "                total_sum += sim\n",
    "                total_count += 1\n",
    "\n",
    "    return total_sum / total_count if total_count != 0 else 0\n",
    "\n",
    "def get_memory_usage(): #memory\n",
    "    return resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024\n",
    "\n",
    "def get_cpu_usage(): #cpu\n",
    "    return psutil.cpu_percent(interval=None)\n",
    "\n",
    "k_values = [2, 3, 4, 5, 6, 7, 8]\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    start_time = time.time()\n",
    "    start_mem = get_memory_usage()\n",
    "    start_cpu = get_cpu_usage()\n",
    "\n",
    "    replacement_candidates, minhashes = minhash_lsh(df_grouped, k, 0.98)\n",
    "    new_process_dictionary = bucketing(replacement_candidates)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    end_mem = get_memory_usage()\n",
    "    end_cpu = get_cpu_usage()\n",
    "\n",
    "    duration = end_time - start_time\n",
    "    avg_jaccard = average_jaccard_sim(new_process_dictionary, minhashes)\n",
    "    mem_used = end_mem - start_mem\n",
    "\n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'time_seconds': duration,\n",
    "        'memory_mb': mem_used,\n",
    "        'unique_processes': len(new_process_dictionary),\n",
    "        'cpu': end_cpu\n",
    "    })\n",
    "\n",
    "    print(f\"Results for k={k}:\")\n",
    "    print(f\"Time: {duration} seconds\")\n",
    "    print(f\"Memory: {mem_used} MB\")\n",
    "    print(f\"CPU Percent: {end_cpu}%\")\n",
    "    print(f\"Unique Processes: {len(new_process_dictionary)}\")\n",
    "    print(f\"Average Jaccard Similarity: {avg_jaccard}\")\n",
    "\n",
    "print(\"\\nSummary of results:\")\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data from your results\n",
    "results = [\n",
    "    {'k': 2, 'time_seconds': 46.22001576423645, 'memory_mb': 0.0,'cpu': 25.5},\n",
    "    {'k': 3, 'time_seconds': 44.95308208465576, 'memory_mb': 0.0, 'cpu': 23.5},\n",
    "    {'k': 4, 'time_seconds': 45.75661110877991, 'memory_mb': 0.0, 'cpu': 21.6},\n",
    "    {'k': 5, 'time_seconds': 45.81163787841797, 'memory_mb': 0.0, 'cpu': 19.2},\n",
    "    {'k': 6, 'time_seconds': 45.756104946136475, 'memory_mb': 0.0, 'cpu': 21.0},\n",
    "    {'k': 7, 'time_seconds': 44.57948970794678, 'memory_mb': 0.0, 'cpu': 18.1},\n",
    "    {'k': 8, 'time_seconds': 45.117955684661865, 'memory_mb': 0.0, 'cpu': 20.3}\n",
    "]\n",
    "\n",
    "k_values = [result['k'] for result in results]\n",
    "time_seconds = [result['time_seconds'] for result in results]\n",
    "cpu_percentages = [result['cpu'] for result in results]\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.set_xlabel('k values')\n",
    "ax1.set_ylabel('Time (seconds)', color='tab:blue')\n",
    "ax1.plot(k_values, time_seconds, marker='o', color='tab:blue', label='Time')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('CPU Usage (%)', color='tab:red')\n",
    "\n",
    "ax2.plot(k_values, cpu_percentages, marker='^', color='tab:red', linestyle='--', label='CPU Usage')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "plt.title('Performance Metrics for Different k Values')\n",
    "fig.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_values = [result['k'] for result in results]\n",
    "time_seconds = [result['time_seconds'] for result in results]\n",
    "cpu_percentages = [result['cpu'] for result in results]\n",
    "\n",
    "# Calculate the performance metric (Product of time_seconds and cpu)\n",
    "performance_metric = [time_seconds[i] * cpu_percentages[i] for i in range(len(results))]\n",
    "\n",
    "# Create a figure and axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the performance metric\n",
    "plt.plot(k_values, performance_metric, marker='o', linestyle='-', color='purple', label='Time * CPU')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('k values')\n",
    "plt.ylabel('Performance Metric (Time * CPU)')\n",
    "plt.title('Combined Metric of Time and CPU Usage vs. k Values')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugo investigate graph output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import psutil\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Function to measure execution time and resource usage\n",
    "# def measure_performance(func, *args, **kwargs):\n",
    "#     start_time = time.time()\n",
    "#     process = psutil.Process()\n",
    "#     start_memory = process.memory_info().rss\n",
    "#     start_cpu = process.cpu_percent(interval=None)\n",
    "\n",
    "#     result = func(*args, **kwargs)\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     end_memory = process.memory_info().rss\n",
    "#     end_cpu = process.cpu_percent(interval=None)\n",
    "\n",
    "#     execution_time = end_time - start_time\n",
    "#     memory_usage = (end_memory - start_memory) / 1024 / 1024  # Convert to MB\n",
    "#     cpu_usage = end_cpu - start_cpu\n",
    "\n",
    "#     return execution_time, memory_usage, cpu_usage, result\n",
    "\n",
    "# # Example function to test performance\n",
    "# def example_function(n):\n",
    "#     total = 0\n",
    "#     for i in range(n):\n",
    "#         total += i ** 2\n",
    "#     return total\n",
    "\n",
    "# # Measure performance of the example function with a specific input\n",
    "# specific_input = 1000000\n",
    "# exec_time, mem_usage, cpu_usage, _ = measure_performance(example_function, specific_input)\n",
    "\n",
    "# # Plotting the results\n",
    "# labels = ['Execution Time (s)', 'Memory Usage (MB)', 'CPU Usage (%)']\n",
    "# values = [exec_time, mem_usage, cpu_usage]\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(labels, values, color=['red', 'blue', 'green'])\n",
    "\n",
    "# for i, v in enumerate(values):\n",
    "#     ax.text(i, v + 0.1, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "# plt.title(f'Computational Expense Analysis for input size {specific_input}')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to get a function that compares the execution times, CPU and memory used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter-tuning for the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:=====>                                                  (1 + 10) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of requests: 12.952429899839839\n",
      "Median number of requests: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_with_lengths = df_grouped.withColumn(\"feature_length\", size(split(col(\"features\"), \"S\")))\n",
    "average_length = df_with_lengths.agg(avg(\"feature_length\")).collect()[0][0]\n",
    "\n",
    "windowSpec = Window.partitionBy(F.lit(1)).orderBy(\"feature_length\")\n",
    "df_with_lengths = df_with_lengths.withColumn(\"row_number\", F.row_number().over(windowSpec))\n",
    "total_count = df_with_lengths.count()\n",
    "\n",
    "if total_count % 2 == 0:\n",
    "    median_index1 = total_count // 2\n",
    "    median_index2 = median_index1 + 1\n",
    "    median_value = df_with_lengths.filter(col(\"row_number\").isin([median_index1, median_index2])) \\\n",
    "                                  .agg(avg(\"feature_length\")).collect()[0][0]\n",
    "else:\n",
    "    median_index = (total_count // 2) + 1\n",
    "    median_value = df_with_lengths.filter(col(\"row_number\") == median_index) \\\n",
    "                                  .select(\"feature_length\").collect()[0][0]\n",
    "    \n",
    "print(f\"Average number of requests: {average_length}\")\n",
    "print(f\"Median number of requests: {median_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that both the average and the median are close to 13, which shows that the dataset is symetricly distributed when it comes to how many requests are performed, we gonna assume that two cases have a small variation iif the number of different requests is around 1. To get an approximation of the threshold, we're going to use the resutls shown before, so we assume that 12/13 are the same. Given this, we decided to use a threshold of 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of cases: 41833\n",
      "After merging cases with threshold 7-shingles: 32304\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial number of cases: {df_grouped.count()}\")\n",
    "ans = minhash_lsh(df_grouped,7,0.93)\n",
    "replacement_candidates7, minhash_dic = ans[0],ans[1]\n",
    "new_process_dictionary7= bucketing(replacement_candidates7)\n",
    "print(f\"After merging cases with threshold 7-shingles: {len(new_process_dictionary7)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1.0\n",
      "7 1.0\n",
      "10 1.0\n",
      "12 0.9296875\n",
      "13 1.0\n",
      "14 1.0\n",
      "19 1.0\n",
      "28 1.0\n",
      "32 0.96875\n",
      "37 1.0\n",
      "48 1.0\n",
      "52 1.0\n",
      "53 1.0\n",
      "57 1.0\n",
      "61 1.0\n",
      "66 1.0\n",
      "71 1.0\n",
      "74 0.9829545454545454\n",
      "77 1.0\n",
      "85 1.0\n",
      "95 1.0\n",
      "99 0.953125\n",
      "100 1.0\n",
      "103 1.0\n",
      "107 1.0\n",
      "110 1.0\n",
      "111 0.9583333333333334\n",
      "112 1.0\n",
      "113 1.0\n",
      "115 1.0\n",
      "116 0.9375\n",
      "117 1.0\n",
      "119 1.0\n",
      "123 1.0\n",
      "126 0.9806547619047619\n",
      "130 1.0\n",
      "131 1.0\n",
      "133 1.0\n",
      "138 1.0\n",
      "140 1.0\n",
      "141 1.0\n",
      "148 1.0\n",
      "151 1.0\n",
      "154 1.0\n",
      "155 1.0\n",
      "161 1.0\n",
      "164 1.0\n",
      "165 1.0\n",
      "170 0.9583333333333334\n",
      "174 1.0\n",
      "176 1.0\n",
      "179 1.0\n",
      "180 1.0\n",
      "183 1.0\n",
      "187 1.0\n",
      "189 0.9296875\n",
      "194 1.0\n",
      "199 0.9609375\n",
      "200 1.0\n",
      "201 1.0\n",
      "202 1.0\n",
      "204 1.0\n",
      "209 1.0\n",
      "215 1.0\n",
      "217 1.0\n",
      "218 1.0\n",
      "221 1.0\n",
      "223 1.0\n",
      "225 1.0\n",
      "232 1.0\n",
      "234 1.0\n",
      "235 1.0\n",
      "238 1.0\n",
      "240 0.9791666666666666\n",
      "244 1.0\n",
      "246 1.0\n",
      "250 1.0\n",
      "257 1.0\n",
      "265 0.9505494505494505\n",
      "267 0.9559294871794872\n",
      "272 0.962071718931475\n",
      "276 1.0\n",
      "281 1.0\n",
      "283 1.0\n",
      "284 1.0\n",
      "288 1.0\n",
      "290 1.0\n",
      "291 0.9806547619047619\n",
      "296 1.0\n",
      "300 0.9517463235294118\n",
      "301 1.0\n",
      "306 1.0\n",
      "310 1.0\n",
      "313 0.9635416666666666\n",
      "315 0.921875\n",
      "320 1.0\n",
      "322 1.0\n",
      "332 0.9739583333333334\n",
      "333 1.0\n",
      "334 1.0\n",
      "336 1.0\n",
      "340 1.0\n",
      "343 1.0\n",
      "344 1.0\n",
      "346 1.0\n",
      "347 1.0\n",
      "350 1.0\n",
      "351 1.0\n",
      "353 1.0\n",
      "354 1.0\n",
      "359 1.0\n",
      "362 1.0\n",
      "365 1.0\n",
      "366 1.0\n",
      "369 1.0\n",
      "371 1.0\n",
      "373 1.0\n",
      "375 1.0\n",
      "376 1.0\n",
      "385 1.0\n",
      "395 1.0\n",
      "409 1.0\n",
      "410 1.0\n",
      "411 1.0\n",
      "415 0.9375\n",
      "421 1.0\n",
      "424 0.9696691176470589\n",
      "435 1.0\n",
      "436 1.0\n",
      "437 0.9558035714285714\n",
      "438 1.0\n",
      "452 1.0\n",
      "455 0.984375\n",
      "460 1.0\n",
      "463 1.0\n",
      "467 1.0\n",
      "468 1.0\n",
      "472 1.0\n",
      "481 0.9609375\n",
      "483 1.0\n",
      "484 1.0\n",
      "488 1.0\n",
      "491 1.0\n",
      "492 0.9337121212121212\n",
      "493 1.0\n",
      "496 1.0\n",
      "497 1.0\n",
      "505 1.0\n",
      "507 1.0\n",
      "517 0.94921875\n",
      "518 1.0\n",
      "520 1.0\n",
      "523 1.0\n",
      "525 0.9635416666666666\n",
      "529 1.0\n",
      "531 1.0\n",
      "533 1.0\n",
      "534 0.9635416666666666\n",
      "538 1.0\n",
      "539 1.0\n",
      "540 1.0\n",
      "543 1.0\n",
      "544 1.0\n",
      "546 1.0\n",
      "547 1.0\n",
      "552 0.953125\n",
      "556 1.0\n",
      "559 1.0\n",
      "564 1.0\n",
      "567 1.0\n",
      "570 1.0\n",
      "572 1.0\n",
      "589 1.0\n",
      "593 1.0\n",
      "595 1.0\n",
      "600 1.0\n",
      "601 0.9791666666666666\n",
      "603 1.0\n",
      "604 1.0\n",
      "609 1.0\n",
      "610 1.0\n",
      "613 1.0\n",
      "614 1.0\n",
      "617 1.0\n",
      "619 1.0\n",
      "622 1.0\n",
      "625 1.0\n",
      "628 1.0\n",
      "629 1.0\n",
      "632 1.0\n",
      "634 0.9375\n",
      "635 0.9427083333333334\n",
      "637 1.0\n",
      "640 1.0\n",
      "641 1.0\n",
      "642 1.0\n",
      "649 1.0\n",
      "651 1.0\n",
      "654 1.0\n",
      "658 1.0\n",
      "659 1.0\n",
      "660 1.0\n",
      "664 0.9427083333333334\n",
      "670 1.0\n",
      "675 1.0\n",
      "676 0.9337121212121212\n",
      "677 1.0\n",
      "678 1.0\n",
      "683 1.0\n",
      "684 1.0\n",
      "689 1.0\n",
      "690 1.0\n",
      "699 1.0\n",
      "701 0.9375\n",
      "703 0.8984375\n",
      "711 0.9450334821428571\n",
      "715 0.9801377118644068\n",
      "720 1.0\n",
      "724 1.0\n",
      "730 1.0\n",
      "733 1.0\n",
      "734 1.0\n",
      "736 1.0\n",
      "745 1.0\n",
      "746 1.0\n",
      "747 1.0\n",
      "748 1.0\n",
      "750 0.90625\n",
      "754 1.0\n",
      "755 1.0\n",
      "763 1.0\n",
      "766 1.0\n",
      "773 1.0\n",
      "778 1.0\n",
      "779 1.0\n",
      "783 1.0\n",
      "790 1.0\n",
      "792 1.0\n",
      "793 1.0\n",
      "796 1.0\n",
      "798 0.9140625\n",
      "808 1.0\n",
      "812 1.0\n",
      "813 1.0\n",
      "816 1.0\n",
      "820 1.0\n",
      "826 1.0\n",
      "830 1.0\n",
      "841 1.0\n",
      "844 1.0\n",
      "849 1.0\n",
      "855 1.0\n",
      "856 1.0\n",
      "867 1.0\n",
      "868 1.0\n",
      "870 1.0\n",
      "871 1.0\n",
      "876 1.0\n",
      "879 1.0\n",
      "880 0.965625\n",
      "883 1.0\n",
      "888 0.9708333333333333\n",
      "897 1.0\n",
      "903 0.9230171783625731\n",
      "914 1.0\n",
      "918 0.9453125\n",
      "923 1.0\n",
      "924 1.0\n",
      "927 1.0\n",
      "933 1.0\n",
      "934 1.0\n",
      "937 1.0\n",
      "938 1.0\n",
      "942 1.0\n",
      "944 1.0\n",
      "952 1.0\n",
      "957 0.96875\n",
      "963 1.0\n",
      "968 1.0\n",
      "971 1.0\n",
      "974 1.0\n",
      "978 0.953125\n",
      "981 1.0\n",
      "984 1.0\n",
      "988 0.9415922619047619\n",
      "990 1.0\n",
      "991 1.0\n",
      "993 1.0\n",
      "996 1.0\n",
      "1001 1.0\n",
      "1004 1.0\n",
      "1007 1.0\n",
      "1013 1.0\n",
      "1014 1.0\n",
      "1024 1.0\n",
      "1047 1.0\n",
      "1049 1.0\n",
      "1052 1.0\n",
      "1054 1.0\n",
      "1057 1.0\n",
      "1064 1.0\n",
      "1065 1.0\n",
      "1070 1.0\n",
      "1073 0.9453125\n",
      "1078 1.0\n",
      "1079 1.0\n",
      "1080 1.0\n",
      "1081 1.0\n",
      "1082 1.0\n",
      "1085 0.9427083333333334\n",
      "1086 1.0\n",
      "1089 1.0\n",
      "1092 1.0\n",
      "1099 1.0\n",
      "1102 1.0\n",
      "1103 1.0\n",
      "1104 1.0\n",
      "1111 1.0\n",
      "1112 1.0\n",
      "1115 1.0\n",
      "1122 1.0\n",
      "1123 0.97265625\n",
      "1127 1.0\n",
      "1129 1.0\n",
      "1131 0.9609375\n",
      "1132 1.0\n",
      "1136 1.0\n",
      "1138 1.0\n",
      "1146 1.0\n",
      "1147 1.0\n",
      "1149 1.0\n",
      "1150 0.9643342391304348\n",
      "1151 1.0\n",
      "1160 0.9140625\n",
      "1161 1.0\n",
      "1162 1.0\n",
      "1166 1.0\n",
      "1169 1.0\n",
      "1172 0.9427083333333334\n",
      "1173 1.0\n",
      "1179 0.9575892857142857\n",
      "1181 1.0\n",
      "1184 1.0\n",
      "1186 1.0\n",
      "1187 1.0\n",
      "1188 1.0\n",
      "1192 1.0\n",
      "1193 1.0\n",
      "1196 1.0\n",
      "1198 0.9453125\n",
      "1202 1.0\n",
      "1205 1.0\n",
      "1207 0.921875\n",
      "1210 1.0\n",
      "1212 1.0\n",
      "1223 0.9166666666666666\n",
      "1225 1.0\n",
      "1233 1.0\n",
      "1234 1.0\n",
      "1235 1.0\n",
      "1238 1.0\n",
      "1249 0.96875\n",
      "1251 1.0\n",
      "1253 1.0\n",
      "1254 1.0\n",
      "1258 1.0\n",
      "1260 1.0\n",
      "1271 1.0\n",
      "1286 1.0\n",
      "1289 1.0\n",
      "1294 1.0\n",
      "1301 1.0\n",
      "1306 1.0\n",
      "1308 0.9609375\n",
      "1309 1.0\n",
      "1314 1.0\n",
      "1318 1.0\n",
      "1319 1.0\n",
      "1323 1.0\n",
      "1325 1.0\n",
      "1326 0.9754901960784313\n",
      "1327 1.0\n",
      "1330 1.0\n",
      "1331 1.0\n",
      "1340 1.0\n",
      "1347 0.9422679227941176\n",
      "1350 1.0\n",
      "1352 0.921875\n",
      "1353 1.0\n",
      "1357 1.0\n",
      "1359 1.0\n",
      "1360 1.0\n",
      "1368 1.0\n",
      "1373 1.0\n",
      "1374 1.0\n",
      "1378 1.0\n",
      "1383 1.0\n",
      "1388 0.9453125\n",
      "1392 1.0\n",
      "1396 1.0\n",
      "1402 1.0\n",
      "1404 1.0\n",
      "1407 1.0\n",
      "1418 1.0\n",
      "1424 1.0\n",
      "1426 1.0\n",
      "1430 1.0\n",
      "1431 1.0\n",
      "1434 1.0\n",
      "1438 1.0\n",
      "1443 1.0\n",
      "1444 0.9829545454545454\n",
      "1448 1.0\n",
      "1449 1.0\n",
      "1471 1.0\n",
      "1474 1.0\n",
      "1475 1.0\n",
      "1478 1.0\n",
      "1479 0.921875\n",
      "1481 1.0\n",
      "1483 1.0\n",
      "1486 1.0\n",
      "1495 1.0\n",
      "1500 1.0\n",
      "1502 1.0\n",
      "1503 1.0\n",
      "1506 1.0\n",
      "1513 1.0\n",
      "1516 1.0\n",
      "1517 1.0\n",
      "1521 1.0\n",
      "1523 1.0\n",
      "1525 1.0\n",
      "1531 1.0\n",
      "1534 1.0\n",
      "1552 1.0\n",
      "1563 0.9765625\n",
      "1565 1.0\n",
      "1569 1.0\n",
      "1576 0.9583333333333334\n",
      "1577 1.0\n",
      "1581 1.0\n",
      "1587 1.0\n",
      "1588 1.0\n",
      "1592 1.0\n",
      "1596 1.0\n",
      "1598 1.0\n",
      "1601 1.0\n",
      "1602 1.0\n",
      "1603 1.0\n",
      "1608 1.0\n",
      "1612 0.9556107954545454\n",
      "1626 1.0\n",
      "1630 1.0\n",
      "1632 1.0\n",
      "1633 1.0\n",
      "1635 1.0\n",
      "1640 1.0\n",
      "1645 0.9296875\n",
      "1647 1.0\n",
      "1651 1.0\n",
      "1657 1.0\n",
      "1660 0.9625\n",
      "1661 1.0\n",
      "1665 0.9453125\n",
      "1669 1.0\n",
      "1670 1.0\n",
      "1679 1.0\n",
      "1681 1.0\n",
      "1684 1.0\n",
      "1685 1.0\n",
      "1687 1.0\n",
      "1693 1.0\n",
      "1697 1.0\n",
      "1704 1.0\n",
      "1707 0.9388020833333334\n",
      "1712 1.0\n",
      "1713 1.0\n",
      "1720 1.0\n",
      "1723 1.0\n",
      "1724 1.0\n",
      "1725 1.0\n",
      "1726 0.9765625\n",
      "1732 1.0\n",
      "1733 1.0\n",
      "1735 0.94921875\n",
      "1739 0.9453125\n",
      "1746 1.0\n",
      "1748 1.0\n",
      "1755 1.0\n",
      "1757 1.0\n",
      "1759 0.9422679227941176\n",
      "1760 1.0\n",
      "1762 1.0\n",
      "1767 1.0\n",
      "1768 0.9583333333333334\n",
      "1770 1.0\n",
      "1771 1.0\n",
      "1775 1.0\n",
      "1779 1.0\n",
      "1785 1.0\n",
      "1787 1.0\n",
      "1788 1.0\n",
      "1800 0.9583333333333334\n",
      "1806 1.0\n",
      "1811 1.0\n",
      "1818 1.0\n",
      "1821 1.0\n",
      "1822 1.0\n",
      "1824 1.0\n",
      "1828 1.0\n",
      "1830 1.0\n",
      "1835 1.0\n",
      "1838 1.0\n",
      "1842 1.0\n",
      "1845 1.0\n",
      "1850 1.0\n",
      "1857 1.0\n",
      "1858 1.0\n",
      "1859 1.0\n",
      "1871 1.0\n",
      "1872 1.0\n",
      "1875 1.0\n",
      "1876 1.0\n",
      "1884 1.0\n",
      "1885 1.0\n",
      "1886 1.0\n",
      "1889 1.0\n",
      "1890 1.0\n",
      "1894 1.0\n",
      "1896 1.0\n",
      "1897 1.0\n",
      "1898 1.0\n",
      "1899 1.0\n",
      "1901 1.0\n",
      "1909 1.0\n",
      "1910 1.0\n",
      "1911 1.0\n",
      "1912 1.0\n",
      "1915 1.0\n",
      "1917 1.0\n",
      "1918 1.0\n",
      "1920 1.0\n",
      "1923 1.0\n",
      "1924 1.0\n",
      "1935 1.0\n",
      "1938 1.0\n",
      "1939 1.0\n",
      "1940 1.0\n",
      "1942 1.0\n",
      "1945 1.0\n",
      "1953 1.0\n",
      "1954 0.9638097426470589\n",
      "1958 1.0\n",
      "1959 1.0\n",
      "1963 1.0\n",
      "1969 1.0\n",
      "1970 0.9548277243589743\n",
      "1973 0.9696691176470589\n",
      "1975 1.0\n",
      "1976 1.0\n",
      "1979 1.0\n",
      "1987 1.0\n",
      "1993 1.0\n",
      "1998 0.9416666666666667\n",
      "2004 1.0\n",
      "2013 1.0\n",
      "2017 0.9416666666666667\n",
      "2023 1.0\n",
      "2028 1.0\n",
      "2030 1.0\n",
      "2031 1.0\n",
      "2032 1.0\n",
      "2035 1.0\n",
      "2036 0.921875\n",
      "2038 1.0\n",
      "2039 1.0\n",
      "2046 1.0\n",
      "2048 1.0\n",
      "2052 0.9625\n",
      "2053 1.0\n",
      "2061 1.0\n",
      "2064 1.0\n",
      "2065 1.0\n",
      "2073 1.0\n",
      "2076 1.0\n",
      "2079 1.0\n",
      "2081 0.953125\n",
      "2084 1.0\n",
      "2088 1.0\n",
      "2089 1.0\n",
      "2092 1.0\n",
      "2093 1.0\n",
      "2095 1.0\n",
      "2096 1.0\n",
      "2100 1.0\n",
      "2104 1.0\n",
      "2111 1.0\n",
      "2113 1.0\n",
      "2118 1.0\n",
      "2122 0.9578125\n",
      "2123 0.9675324675324676\n",
      "2124 1.0\n",
      "2125 1.0\n",
      "2127 1.0\n",
      "2136 1.0\n",
      "2143 1.0\n",
      "2144 1.0\n",
      "2145 1.0\n",
      "2151 0.962071718931475\n",
      "2152 1.0\n",
      "2154 1.0\n",
      "2156 1.0\n",
      "2160 1.0\n",
      "2161 1.0\n",
      "2162 1.0\n",
      "2166 0.9401041666666666\n",
      "2167 0.9352678571428571\n",
      "2172 1.0\n",
      "2175 1.0\n",
      "2176 1.0\n",
      "2181 1.0\n",
      "2187 1.0\n",
      "2188 1.0\n",
      "2189 1.0\n",
      "2195 1.0\n",
      "2197 0.9638097426470589\n",
      "2198 1.0\n",
      "2200 1.0\n",
      "2201 1.0\n",
      "2202 0.9453125\n",
      "2205 1.0\n",
      "2206 1.0\n",
      "2207 1.0\n",
      "2208 1.0\n",
      "2209 1.0\n",
      "2213 1.0\n",
      "2216 0.96484375\n",
      "2217 0.9453125\n",
      "2219 1.0\n",
      "2220 1.0\n",
      "2222 1.0\n",
      "2223 1.0\n",
      "2224 0.9801377118644068\n",
      "2225 1.0\n",
      "2227 1.0\n",
      "2229 0.9556107954545454\n",
      "2233 1.0\n",
      "2235 1.0\n",
      "2237 1.0\n",
      "2249 1.0\n",
      "2256 1.0\n",
      "2258 1.0\n",
      "2261 1.0\n",
      "2262 1.0\n",
      "2272 0.962071718931475\n",
      "2278 1.0\n",
      "2286 1.0\n",
      "2289 1.0\n",
      "2302 1.0\n",
      "2303 1.0\n",
      "2305 1.0\n",
      "2310 1.0\n",
      "2312 1.0\n",
      "2316 1.0\n",
      "2317 1.0\n",
      "2319 1.0\n",
      "2320 1.0\n",
      "2324 0.96484375\n",
      "2326 1.0\n",
      "2329 1.0\n",
      "2334 1.0\n",
      "2338 1.0\n",
      "2342 1.0\n",
      "2349 1.0\n",
      "2350 1.0\n",
      "2351 1.0\n",
      "2355 1.0\n",
      "2359 1.0\n",
      "2364 1.0\n",
      "2367 1.0\n",
      "2368 1.0\n",
      "2371 1.0\n",
      "2387 1.0\n",
      "2388 1.0\n",
      "2399 1.0\n",
      "2401 1.0\n",
      "2402 0.9602272727272727\n",
      "2403 1.0\n",
      "2407 1.0\n",
      "2414 1.0\n",
      "2418 1.0\n",
      "2420 1.0\n",
      "2422 1.0\n",
      "2424 1.0\n",
      "2426 1.0\n",
      "2428 0.9583333333333334\n",
      "2430 0.9765625\n",
      "2435 1.0\n",
      "2440 1.0\n",
      "2441 1.0\n",
      "2442 1.0\n",
      "2448 1.0\n",
      "2452 1.0\n",
      "2460 1.0\n",
      "2461 1.0\n",
      "2463 0.9322916666666666\n",
      "2465 1.0\n",
      "2468 0.9793198529411765\n",
      "2470 1.0\n",
      "2478 1.0\n",
      "2485 1.0\n",
      "2486 0.9635416666666666\n",
      "2490 1.0\n",
      "2493 1.0\n",
      "2498 0.859375\n",
      "2505 1.0\n",
      "2511 0.953125\n",
      "2515 1.0\n",
      "2516 1.0\n",
      "2517 1.0\n",
      "2519 1.0\n",
      "2524 0.9921875\n",
      "2531 1.0\n",
      "2537 1.0\n",
      "2538 1.0\n",
      "2542 1.0\n",
      "2544 1.0\n",
      "2547 1.0\n",
      "2548 1.0\n",
      "2557 1.0\n",
      "2563 1.0\n",
      "2573 1.0\n",
      "2574 1.0\n",
      "2575 1.0\n",
      "2580 0.9495192307692307\n",
      "2590 0.9388020833333334\n",
      "2592 1.0\n",
      "2593 1.0\n",
      "2594 0.9427083333333334\n",
      "2595 1.0\n",
      "2597 1.0\n",
      "2598 1.0\n",
      "2602 1.0\n",
      "2605 1.0\n",
      "2606 0.9364583333333333\n",
      "2607 1.0\n",
      "2611 1.0\n",
      "2613 1.0\n",
      "2616 1.0\n",
      "2617 0.9806547619047619\n",
      "2625 1.0\n",
      "2626 0.9830013736263736\n",
      "2632 1.0\n",
      "2635 1.0\n",
      "2637 1.0\n",
      "2638 0.9559294871794872\n",
      "2640 1.0\n",
      "2643 0.96875\n",
      "2645 1.0\n",
      "2646 1.0\n",
      "2647 1.0\n",
      "2650 1.0\n",
      "2654 0.9375\n",
      "2655 1.0\n",
      "2658 1.0\n",
      "2660 1.0\n",
      "2665 1.0\n",
      "2670 1.0\n",
      "2671 1.0\n",
      "2681 1.0\n",
      "2682 1.0\n",
      "2686 1.0\n",
      "2687 1.0\n",
      "2699 1.0\n",
      "2704 1.0\n",
      "2706 1.0\n",
      "2707 0.921875\n",
      "2715 1.0\n",
      "2716 0.9375\n",
      "2723 1.0\n",
      "2726 1.0\n",
      "2729 1.0\n",
      "2731 1.0\n",
      "2735 1.0\n",
      "2741 1.0\n",
      "2744 1.0\n",
      "2745 0.9765625\n",
      "2746 1.0\n",
      "2747 1.0\n",
      "2752 1.0\n",
      "2758 1.0\n",
      "2759 1.0\n",
      "2762 1.0\n",
      "2771 1.0\n",
      "2778 1.0\n",
      "2780 1.0\n",
      "2784 1.0\n",
      "2789 1.0\n",
      "2791 1.0\n",
      "2794 1.0\n",
      "2796 0.9765625\n",
      "2797 0.9583333333333334\n",
      "2800 1.0\n",
      "2803 0.9522569444444444\n",
      "2804 0.9765625\n",
      "2809 1.0\n",
      "2812 1.0\n",
      "2818 1.0\n",
      "2821 1.0\n",
      "2823 1.0\n",
      "2830 0.9799107142857143\n",
      "2831 1.0\n",
      "2833 1.0\n",
      "2834 1.0\n",
      "2838 0.9765625\n",
      "2839 1.0\n",
      "2840 1.0\n",
      "2844 1.0\n",
      "2848 1.0\n",
      "2851 1.0\n",
      "2860 1.0\n",
      "2861 0.9643342391304348\n",
      "2865 1.0\n",
      "2866 0.9375\n",
      "2870 0.9556107954545454\n",
      "2871 1.0\n",
      "2875 1.0\n",
      "2876 1.0\n",
      "2880 1.0\n",
      "2883 0.9625\n",
      "2886 1.0\n",
      "2890 0.9635416666666666\n",
      "2894 1.0\n",
      "2896 1.0\n",
      "2897 1.0\n",
      "2899 1.0\n",
      "2904 1.0\n",
      "2911 1.0\n",
      "2913 1.0\n",
      "2915 0.96875\n",
      "2916 1.0\n",
      "2920 1.0\n",
      "2929 1.0\n",
      "2931 1.0\n",
      "2943 1.0\n",
      "2946 0.953125\n",
      "2949 1.0\n",
      "2950 1.0\n",
      "2951 1.0\n",
      "2952 1.0\n",
      "2957 1.0\n",
      "2959 1.0\n",
      "2962 1.0\n",
      "2970 1.0\n",
      "2972 1.0\n",
      "2973 1.0\n",
      "2981 1.0\n",
      "2983 0.9140625\n",
      "2984 0.9453125\n",
      "2988 1.0\n",
      "2996 1.0\n",
      "3011 0.9453125\n",
      "3012 1.0\n",
      "3013 1.0\n",
      "3023 1.0\n",
      "3025 0.9375\n",
      "3030 1.0\n",
      "3033 1.0\n",
      "3037 1.0\n",
      "3043 1.0\n",
      "3044 1.0\n",
      "3047 1.0\n",
      "3048 1.0\n",
      "3064 1.0\n",
      "3065 0.9857954545454546\n",
      "3066 1.0\n",
      "3076 1.0\n",
      "3078 1.0\n",
      "3080 1.0\n",
      "3081 1.0\n",
      "3086 1.0\n",
      "3093 1.0\n",
      "3094 1.0\n",
      "3095 1.0\n",
      "3098 1.0\n",
      "3105 1.0\n",
      "3107 1.0\n",
      "3108 1.0\n",
      "3113 1.0\n",
      "3116 1.0\n",
      "3119 1.0\n",
      "3125 1.0\n",
      "3129 1.0\n",
      "3130 1.0\n",
      "3131 1.0\n",
      "3132 1.0\n",
      "3136 1.0\n",
      "3144 1.0\n",
      "3146 1.0\n",
      "3150 1.0\n",
      "3162 1.0\n",
      "3167 1.0\n",
      "3169 1.0\n",
      "3170 0.9296875\n",
      "3175 1.0\n",
      "3177 1.0\n",
      "3181 1.0\n",
      "3183 1.0\n",
      "3184 1.0\n",
      "3187 1.0\n",
      "3188 1.0\n",
      "3193 1.0\n",
      "3197 1.0\n",
      "3201 1.0\n",
      "3205 1.0\n",
      "3207 1.0\n",
      "3208 0.9453125\n",
      "3211 1.0\n",
      "3212 1.0\n",
      "3213 1.0\n",
      "3218 1.0\n",
      "3220 0.9270833333333334\n",
      "3221 0.9609375\n",
      "3228 1.0\n",
      "3235 1.0\n",
      "3248 1.0\n",
      "3252 1.0\n",
      "3258 1.0\n",
      "3262 1.0\n",
      "3263 1.0\n",
      "3264 1.0\n",
      "3266 0.962071718931475\n",
      "3268 1.0\n",
      "3269 0.9553571428571429\n",
      "3271 1.0\n",
      "3282 1.0\n",
      "3285 1.0\n",
      "3286 0.9495192307692307\n",
      "3289 1.0\n",
      "3294 1.0\n",
      "3297 1.0\n",
      "3302 1.0\n",
      "3305 1.0\n",
      "3310 1.0\n",
      "3313 1.0\n",
      "3316 1.0\n",
      "3321 1.0\n",
      "3322 1.0\n",
      "3326 1.0\n",
      "3330 1.0\n",
      "3331 1.0\n",
      "3333 1.0\n",
      "3334 1.0\n",
      "3338 1.0\n",
      "3339 0.9598214285714286\n",
      "3347 0.953125\n",
      "3350 1.0\n",
      "3353 1.0\n",
      "3354 1.0\n",
      "3358 1.0\n",
      "3362 1.0\n",
      "3363 1.0\n",
      "3372 1.0\n",
      "3380 1.0\n",
      "3382 1.0\n",
      "3384 1.0\n",
      "3385 1.0\n",
      "3396 0.9801377118644068\n",
      "3398 1.0\n",
      "3399 0.97265625\n",
      "3400 1.0\n",
      "3408 0.9862132352941176\n",
      "3410 1.0\n",
      "3415 1.0\n",
      "3418 1.0\n",
      "3420 1.0\n",
      "3421 1.0\n",
      "3422 1.0\n",
      "3423 1.0\n",
      "3424 0.9296875\n",
      "3431 1.0\n",
      "3432 0.9453125\n",
      "3435 1.0\n",
      "3436 1.0\n",
      "3442 1.0\n",
      "3444 1.0\n",
      "3447 1.0\n",
      "3457 1.0\n",
      "3459 1.0\n",
      "3471 1.0\n",
      "3477 0.9453125\n",
      "3479 1.0\n",
      "3486 1.0\n",
      "3489 1.0\n",
      "3492 1.0\n",
      "3493 1.0\n",
      "3499 1.0\n",
      "3500 1.0\n",
      "3502 1.0\n",
      "3505 0.953125\n",
      "3508 1.0\n",
      "3513 1.0\n",
      "3514 1.0\n",
      "3515 1.0\n",
      "3521 1.0\n",
      "3522 1.0\n",
      "3526 0.9625\n",
      "3529 1.0\n",
      "3533 0.9541666666666667\n",
      "3535 1.0\n",
      "3536 0.953125\n",
      "3537 1.0\n",
      "3538 1.0\n",
      "3539 1.0\n",
      "3541 1.0\n",
      "3550 1.0\n",
      "3551 1.0\n",
      "3552 1.0\n",
      "3554 1.0\n",
      "3555 1.0\n",
      "3556 0.9578125\n",
      "3557 0.9638097426470589\n",
      "3559 1.0\n",
      "3562 0.875\n",
      "3564 1.0\n",
      "3565 1.0\n",
      "3567 1.0\n",
      "3568 0.9427083333333334\n",
      "3569 1.0\n",
      "3571 1.0\n",
      "3575 0.9621975806451613\n",
      "3577 1.0\n",
      "3578 1.0\n",
      "3590 1.0\n",
      "3593 1.0\n",
      "3597 1.0\n",
      "3598 0.953125\n",
      "3599 1.0\n",
      "3600 1.0\n",
      "3605 1.0\n",
      "3606 1.0\n",
      "3608 1.0\n",
      "3609 1.0\n",
      "3610 1.0\n",
      "3613 0.9583333333333334\n",
      "3614 1.0\n",
      "3615 1.0\n",
      "3616 1.0\n",
      "3620 1.0\n",
      "3621 1.0\n",
      "3623 1.0\n",
      "3625 1.0\n",
      "3626 0.9140625\n",
      "3631 1.0\n",
      "3632 1.0\n",
      "3635 0.953125\n",
      "3640 1.0\n",
      "3646 0.96484375\n",
      "3647 1.0\n",
      "3651 1.0\n",
      "3657 1.0\n",
      "3659 1.0\n",
      "3660 1.0\n",
      "3669 1.0\n",
      "3672 1.0\n",
      "3680 1.0\n",
      "3682 1.0\n",
      "3683 1.0\n",
      "3684 0.9558035714285714\n",
      "3685 0.9621975806451613\n",
      "3687 0.9375\n",
      "3698 1.0\n",
      "3699 1.0\n",
      "3703 1.0\n",
      "3709 1.0\n",
      "3712 1.0\n",
      "3714 1.0\n",
      "3715 0.953125\n",
      "3719 1.0\n",
      "3723 1.0\n",
      "3724 1.0\n",
      "3726 1.0\n",
      "3727 1.0\n",
      "3728 1.0\n",
      "3729 1.0\n",
      "3733 0.9548277243589743\n",
      "3738 1.0\n",
      "3743 0.9632932692307692\n",
      "3744 1.0\n",
      "3748 1.0\n",
      "3753 1.0\n",
      "3754 1.0\n",
      "3755 1.0\n",
      "3759 1.0\n",
      "3760 1.0\n",
      "3762 1.0\n",
      "3763 0.9427083333333334\n",
      "3764 1.0\n",
      "3767 1.0\n",
      "3769 1.0\n",
      "3774 1.0\n",
      "3776 0.9643342391304348\n",
      "3779 1.0\n",
      "3780 1.0\n",
      "3784 0.9479166666666666\n",
      "3786 1.0\n",
      "3791 1.0\n",
      "3793 1.0\n",
      "3797 0.9638097426470589\n",
      "3800 1.0\n",
      "3801 1.0\n",
      "3809 1.0\n",
      "3814 0.946875\n",
      "3822 1.0\n",
      "3823 1.0\n",
      "3827 1.0\n",
      "3828 1.0\n",
      "3830 1.0\n",
      "3835 1.0\n",
      "3838 1.0\n",
      "3844 1.0\n",
      "3846 1.0\n",
      "3850 1.0\n",
      "3851 1.0\n",
      "3853 1.0\n",
      "3854 0.9895833333333334\n",
      "3856 1.0\n",
      "3859 1.0\n",
      "3863 1.0\n",
      "3865 1.0\n",
      "3867 1.0\n",
      "3872 1.0\n",
      "3876 1.0\n",
      "3878 1.0\n",
      "3879 1.0\n",
      "3883 1.0\n",
      "3889 1.0\n",
      "3891 1.0\n",
      "3892 1.0\n",
      "3896 0.984375\n",
      "3901 1.0\n",
      "3908 1.0\n",
      "3911 1.0\n",
      "3922 1.0\n",
      "3934 1.0\n",
      "3938 0.9296875\n",
      "3944 1.0\n",
      "3946 1.0\n",
      "3948 0.9621975806451613\n",
      "3957 1.0\n",
      "3958 1.0\n",
      "3959 0.96875\n",
      "3961 1.0\n",
      "3965 1.0\n",
      "3969 1.0\n",
      "3974 0.90625\n",
      "3975 1.0\n",
      "3977 1.0\n",
      "3982 1.0\n",
      "3983 1.0\n",
      "3988 1.0\n",
      "3992 1.0\n",
      "3993 1.0\n",
      "3996 1.0\n",
      "3999 1.0\n",
      "4002 1.0\n",
      "4003 0.97265625\n",
      "4004 1.0\n",
      "4009 1.0\n",
      "4017 1.0\n",
      "4018 1.0\n",
      "4020 0.9495192307692307\n",
      "4023 1.0\n",
      "4024 0.96875\n",
      "4029 1.0\n",
      "4031 1.0\n",
      "4037 1.0\n",
      "4038 0.9791666666666666\n",
      "4043 1.0\n",
      "4045 1.0\n",
      "4047 1.0\n",
      "4050 1.0\n",
      "4053 1.0\n",
      "4057 0.9598214285714286\n",
      "4059 1.0\n",
      "4062 1.0\n",
      "4065 1.0\n",
      "4066 0.8359375\n",
      "4071 1.0\n",
      "4076 1.0\n",
      "4077 1.0\n",
      "4085 1.0\n",
      "4088 1.0\n",
      "4091 1.0\n",
      "4092 0.9806547619047619\n",
      "4094 1.0\n",
      "4101 1.0\n",
      "4102 1.0\n",
      "4108 1.0\n",
      "4109 1.0\n",
      "4110 1.0\n",
      "4113 1.0\n",
      "4114 1.0\n",
      "4115 1.0\n",
      "4118 1.0\n",
      "4120 1.0\n",
      "4123 1.0\n",
      "4124 1.0\n",
      "4126 1.0\n",
      "4129 1.0\n",
      "4130 0.962071718931475\n",
      "4138 1.0\n",
      "4146 1.0\n",
      "4154 1.0\n",
      "4155 1.0\n",
      "4156 1.0\n",
      "4160 1.0\n",
      "4161 1.0\n",
      "4164 1.0\n",
      "4167 1.0\n",
      "4171 1.0\n",
      "4172 1.0\n",
      "4182 1.0\n",
      "4184 1.0\n",
      "4185 1.0\n",
      "4188 1.0\n",
      "4193 1.0\n",
      "4197 1.0\n",
      "4199 1.0\n",
      "4201 1.0\n",
      "4207 1.0\n",
      "4208 1.0\n",
      "4214 1.0\n",
      "4215 1.0\n",
      "4216 1.0\n",
      "4223 1.0\n",
      "4225 1.0\n",
      "4227 0.9602272727272727\n",
      "4228 0.9675324675324676\n",
      "4229 0.9497767857142857\n",
      "4231 1.0\n",
      "4233 1.0\n",
      "4235 1.0\n",
      "4240 1.0\n",
      "4242 1.0\n",
      "4243 1.0\n",
      "4245 0.9609375\n",
      "4253 1.0\n",
      "4254 1.0\n",
      "4257 1.0\n",
      "4258 1.0\n",
      "4265 1.0\n",
      "4272 1.0\n",
      "4281 1.0\n",
      "4286 1.0\n",
      "4289 1.0\n",
      "4290 1.0\n",
      "4291 1.0\n",
      "4292 1.0\n",
      "4295 0.890625\n",
      "4299 0.9427083333333334\n",
      "4301 1.0\n",
      "4309 1.0\n",
      "4314 1.0\n",
      "4316 1.0\n",
      "4320 1.0\n",
      "4323 1.0\n",
      "4328 1.0\n",
      "4329 1.0\n",
      "4330 1.0\n",
      "4333 0.9522569444444444\n",
      "4336 1.0\n",
      "4338 0.96875\n",
      "4340 1.0\n",
      "4341 1.0\n",
      "4342 0.962071718931475\n",
      "4345 1.0\n",
      "4350 1.0\n",
      "4357 1.0\n",
      "4366 1.0\n",
      "4367 1.0\n",
      "4369 0.9862132352941176\n",
      "4372 1.0\n",
      "4378 0.9453125\n",
      "4381 1.0\n",
      "4388 1.0\n",
      "4396 1.0\n",
      "4399 1.0\n",
      "4401 1.0\n",
      "4402 1.0\n",
      "4413 1.0\n",
      "4414 1.0\n",
      "4424 0.9830013736263736\n",
      "4430 1.0\n",
      "4433 0.9765625\n",
      "4437 1.0\n",
      "4439 1.0\n",
      "4444 1.0\n",
      "4445 1.0\n",
      "4448 1.0\n",
      "4456 1.0\n",
      "4462 1.0\n",
      "4463 1.0\n",
      "4466 1.0\n",
      "4471 1.0\n",
      "4474 1.0\n",
      "4483 1.0\n",
      "4484 1.0\n",
      "4485 0.9140625\n",
      "4486 1.0\n",
      "4497 1.0\n",
      "4499 1.0\n",
      "4504 1.0\n",
      "4507 1.0\n",
      "4508 1.0\n",
      "4509 0.9765625\n",
      "4510 1.0\n",
      "4512 1.0\n",
      "4515 1.0\n",
      "4525 1.0\n",
      "4526 1.0\n",
      "4531 1.0\n",
      "4532 1.0\n",
      "4533 1.0\n",
      "4540 1.0\n",
      "4541 1.0\n",
      "4542 0.9765625\n",
      "4546 1.0\n",
      "4548 1.0\n",
      "4549 1.0\n",
      "4551 1.0\n",
      "4553 1.0\n",
      "4558 1.0\n",
      "4575 1.0\n",
      "4576 1.0\n",
      "4577 1.0\n",
      "4578 1.0\n",
      "4582 1.0\n",
      "4586 1.0\n",
      "4590 1.0\n",
      "4591 1.0\n",
      "4592 0.91015625\n",
      "4593 1.0\n",
      "4600 1.0\n",
      "4613 1.0\n",
      "4616 1.0\n",
      "4617 1.0\n",
      "4618 1.0\n",
      "4619 1.0\n",
      "4620 1.0\n",
      "4623 1.0\n",
      "4629 0.9421875\n",
      "4632 1.0\n",
      "4634 1.0\n",
      "4635 1.0\n",
      "4636 1.0\n",
      "4640 1.0\n",
      "4642 1.0\n",
      "4643 1.0\n",
      "4644 1.0\n",
      "4667 1.0\n",
      "4668 0.9621975806451613\n",
      "4676 1.0\n",
      "4677 0.8984375\n",
      "4681 1.0\n",
      "4691 1.0\n",
      "4693 1.0\n",
      "4695 1.0\n",
      "4696 1.0\n",
      "4700 1.0\n",
      "4706 1.0\n",
      "4708 1.0\n",
      "4712 1.0\n",
      "4716 1.0\n",
      "4725 1.0\n",
      "4726 1.0\n",
      "4727 1.0\n",
      "4731 0.9558035714285714\n",
      "4733 1.0\n",
      "4734 0.9408482142857143\n",
      "4737 1.0\n",
      "4740 0.9464285714285714\n",
      "4741 1.0\n",
      "4746 1.0\n",
      "4747 1.0\n",
      "4748 1.0\n",
      "4755 1.0\n",
      "4757 1.0\n",
      "4767 1.0\n",
      "4772 1.0\n",
      "4775 1.0\n",
      "4779 1.0\n",
      "4781 0.9408482142857143\n",
      "4787 1.0\n",
      "4792 1.0\n",
      "4793 1.0\n",
      "4794 1.0\n",
      "4796 0.9541666666666667\n",
      "4802 1.0\n",
      "4803 1.0\n",
      "4804 1.0\n",
      "4807 1.0\n",
      "4812 1.0\n",
      "4814 1.0\n",
      "4817 1.0\n",
      "4822 0.9754901960784313\n",
      "4824 0.9421875\n",
      "4825 1.0\n",
      "4836 1.0\n",
      "4837 1.0\n",
      "4839 1.0\n",
      "4840 1.0\n",
      "4841 1.0\n",
      "4845 1.0\n",
      "4846 1.0\n",
      "4848 1.0\n",
      "4849 1.0\n",
      "4852 0.984375\n",
      "4856 1.0\n",
      "4864 1.0\n",
      "4869 1.0\n",
      "4872 1.0\n",
      "4874 1.0\n",
      "4876 1.0\n",
      "4881 1.0\n",
      "4882 1.0\n",
      "4885 0.9558035714285714\n",
      "4888 1.0\n",
      "4889 0.96875\n",
      "4893 1.0\n",
      "4895 1.0\n",
      "4896 1.0\n",
      "4897 0.9713541666666666\n",
      "4904 0.8984375\n",
      "4906 1.0\n",
      "4911 1.0\n",
      "4921 1.0\n",
      "4924 1.0\n",
      "4929 1.0\n",
      "4934 1.0\n",
      "4936 1.0\n",
      "4944 1.0\n",
      "4946 1.0\n",
      "4947 1.0\n",
      "4949 1.0\n",
      "4961 0.921875\n",
      "4963 1.0\n",
      "4965 1.0\n",
      "4970 1.0\n",
      "4976 1.0\n",
      "4980 1.0\n",
      "4981 0.9517463235294118\n",
      "4982 1.0\n",
      "4985 1.0\n",
      "4987 0.8203125\n",
      "4996 1.0\n",
      "4998 1.0\n",
      "5005 1.0\n",
      "5006 1.0\n",
      "5010 1.0\n",
      "5012 1.0\n",
      "5013 1.0\n",
      "5015 0.9813988095238095\n",
      "5018 1.0\n",
      "5021 0.9635416666666666\n",
      "5022 1.0\n",
      "5031 1.0\n",
      "5037 1.0\n",
      "5038 1.0\n",
      "5039 1.0\n",
      "5049 1.0\n",
      "5053 0.96875\n",
      "5054 1.0\n",
      "5058 1.0\n",
      "5059 1.0\n",
      "5064 1.0\n",
      "5074 1.0\n",
      "5076 1.0\n",
      "5077 1.0\n",
      "5081 1.0\n",
      "5082 1.0\n",
      "5087 0.9140625\n",
      "5089 1.0\n",
      "5096 1.0\n",
      "5100 1.0\n",
      "5103 1.0\n",
      "5108 1.0\n",
      "5111 1.0\n",
      "5114 1.0\n",
      "5118 1.0\n",
      "5120 1.0\n",
      "5123 1.0\n",
      "5128 1.0\n",
      "5129 0.96875\n",
      "5130 1.0\n",
      "5133 1.0\n",
      "5137 1.0\n",
      "5144 1.0\n",
      "5147 0.9375\n",
      "5149 0.9296875\n",
      "5153 1.0\n",
      "5154 0.9783653846153846\n",
      "5159 1.0\n",
      "5161 1.0\n",
      "5166 1.0\n",
      "5172 1.0\n",
      "5179 1.0\n",
      "5181 1.0\n",
      "5186 1.0\n",
      "5191 1.0\n",
      "5209 1.0\n",
      "5214 1.0\n",
      "5217 1.0\n",
      "5220 1.0\n",
      "5221 1.0\n",
      "5226 1.0\n",
      "5231 0.921875\n",
      "5233 1.0\n",
      "5237 1.0\n",
      "5239 0.8984375\n",
      "5241 1.0\n",
      "5242 0.953125\n",
      "5245 1.0\n",
      "5256 1.0\n",
      "5262 0.953125\n",
      "5263 1.0\n",
      "5264 1.0\n",
      "5268 1.0\n",
      "5272 0.9765625\n",
      "5279 1.0\n",
      "5286 1.0\n",
      "5288 1.0\n",
      "5289 1.0\n",
      "5292 1.0\n",
      "5297 1.0\n",
      "5300 1.0\n",
      "5312 0.9862132352941176\n",
      "5314 1.0\n",
      "5315 1.0\n",
      "5321 0.9497767857142857\n",
      "5325 1.0\n",
      "5328 0.9862132352941176\n",
      "5332 1.0\n",
      "5335 1.0\n",
      "5338 1.0\n",
      "5347 1.0\n",
      "5348 1.0\n",
      "5354 1.0\n",
      "5356 1.0\n",
      "5360 1.0\n",
      "5362 1.0\n",
      "5367 1.0\n",
      "5372 0.9754901960784313\n",
      "5379 1.0\n",
      "5387 1.0\n",
      "5388 1.0\n",
      "5390 1.0\n",
      "5391 1.0\n",
      "5393 1.0\n",
      "5395 1.0\n",
      "5397 1.0\n",
      "5410 1.0\n",
      "5418 1.0\n",
      "5420 1.0\n",
      "5421 1.0\n",
      "5426 1.0\n",
      "5429 0.9642857142857143\n",
      "5435 1.0\n",
      "5439 1.0\n",
      "5444 1.0\n",
      "5447 1.0\n",
      "5452 1.0\n",
      "5459 1.0\n",
      "5461 1.0\n",
      "5462 0.9453125\n",
      "5466 0.9635416666666666\n",
      "5471 1.0\n",
      "5473 1.0\n",
      "5479 1.0\n",
      "5481 0.90625\n",
      "5484 0.9799107142857143\n",
      "5487 1.0\n",
      "5490 0.9559294871794872\n",
      "5492 1.0\n",
      "5494 1.0\n",
      "5497 1.0\n",
      "5499 1.0\n",
      "5501 1.0\n",
      "5502 0.9422679227941176\n",
      "5503 1.0\n",
      "5507 1.0\n",
      "5509 1.0\n",
      "5511 1.0\n",
      "5512 1.0\n",
      "5514 1.0\n",
      "5515 1.0\n",
      "5517 1.0\n",
      "5518 1.0\n",
      "5520 1.0\n",
      "5528 1.0\n",
      "5532 1.0\n",
      "5540 1.0\n",
      "5542 0.9621975806451613\n",
      "5545 1.0\n",
      "5549 1.0\n",
      "5554 1.0\n",
      "5556 1.0\n",
      "5558 1.0\n",
      "5561 1.0\n",
      "5567 1.0\n",
      "5568 1.0\n",
      "5572 0.946875\n",
      "5573 0.9479166666666666\n",
      "5574 1.0\n",
      "5575 1.0\n",
      "5584 1.0\n",
      "5587 0.9375\n",
      "5590 1.0\n",
      "5593 1.0\n",
      "5594 1.0\n",
      "5596 1.0\n",
      "5606 1.0\n",
      "5618 1.0\n",
      "5620 1.0\n",
      "5627 1.0\n",
      "5630 1.0\n",
      "5636 1.0\n",
      "5637 1.0\n",
      "5642 1.0\n",
      "5645 1.0\n",
      "5647 1.0\n",
      "5652 0.9635416666666666\n",
      "5657 1.0\n",
      "5659 0.9296875\n",
      "5662 0.9696691176470589\n",
      "5663 1.0\n",
      "5665 1.0\n",
      "5666 1.0\n",
      "5670 1.0\n",
      "5672 1.0\n",
      "5674 0.9609375\n",
      "5675 0.9453125\n",
      "5681 1.0\n",
      "5682 1.0\n",
      "5683 1.0\n",
      "5696 1.0\n",
      "5700 1.0\n",
      "5701 1.0\n",
      "5705 1.0\n",
      "5706 1.0\n",
      "5713 1.0\n",
      "5717 1.0\n",
      "5721 1.0\n",
      "5723 1.0\n",
      "5726 0.9765625\n",
      "5728 1.0\n",
      "5732 1.0\n",
      "5739 0.9830013736263736\n",
      "5742 1.0\n",
      "5743 1.0\n",
      "5749 0.96875\n",
      "5752 1.0\n",
      "5758 1.0\n",
      "5760 1.0\n",
      "5762 1.0\n",
      "5768 1.0\n",
      "5769 1.0\n",
      "5771 1.0\n",
      "5772 1.0\n",
      "5774 1.0\n",
      "5779 0.9621975806451613\n",
      "5782 0.9791666666666666\n",
      "5792 0.9421875\n",
      "5793 0.9642857142857143\n",
      "5794 0.96875\n",
      "5798 1.0\n",
      "5803 1.0\n",
      "5806 0.94140625\n",
      "5810 1.0\n",
      "5811 1.0\n",
      "5813 1.0\n",
      "5820 1.0\n",
      "5821 1.0\n",
      "5824 1.0\n",
      "5830 1.0\n",
      "5832 1.0\n",
      "5833 1.0\n",
      "5838 1.0\n",
      "5842 1.0\n",
      "5850 1.0\n",
      "5854 1.0\n",
      "5858 1.0\n",
      "5861 1.0\n",
      "5863 0.953125\n",
      "5869 1.0\n",
      "5874 1.0\n",
      "5882 1.0\n",
      "5885 1.0\n",
      "5890 1.0\n",
      "5891 0.9588815789473685\n",
      "5894 1.0\n",
      "5900 0.875\n",
      "5903 1.0\n",
      "5904 1.0\n",
      "5911 0.9296875\n",
      "5913 1.0\n",
      "5914 1.0\n",
      "5919 1.0\n",
      "5926 0.9675324675324676\n",
      "5927 1.0\n",
      "5932 0.9609375\n",
      "5935 1.0\n",
      "5938 1.0\n",
      "5941 1.0\n",
      "5943 1.0\n",
      "5945 1.0\n",
      "5946 1.0\n",
      "5951 1.0\n",
      "5961 1.0\n",
      "5964 1.0\n",
      "5967 1.0\n",
      "5968 1.0\n",
      "5972 1.0\n",
      "5976 1.0\n",
      "5984 1.0\n",
      "5989 1.0\n",
      "5992 1.0\n",
      "5993 1.0\n",
      "6000 1.0\n",
      "6002 1.0\n",
      "6014 1.0\n",
      "6023 1.0\n",
      "6028 1.0\n",
      "6030 1.0\n",
      "6036 1.0\n",
      "6044 1.0\n",
      "6045 1.0\n",
      "6046 0.9517463235294118\n",
      "6048 0.9453125\n",
      "6053 0.9375\n",
      "6055 1.0\n",
      "6059 1.0\n",
      "6060 1.0\n",
      "6061 1.0\n",
      "6067 1.0\n",
      "6075 0.9114583333333334\n",
      "6077 1.0\n",
      "6082 1.0\n",
      "6095 1.0\n",
      "6100 1.0\n",
      "6102 0.9635416666666666\n",
      "6103 1.0\n",
      "6105 1.0\n",
      "6113 1.0\n",
      "6118 1.0\n",
      "6120 1.0\n",
      "6121 1.0\n",
      "6122 1.0\n",
      "6125 1.0\n",
      "6138 0.9548277243589743\n",
      "6139 1.0\n",
      "6142 1.0\n",
      "6145 1.0\n",
      "6146 0.9801377118644068\n",
      "6148 1.0\n",
      "6154 0.9732142857142857\n",
      "6157 1.0\n",
      "6165 1.0\n",
      "6166 1.0\n",
      "6174 1.0\n",
      "6177 1.0\n",
      "6178 1.0\n",
      "6181 1.0\n",
      "6182 0.9765625\n",
      "6195 1.0\n",
      "6197 1.0\n",
      "6199 1.0\n",
      "6203 0.9635416666666666\n",
      "6204 1.0\n",
      "6205 1.0\n",
      "6206 1.0\n",
      "6216 1.0\n",
      "6218 0.971875\n",
      "6221 1.0\n",
      "6224 0.953125\n",
      "6227 1.0\n",
      "6232 1.0\n",
      "6237 1.0\n",
      "6239 1.0\n",
      "6240 1.0\n",
      "6246 1.0\n",
      "6247 1.0\n",
      "6250 1.0\n",
      "6252 1.0\n",
      "6263 1.0\n",
      "6266 1.0\n",
      "6271 1.0\n",
      "6273 1.0\n",
      "6275 1.0\n",
      "6282 1.0\n",
      "6283 1.0\n",
      "6285 0.9801377118644068\n",
      "6297 1.0\n",
      "6305 1.0\n",
      "6306 1.0\n",
      "6308 1.0\n",
      "6310 1.0\n",
      "6317 1.0\n",
      "6323 1.0\n",
      "6324 0.9765625\n",
      "6325 1.0\n",
      "6331 1.0\n",
      "6334 1.0\n",
      "6337 1.0\n",
      "6339 0.9375\n",
      "6340 1.0\n",
      "6341 0.96875\n",
      "6352 1.0\n",
      "6353 0.9642857142857143\n",
      "6356 1.0\n",
      "6357 1.0\n",
      "6362 1.0\n",
      "6368 1.0\n",
      "6374 0.9375\n",
      "6375 1.0\n",
      "6378 1.0\n",
      "6393 1.0\n",
      "6397 1.0\n",
      "6403 1.0\n",
      "6407 1.0\n",
      "6414 1.0\n",
      "6416 0.97265625\n",
      "6421 0.9495192307692307\n",
      "6429 1.0\n",
      "6433 1.0\n",
      "6434 1.0\n",
      "6442 0.953125\n",
      "6445 1.0\n",
      "6450 1.0\n",
      "6453 1.0\n",
      "6455 1.0\n",
      "6458 1.0\n",
      "6460 1.0\n",
      "6463 1.0\n",
      "6472 1.0\n",
      "6474 1.0\n",
      "6475 1.0\n",
      "6476 1.0\n",
      "6478 0.9791666666666666\n",
      "6489 0.9791666666666666\n",
      "6490 1.0\n",
      "6495 0.9801377118644068\n",
      "6498 1.0\n",
      "6499 1.0\n",
      "6502 1.0\n",
      "6509 1.0\n",
      "6511 1.0\n",
      "6520 1.0\n",
      "6529 1.0\n",
      "6531 1.0\n",
      "6532 1.0\n",
      "6538 1.0\n",
      "6541 1.0\n",
      "6542 1.0\n",
      "6543 1.0\n",
      "6548 1.0\n",
      "6555 1.0\n",
      "6556 1.0\n",
      "6565 0.890625\n",
      "6567 0.9609375\n",
      "6568 1.0\n",
      "6571 1.0\n",
      "6572 0.9921875\n",
      "6574 0.8984375\n",
      "6578 0.96875\n",
      "6582 1.0\n",
      "6583 0.9427083333333334\n",
      "6586 1.0\n",
      "6589 1.0\n",
      "6590 1.0\n",
      "6592 1.0\n",
      "6599 1.0\n",
      "6602 1.0\n",
      "6603 1.0\n",
      "6610 1.0\n",
      "6613 1.0\n",
      "6618 1.0\n",
      "6627 1.0\n",
      "6629 1.0\n",
      "6630 0.9375\n",
      "6632 0.9548277243589743\n",
      "6641 1.0\n",
      "6651 1.0\n",
      "6653 1.0\n",
      "6662 1.0\n",
      "6664 0.96875\n",
      "6672 1.0\n",
      "6673 1.0\n",
      "6676 1.0\n",
      "6679 1.0\n",
      "6683 1.0\n",
      "6685 1.0\n",
      "6686 1.0\n",
      "6689 1.0\n",
      "6694 1.0\n",
      "6697 1.0\n",
      "6700 1.0\n",
      "6707 0.96875\n",
      "6710 1.0\n",
      "6711 1.0\n",
      "6716 0.9401041666666666\n",
      "6718 1.0\n",
      "6720 1.0\n",
      "6723 1.0\n",
      "6725 1.0\n",
      "6728 1.0\n",
      "6729 1.0\n",
      "6733 1.0\n",
      "6738 1.0\n",
      "6739 1.0\n",
      "6742 1.0\n",
      "6747 0.921875\n",
      "6752 1.0\n",
      "6754 1.0\n",
      "6755 0.9449404761904762\n",
      "6756 1.0\n",
      "6758 0.9609375\n",
      "6759 1.0\n",
      "6761 1.0\n",
      "6763 1.0\n",
      "6780 1.0\n",
      "6786 1.0\n",
      "6789 1.0\n",
      "6791 1.0\n",
      "6792 1.0\n",
      "6793 1.0\n",
      "6796 1.0\n",
      "6798 1.0\n",
      "6799 1.0\n",
      "6802 0.9375\n",
      "6808 0.9558035714285714\n",
      "6813 0.9613042840375586\n",
      "6816 0.9613042840375586\n",
      "6818 1.0\n",
      "6824 0.9739583333333334\n",
      "6825 1.0\n",
      "6826 1.0\n",
      "6830 1.0\n",
      "6838 1.0\n",
      "6842 1.0\n",
      "6848 1.0\n",
      "6852 1.0\n",
      "6862 1.0\n",
      "6866 0.9479166666666666\n",
      "6871 0.953125\n",
      "6876 1.0\n",
      "6878 1.0\n",
      "6879 1.0\n",
      "6884 1.0\n",
      "6885 1.0\n",
      "6886 1.0\n",
      "6891 1.0\n",
      "6892 1.0\n",
      "6893 1.0\n",
      "6899 0.9801377118644068\n",
      "6901 1.0\n",
      "6902 1.0\n",
      "6905 1.0\n",
      "6911 1.0\n",
      "6913 1.0\n",
      "6920 0.9643342391304348\n",
      "6937 1.0\n",
      "6956 1.0\n",
      "6957 1.0\n",
      "6959 0.9296875\n",
      "6960 0.9484375\n",
      "6961 1.0\n",
      "6963 1.0\n",
      "6965 1.0\n",
      "6966 1.0\n",
      "6971 0.9729567307692307\n",
      "6972 1.0\n",
      "6974 1.0\n",
      "6975 1.0\n",
      "6977 1.0\n",
      "6978 1.0\n",
      "6982 0.9609375\n",
      "6995 0.953125\n",
      "6999 1.0\n",
      "7001 1.0\n",
      "7002 1.0\n",
      "7006 0.9793198529411765\n",
      "7007 1.0\n",
      "7008 1.0\n",
      "7012 0.9166666666666666\n",
      "7020 1.0\n",
      "7022 0.9559294871794872\n",
      "7033 1.0\n",
      "7040 1.0\n",
      "7041 1.0\n",
      "7042 0.9309895833333334\n",
      "7046 1.0\n",
      "7047 1.0\n",
      "7050 1.0\n",
      "7054 1.0\n",
      "7057 1.0\n",
      "7061 1.0\n",
      "7068 1.0\n",
      "7071 1.0\n",
      "7072 1.0\n",
      "7077 1.0\n",
      "7085 1.0\n",
      "7087 1.0\n",
      "7092 0.9635416666666666\n",
      "7093 0.9140625\n",
      "7094 1.0\n",
      "7102 1.0\n",
      "7112 1.0\n",
      "7113 1.0\n",
      "7114 1.0\n",
      "7118 1.0\n",
      "7126 1.0\n",
      "7128 0.915719696969697\n",
      "7129 1.0\n",
      "7130 0.9427083333333334\n",
      "7135 1.0\n",
      "7136 1.0\n",
      "7139 0.9186197916666666\n",
      "7141 1.0\n",
      "7144 1.0\n",
      "7145 1.0\n",
      "7150 1.0\n",
      "7153 1.0\n",
      "7159 1.0\n",
      "7161 1.0\n",
      "7162 1.0\n",
      "7167 1.0\n",
      "7168 1.0\n",
      "7181 1.0\n",
      "7182 1.0\n",
      "7185 1.0\n",
      "7186 1.0\n",
      "7195 1.0\n",
      "7198 1.0\n",
      "7199 1.0\n",
      "7201 1.0\n",
      "7208 1.0\n",
      "7209 1.0\n",
      "7211 1.0\n",
      "7219 0.9296875\n",
      "7223 1.0\n",
      "7224 1.0\n",
      "7235 0.9921875\n",
      "7236 1.0\n",
      "7239 1.0\n",
      "7242 1.0\n",
      "7247 0.962071718931475\n",
      "7251 1.0\n",
      "7253 0.962071718931475\n",
      "7254 1.0\n",
      "7257 1.0\n",
      "7260 0.9632932692307692\n",
      "7268 0.9830013736263736\n",
      "7274 1.0\n",
      "7278 1.0\n",
      "7286 1.0\n",
      "7296 1.0\n",
      "7297 1.0\n",
      "7300 1.0\n",
      "7304 1.0\n",
      "7317 1.0\n",
      "7325 1.0\n",
      "7327 1.0\n",
      "7333 1.0\n",
      "7336 1.0\n",
      "7338 1.0\n",
      "7340 1.0\n",
      "7341 1.0\n",
      "7342 1.0\n",
      "7343 1.0\n",
      "7344 1.0\n",
      "7348 1.0\n",
      "7352 1.0\n",
      "7355 1.0\n",
      "7358 1.0\n",
      "7359 1.0\n",
      "7361 1.0\n",
      "7364 1.0\n",
      "7366 1.0\n",
      "7367 1.0\n",
      "7369 1.0\n",
      "7374 0.96875\n",
      "7380 1.0\n",
      "7382 1.0\n",
      "7383 0.9696691176470589\n",
      "7384 1.0\n",
      "7385 1.0\n",
      "7386 1.0\n",
      "7391 1.0\n",
      "7392 1.0\n",
      "7396 1.0\n",
      "7410 0.9375\n",
      "7414 1.0\n",
      "7419 1.0\n",
      "7420 1.0\n",
      "7424 1.0\n",
      "7429 0.9806547619047619\n",
      "7437 0.953125\n",
      "7438 0.9765625\n",
      "7441 0.9642857142857143\n",
      "7442 0.9541666666666667\n",
      "7443 1.0\n",
      "7444 1.0\n",
      "7448 1.0\n",
      "7450 1.0\n",
      "7451 1.0\n",
      "7453 1.0\n",
      "7455 1.0\n",
      "7461 1.0\n",
      "7462 1.0\n",
      "7469 1.0\n",
      "7474 0.96875\n",
      "7481 1.0\n",
      "7483 1.0\n",
      "7485 0.9642857142857143\n",
      "7486 1.0\n",
      "7488 0.9588815789473685\n",
      "7493 1.0\n",
      "7500 1.0\n",
      "7501 1.0\n",
      "7502 1.0\n",
      "7507 0.9583333333333334\n",
      "7514 0.9337121212121212\n",
      "7520 1.0\n",
      "7522 1.0\n",
      "7524 0.9375\n",
      "7529 0.959280303030303\n",
      "7534 1.0\n",
      "7535 1.0\n",
      "7539 1.0\n",
      "7548 1.0\n",
      "7549 1.0\n",
      "7550 1.0\n",
      "7553 1.0\n",
      "7556 0.9830013736263736\n",
      "7557 1.0\n",
      "7558 1.0\n",
      "7569 1.0\n",
      "7571 1.0\n",
      "7576 1.0\n",
      "7577 0.9801377118644068\n",
      "7579 1.0\n",
      "7581 1.0\n",
      "7582 1.0\n",
      "7589 1.0\n",
      "7590 1.0\n",
      "7591 1.0\n",
      "7594 0.9801377118644068\n",
      "7598 1.0\n",
      "7599 1.0\n",
      "7607 1.0\n",
      "7611 1.0\n",
      "7613 1.0\n",
      "7617 1.0\n",
      "7619 1.0\n",
      "7620 1.0\n",
      "7621 1.0\n",
      "7622 1.0\n",
      "7625 1.0\n",
      "7626 1.0\n",
      "7627 1.0\n",
      "7631 1.0\n",
      "7636 1.0\n",
      "7641 1.0\n",
      "7642 0.9296875\n",
      "7645 1.0\n",
      "7646 0.9791666666666666\n",
      "7654 0.96875\n",
      "7656 1.0\n",
      "7658 1.0\n",
      "7667 1.0\n",
      "7669 1.0\n",
      "7675 0.9754901960784313\n",
      "7679 1.0\n",
      "7680 1.0\n",
      "7681 1.0\n",
      "7682 1.0\n",
      "7683 0.9505208333333334\n",
      "7686 1.0\n",
      "7689 0.9583333333333334\n",
      "7692 1.0\n",
      "7698 0.9765625\n",
      "7702 1.0\n",
      "7704 1.0\n",
      "7705 1.0\n",
      "7710 1.0\n",
      "7717 1.0\n",
      "7720 1.0\n",
      "7722 1.0\n",
      "7730 1.0\n",
      "7732 1.0\n",
      "7735 1.0\n",
      "7742 1.0\n",
      "7745 1.0\n",
      "7748 1.0\n",
      "7749 1.0\n",
      "7754 0.8828125\n",
      "7755 1.0\n",
      "7759 1.0\n",
      "7761 1.0\n",
      "7767 0.9553571428571429\n",
      "7768 1.0\n",
      "7777 1.0\n",
      "7784 1.0\n",
      "7791 0.9241071428571429\n",
      "7793 0.9895833333333334\n",
      "7798 1.0\n",
      "7799 1.0\n",
      "7804 1.0\n",
      "7806 1.0\n",
      "7808 0.9666666666666667\n",
      "7816 0.9453125\n",
      "7819 1.0\n",
      "7826 1.0\n",
      "7827 1.0\n",
      "7829 1.0\n",
      "7830 0.9793198529411765\n",
      "7833 1.0\n",
      "7844 1.0\n",
      "7848 1.0\n",
      "7852 1.0\n",
      "7853 1.0\n",
      "7856 0.98046875\n",
      "7857 1.0\n",
      "7860 0.93359375\n",
      "7862 1.0\n",
      "7864 1.0\n",
      "7867 1.0\n",
      "7871 1.0\n",
      "7874 1.0\n",
      "7880 1.0\n",
      "7884 1.0\n",
      "7885 1.0\n",
      "7887 1.0\n",
      "7893 1.0\n",
      "7899 1.0\n",
      "7902 1.0\n",
      "7907 1.0\n",
      "7910 1.0\n",
      "7912 1.0\n",
      "7915 1.0\n",
      "7916 1.0\n",
      "7924 0.9140625\n",
      "7925 1.0\n",
      "7926 1.0\n",
      "7927 1.0\n",
      "7930 1.0\n",
      "7934 1.0\n",
      "7942 1.0\n",
      "7944 1.0\n",
      "7947 1.0\n",
      "7949 1.0\n",
      "7950 0.9559294871794872\n",
      "7958 0.9895833333333334\n",
      "7959 1.0\n",
      "7964 1.0\n",
      "7966 1.0\n",
      "7969 1.0\n",
      "7970 1.0\n",
      "7979 1.0\n",
      "7981 1.0\n",
      "7983 0.9799107142857143\n",
      "7987 0.9806547619047619\n",
      "7993 1.0\n",
      "8000 1.0\n",
      "8002 1.0\n",
      "8003 1.0\n",
      "8009 1.0\n",
      "8010 1.0\n",
      "8015 1.0\n",
      "8018 1.0\n",
      "8020 1.0\n",
      "8022 1.0\n",
      "8031 1.0\n",
      "8032 1.0\n",
      "8037 1.0\n",
      "8039 1.0\n",
      "8040 1.0\n",
      "8041 1.0\n",
      "8045 0.9296875\n",
      "8046 1.0\n",
      "8047 1.0\n",
      "8049 0.9754901960784313\n",
      "8053 1.0\n",
      "8068 1.0\n",
      "8069 1.0\n",
      "8070 1.0\n",
      "8082 1.0\n",
      "8083 1.0\n",
      "8085 1.0\n",
      "8086 0.9583333333333334\n",
      "8091 1.0\n",
      "8094 1.0\n",
      "8096 1.0\n",
      "8097 1.0\n",
      "8098 0.984375\n",
      "8104 0.9739583333333334\n",
      "8106 1.0\n",
      "8108 1.0\n",
      "8112 0.9793198529411765\n",
      "8121 1.0\n",
      "8132 1.0\n",
      "8143 1.0\n",
      "8145 1.0\n",
      "8146 1.0\n",
      "8151 1.0\n",
      "8153 0.9575892857142857\n",
      "8159 0.9572458791208791\n",
      "8160 1.0\n",
      "8164 1.0\n",
      "8166 1.0\n",
      "8171 1.0\n",
      "8173 1.0\n",
      "8174 1.0\n",
      "8175 1.0\n",
      "8177 1.0\n",
      "8182 1.0\n",
      "8197 1.0\n",
      "8200 1.0\n",
      "8201 1.0\n",
      "8204 1.0\n",
      "8213 1.0\n",
      "8216 1.0\n",
      "8218 1.0\n",
      "8223 1.0\n",
      "8225 1.0\n",
      "8226 1.0\n",
      "8227 1.0\n",
      "8229 1.0\n",
      "8232 1.0\n",
      "8236 1.0\n",
      "8237 0.962071718931475\n",
      "8249 1.0\n",
      "8251 1.0\n",
      "8255 1.0\n",
      "8256 1.0\n",
      "8257 1.0\n",
      "8258 1.0\n",
      "8260 0.9754901960784313\n",
      "8261 0.9522569444444444\n",
      "8267 1.0\n",
      "8268 1.0\n",
      "8270 0.98046875\n",
      "8271 0.9793198529411765\n",
      "8273 1.0\n",
      "8278 1.0\n",
      "8279 0.9422679227941176\n",
      "8289 0.9427083333333334\n",
      "8295 1.0\n",
      "8309 1.0\n",
      "8314 1.0\n",
      "8316 1.0\n",
      "8317 0.9765625\n",
      "8318 1.0\n",
      "8319 1.0\n",
      "8321 1.0\n",
      "8327 1.0\n",
      "8333 1.0\n",
      "8341 1.0\n",
      "8347 1.0\n",
      "8349 1.0\n",
      "8351 1.0\n",
      "8355 0.9375\n",
      "8357 0.9739583333333334\n",
      "8359 1.0\n",
      "8361 0.9583333333333334\n",
      "8364 1.0\n",
      "8368 1.0\n",
      "8370 1.0\n",
      "8371 1.0\n",
      "8385 1.0\n",
      "8388 1.0\n",
      "8395 1.0\n",
      "8398 1.0\n",
      "8417 1.0\n",
      "8419 1.0\n",
      "8421 1.0\n",
      "8427 1.0\n",
      "8428 1.0\n",
      "8430 1.0\n",
      "8441 1.0\n",
      "8444 1.0\n",
      "8446 1.0\n",
      "8455 1.0\n",
      "8457 1.0\n",
      "8461 1.0\n",
      "8462 1.0\n",
      "8466 1.0\n",
      "8469 1.0\n",
      "8470 1.0\n",
      "8472 1.0\n",
      "8476 1.0\n",
      "8477 1.0\n",
      "8480 1.0\n",
      "8482 0.9140625\n",
      "8488 1.0\n",
      "8493 1.0\n",
      "8494 1.0\n",
      "8501 1.0\n",
      "8503 0.962071718931475\n",
      "8507 1.0\n",
      "8511 1.0\n",
      "8513 1.0\n",
      "8514 1.0\n",
      "8517 1.0\n",
      "8518 0.9765625\n",
      "8520 1.0\n",
      "8526 1.0\n",
      "8527 1.0\n",
      "8529 1.0\n",
      "8532 1.0\n",
      "8533 1.0\n",
      "8538 1.0\n",
      "8543 0.9583333333333334\n",
      "8544 0.9309895833333334\n",
      "8551 0.953125\n",
      "8552 1.0\n",
      "8553 1.0\n",
      "8555 1.0\n",
      "8559 1.0\n",
      "8560 1.0\n",
      "8562 1.0\n",
      "8566 0.9791666666666666\n",
      "8568 1.0\n",
      "8569 1.0\n",
      "8573 1.0\n",
      "8582 1.0\n",
      "8585 1.0\n",
      "8589 1.0\n",
      "8593 1.0\n",
      "8595 1.0\n",
      "8596 0.97265625\n",
      "8602 1.0\n",
      "8606 1.0\n",
      "8607 0.9453125\n",
      "8608 1.0\n",
      "8610 1.0\n",
      "8611 1.0\n",
      "8613 1.0\n",
      "8618 1.0\n",
      "8620 1.0\n",
      "8623 1.0\n",
      "8624 1.0\n",
      "8627 1.0\n",
      "8629 1.0\n",
      "8631 1.0\n",
      "8634 0.921875\n",
      "8635 1.0\n",
      "8636 0.9270833333333334\n",
      "8637 1.0\n",
      "8639 1.0\n",
      "8641 1.0\n",
      "8645 1.0\n",
      "8646 1.0\n",
      "8650 1.0\n",
      "8655 1.0\n",
      "8659 1.0\n",
      "8666 1.0\n",
      "8667 0.9642857142857143\n",
      "8672 1.0\n",
      "8675 1.0\n",
      "8677 0.9625\n",
      "8679 1.0\n",
      "8681 0.9765625\n",
      "8686 1.0\n",
      "8688 1.0\n",
      "8690 1.0\n",
      "8696 1.0\n",
      "8701 1.0\n",
      "8702 0.9296875\n",
      "8703 1.0\n",
      "8707 1.0\n",
      "8710 1.0\n",
      "8715 1.0\n",
      "8718 1.0\n",
      "8725 0.98046875\n",
      "8730 1.0\n",
      "8733 1.0\n",
      "8738 1.0\n",
      "8744 1.0\n",
      "8745 0.9609375\n",
      "8746 1.0\n",
      "8748 1.0\n",
      "8752 1.0\n",
      "8758 1.0\n",
      "8759 1.0\n",
      "8760 1.0\n",
      "8769 1.0\n",
      "8770 1.0\n",
      "8771 1.0\n",
      "8775 1.0\n",
      "8778 1.0\n",
      "8784 0.9466145833333334\n",
      "8789 1.0\n",
      "8791 1.0\n",
      "8798 1.0\n",
      "8799 1.0\n",
      "8800 0.984375\n",
      "8801 1.0\n",
      "8802 1.0\n",
      "8803 1.0\n",
      "8804 1.0\n",
      "8806 1.0\n",
      "8814 1.0\n",
      "8816 1.0\n",
      "8820 1.0\n",
      "8824 1.0\n",
      "8826 1.0\n",
      "8828 1.0\n",
      "8833 1.0\n",
      "8840 1.0\n",
      "8842 1.0\n",
      "8843 1.0\n",
      "8847 1.0\n",
      "8852 1.0\n",
      "8853 1.0\n",
      "8863 1.0\n",
      "8866 1.0\n",
      "8867 1.0\n",
      "8869 1.0\n",
      "8870 1.0\n",
      "8879 1.0\n",
      "8883 1.0\n",
      "8884 1.0\n",
      "8885 1.0\n",
      "8886 1.0\n",
      "8889 1.0\n",
      "8891 1.0\n",
      "8892 1.0\n",
      "8893 1.0\n",
      "8895 1.0\n",
      "8897 1.0\n",
      "8898 1.0\n",
      "8902 1.0\n",
      "8905 1.0\n",
      "8907 1.0\n",
      "8910 1.0\n",
      "8917 1.0\n",
      "8923 1.0\n",
      "8927 1.0\n",
      "8928 1.0\n",
      "8930 1.0\n",
      "8931 1.0\n",
      "8937 0.98046875\n",
      "8939 1.0\n",
      "8944 0.9479166666666666\n",
      "8947 1.0\n",
      "8950 1.0\n",
      "8957 1.0\n",
      "8960 1.0\n",
      "8964 1.0\n",
      "8967 1.0\n",
      "8968 1.0\n",
      "8971 1.0\n",
      "8973 1.0\n",
      "8975 1.0\n",
      "8984 1.0\n",
      "8985 0.9466145833333334\n",
      "8989 1.0\n",
      "8999 1.0\n",
      "9000 1.0\n",
      "9004 0.9583333333333334\n",
      "9007 1.0\n",
      "9008 1.0\n",
      "9009 0.9829545454545454\n",
      "9010 1.0\n",
      "9011 0.921875\n",
      "9018 1.0\n",
      "9019 1.0\n",
      "9021 1.0\n",
      "9023 1.0\n",
      "9025 0.96875\n",
      "9028 1.0\n",
      "9030 1.0\n",
      "9031 1.0\n",
      "9032 1.0\n",
      "9048 1.0\n",
      "9049 1.0\n",
      "9051 1.0\n",
      "9052 0.9479166666666666\n",
      "9058 1.0\n",
      "9062 1.0\n",
      "9074 1.0\n",
      "9075 1.0\n",
      "9077 1.0\n",
      "9083 1.0\n",
      "9090 1.0\n",
      "9098 1.0\n",
      "9106 1.0\n",
      "9111 1.0\n",
      "9112 1.0\n",
      "9115 1.0\n",
      "9118 1.0\n",
      "9123 1.0\n",
      "9135 1.0\n",
      "9140 1.0\n",
      "9143 0.9375\n",
      "9144 1.0\n",
      "9151 1.0\n",
      "9154 0.9517463235294118\n",
      "9155 1.0\n",
      "9158 1.0\n",
      "9159 1.0\n",
      "9163 1.0\n",
      "9165 1.0\n",
      "9167 1.0\n",
      "9168 1.0\n",
      "9171 0.96875\n",
      "9177 0.9401041666666666\n",
      "9179 1.0\n",
      "9182 0.9553571428571429\n",
      "9187 1.0\n",
      "9188 1.0\n",
      "9190 0.90625\n",
      "9201 1.0\n",
      "9202 1.0\n",
      "9205 1.0\n",
      "9208 0.9713541666666666\n",
      "9210 1.0\n",
      "9212 1.0\n",
      "9225 1.0\n",
      "9228 1.0\n",
      "9241 0.95703125\n",
      "9243 1.0\n",
      "9246 1.0\n",
      "9251 1.0\n",
      "9252 1.0\n",
      "9256 1.0\n",
      "9262 1.0\n",
      "9265 1.0\n",
      "9269 0.9638097426470589\n",
      "9271 1.0\n",
      "9273 1.0\n",
      "9275 1.0\n",
      "9277 1.0\n",
      "9279 1.0\n",
      "9283 1.0\n",
      "9287 1.0\n",
      "9294 1.0\n",
      "9296 1.0\n",
      "9299 1.0\n",
      "9311 1.0\n",
      "9319 1.0\n",
      "9321 1.0\n",
      "9330 1.0\n",
      "9331 1.0\n",
      "9332 1.0\n",
      "9338 1.0\n",
      "9342 1.0\n",
      "9344 1.0\n",
      "9347 1.0\n",
      "9355 0.9453125\n",
      "9359 1.0\n",
      "9361 1.0\n",
      "9362 0.96875\n",
      "9364 1.0\n",
      "9366 1.0\n",
      "9370 1.0\n",
      "9378 1.0\n",
      "9384 1.0\n",
      "9393 1.0\n",
      "9394 1.0\n",
      "9406 0.9337121212121212\n",
      "9409 1.0\n",
      "9411 1.0\n",
      "9412 1.0\n",
      "9419 1.0\n",
      "9425 1.0\n",
      "9428 1.0\n",
      "9429 1.0\n",
      "9430 1.0\n",
      "9434 1.0\n",
      "9439 1.0\n",
      "9449 1.0\n",
      "9451 1.0\n",
      "9452 1.0\n",
      "9460 1.0\n",
      "9461 0.9526041666666667\n",
      "9465 1.0\n",
      "9477 1.0\n",
      "9479 1.0\n",
      "9480 1.0\n",
      "9481 1.0\n",
      "9483 1.0\n",
      "9486 1.0\n",
      "9489 1.0\n",
      "9490 0.9783653846153846\n",
      "9497 1.0\n",
      "9499 1.0\n",
      "9503 1.0\n",
      "9507 1.0\n",
      "9508 1.0\n",
      "9510 1.0\n",
      "9512 1.0\n",
      "9515 1.0\n",
      "9516 1.0\n",
      "9520 1.0\n",
      "9522 1.0\n",
      "9527 1.0\n",
      "9528 1.0\n",
      "9531 1.0\n",
      "9532 1.0\n",
      "9537 1.0\n",
      "9539 1.0\n",
      "9542 1.0\n",
      "9544 1.0\n",
      "9547 1.0\n",
      "9548 1.0\n",
      "9551 1.0\n",
      "9554 1.0\n",
      "9557 1.0\n",
      "9559 1.0\n",
      "9563 1.0\n",
      "9570 1.0\n",
      "9571 1.0\n",
      "9575 0.9453125\n",
      "9580 1.0\n",
      "9583 1.0\n",
      "9584 1.0\n",
      "9585 1.0\n",
      "9588 1.0\n",
      "9590 0.9625\n",
      "9594 1.0\n",
      "9597 1.0\n",
      "9598 1.0\n",
      "9606 1.0\n",
      "9609 1.0\n",
      "9612 1.0\n",
      "9619 1.0\n",
      "9620 1.0\n",
      "9621 1.0\n",
      "9629 0.9453125\n",
      "9631 1.0\n",
      "9632 1.0\n",
      "9635 1.0\n",
      "9645 1.0\n",
      "9651 1.0\n",
      "9653 1.0\n",
      "9654 1.0\n",
      "9656 1.0\n",
      "9659 0.9421875\n",
      "9666 1.0\n",
      "9667 1.0\n",
      "9669 1.0\n",
      "9671 1.0\n",
      "9679 1.0\n",
      "9683 1.0\n",
      "9684 1.0\n",
      "9686 0.9609375\n",
      "9688 1.0\n",
      "9691 1.0\n",
      "9693 0.9375\n",
      "9699 1.0\n",
      "9705 1.0\n",
      "9706 1.0\n",
      "9708 1.0\n",
      "9710 1.0\n",
      "9711 1.0\n",
      "9713 0.9806547619047619\n",
      "9715 1.0\n",
      "9718 1.0\n",
      "9720 1.0\n",
      "9721 1.0\n",
      "9725 1.0\n",
      "9729 0.96875\n",
      "9731 1.0\n",
      "9732 1.0\n",
      "9736 1.0\n",
      "9737 0.9449404761904762\n",
      "9744 1.0\n",
      "9748 0.9495192307692307\n",
      "9754 1.0\n",
      "9755 1.0\n",
      "9756 1.0\n",
      "9761 1.0\n",
      "9768 0.96875\n",
      "9769 1.0\n",
      "9773 0.9466145833333334\n",
      "9775 0.828125\n",
      "9782 1.0\n",
      "9800 1.0\n",
      "9801 0.98046875\n",
      "9804 1.0\n",
      "9806 1.0\n",
      "9807 1.0\n",
      "9808 1.0\n",
      "9809 1.0\n",
      "9816 1.0\n",
      "9817 1.0\n",
      "9818 0.9765625\n",
      "9820 1.0\n",
      "9829 1.0\n",
      "9831 1.0\n",
      "9832 1.0\n",
      "9836 1.0\n",
      "9842 1.0\n",
      "9844 0.9609375\n",
      "9846 1.0\n",
      "9849 0.9652300824175825\n",
      "9851 1.0\n",
      "9857 1.0\n",
      "9859 0.9522569444444444\n",
      "9863 1.0\n",
      "9864 1.0\n",
      "9870 0.9830013736263736\n",
      "9877 1.0\n",
      "9883 1.0\n",
      "9886 1.0\n",
      "9891 1.0\n",
      "9896 1.0\n",
      "9897 0.9375\n",
      "9900 1.0\n",
      "9906 1.0\n",
      "9908 0.9652300824175825\n",
      "9910 1.0\n",
      "9914 1.0\n",
      "9916 0.9437872023809524\n",
      "9922 1.0\n",
      "9925 1.0\n",
      "9926 0.9572458791208791\n",
      "9929 1.0\n",
      "9931 0.8828125\n",
      "9932 1.0\n",
      "9937 1.0\n",
      "9938 1.0\n",
      "9939 1.0\n",
      "9941 0.9558035714285714\n",
      "9943 0.9632932692307692\n",
      "9944 1.0\n",
      "9950 1.0\n",
      "9951 1.0\n",
      "9960 1.0\n",
      "9963 1.0\n",
      "9964 1.0\n",
      "9965 1.0\n",
      "9970 1.0\n",
      "9972 1.0\n",
      "9975 1.0\n",
      "9979 0.9541666666666667\n",
      "9992 1.0\n",
      "9995 1.0\n",
      "9996 1.0\n",
      "9997 1.0\n",
      "10001 1.0\n",
      "10016 1.0\n",
      "10019 1.0\n",
      "10025 1.0\n",
      "10028 1.0\n",
      "10031 0.9635416666666666\n",
      "10035 1.0\n",
      "10041 1.0\n",
      "10043 1.0\n",
      "10044 1.0\n",
      "10046 1.0\n",
      "10061 1.0\n",
      "10062 1.0\n",
      "10063 1.0\n",
      "10065 1.0\n",
      "10067 1.0\n",
      "10069 1.0\n",
      "10070 1.0\n",
      "10078 1.0\n",
      "10086 0.9241071428571429\n",
      "10098 1.0\n",
      "10101 0.9583333333333334\n",
      "10105 1.0\n",
      "10106 1.0\n",
      "10108 1.0\n",
      "10110 1.0\n",
      "10112 1.0\n",
      "10113 1.0\n",
      "10114 1.0\n",
      "10123 1.0\n",
      "10132 1.0\n",
      "10138 1.0\n",
      "10139 1.0\n",
      "10141 1.0\n",
      "10142 1.0\n",
      "10152 0.9862132352941176\n",
      "10157 1.0\n",
      "10159 0.9484375\n",
      "10160 1.0\n",
      "10162 1.0\n",
      "10166 0.9517463235294118\n",
      "10177 1.0\n",
      "10178 1.0\n",
      "10179 0.95\n",
      "10181 1.0\n",
      "10185 1.0\n",
      "10189 1.0\n",
      "10190 0.9895833333333334\n",
      "10191 1.0\n",
      "10193 1.0\n",
      "10198 1.0\n",
      "10199 1.0\n",
      "10202 0.9635416666666666\n",
      "10206 1.0\n",
      "10211 0.9609375\n",
      "10212 1.0\n",
      "10217 1.0\n",
      "10220 1.0\n",
      "10222 0.9375\n",
      "10226 1.0\n",
      "10230 1.0\n",
      "10232 1.0\n",
      "10235 1.0\n",
      "10239 1.0\n",
      "10242 0.90625\n",
      "10246 1.0\n",
      "10248 1.0\n",
      "10250 1.0\n",
      "10256 1.0\n",
      "10262 1.0\n",
      "10269 0.9666666666666667\n",
      "10272 1.0\n",
      "10273 0.9572458791208791\n",
      "10275 1.0\n",
      "10276 1.0\n",
      "10279 0.984375\n",
      "10280 1.0\n",
      "10287 0.9609375\n",
      "10289 1.0\n",
      "10290 0.9643342391304348\n",
      "10291 1.0\n",
      "10293 0.953125\n",
      "10296 1.0\n",
      "10298 1.0\n",
      "10302 0.9296875\n",
      "10307 1.0\n",
      "10315 1.0\n",
      "10321 1.0\n",
      "10322 0.9765625\n",
      "10323 1.0\n",
      "10325 1.0\n",
      "10329 0.9609375\n",
      "10331 1.0\n",
      "10342 1.0\n",
      "10344 1.0\n",
      "10345 1.0\n",
      "10347 0.9296875\n",
      "10351 1.0\n",
      "10357 1.0\n",
      "10372 1.0\n",
      "10373 1.0\n",
      "10386 1.0\n",
      "10390 1.0\n",
      "10394 1.0\n",
      "10397 1.0\n",
      "10402 1.0\n",
      "10403 0.9572458791208791\n",
      "10407 0.9375\n",
      "10409 1.0\n",
      "10410 1.0\n",
      "10411 1.0\n",
      "10414 0.9609375\n",
      "10417 1.0\n",
      "10419 1.0\n",
      "10422 0.984375\n",
      "10423 1.0\n",
      "10427 1.0\n",
      "10431 0.975\n",
      "10436 1.0\n",
      "10439 1.0\n",
      "10440 1.0\n",
      "10448 1.0\n",
      "10449 1.0\n",
      "10450 1.0\n",
      "10457 1.0\n",
      "10459 1.0\n",
      "10462 1.0\n",
      "10464 1.0\n",
      "10467 1.0\n",
      "10472 1.0\n",
      "10474 0.9437872023809524\n",
      "10477 1.0\n",
      "10481 1.0\n",
      "10482 1.0\n",
      "10484 0.9497767857142857\n",
      "10490 0.859375\n",
      "10504 1.0\n",
      "10507 1.0\n",
      "10511 0.9553571428571429\n",
      "10513 1.0\n",
      "10515 1.0\n",
      "10516 1.0\n",
      "10519 1.0\n",
      "10522 1.0\n",
      "10527 0.9598214285714286\n",
      "10528 1.0\n",
      "10530 0.9638097426470589\n",
      "10539 1.0\n",
      "10540 0.9453125\n",
      "10543 1.0\n",
      "10545 1.0\n",
      "10550 1.0\n",
      "10552 1.0\n",
      "10556 1.0\n",
      "10565 1.0\n",
      "10570 1.0\n",
      "10572 1.0\n",
      "10577 1.0\n",
      "10579 0.9739583333333334\n",
      "10584 1.0\n",
      "10585 1.0\n",
      "10586 1.0\n",
      "10602 1.0\n",
      "10604 1.0\n",
      "10615 1.0\n",
      "10616 1.0\n",
      "10622 1.0\n",
      "10625 1.0\n",
      "10631 1.0\n",
      "10632 1.0\n",
      "10636 0.8671875\n",
      "10638 1.0\n",
      "10642 1.0\n",
      "10645 1.0\n",
      "10648 1.0\n",
      "10651 1.0\n",
      "10655 1.0\n",
      "10657 0.9583333333333334\n",
      "10659 1.0\n",
      "10666 1.0\n",
      "10669 1.0\n",
      "10676 1.0\n",
      "10679 1.0\n",
      "10686 1.0\n",
      "10688 1.0\n",
      "10689 0.9296875\n",
      "10699 1.0\n",
      "10700 1.0\n",
      "10703 1.0\n",
      "10704 1.0\n",
      "10708 0.9739583333333334\n",
      "10711 1.0\n",
      "10712 1.0\n",
      "10718 1.0\n",
      "10719 1.0\n",
      "10721 0.953125\n",
      "10722 0.9609375\n",
      "10731 0.9453125\n",
      "10733 1.0\n",
      "10735 0.96484375\n",
      "10739 1.0\n",
      "10740 1.0\n",
      "10741 1.0\n",
      "10746 1.0\n",
      "10748 1.0\n",
      "10751 1.0\n",
      "10756 1.0\n",
      "10758 1.0\n",
      "10759 0.9416666666666667\n",
      "10761 1.0\n",
      "10772 1.0\n",
      "10776 1.0\n",
      "10778 1.0\n",
      "10783 1.0\n",
      "10786 1.0\n",
      "10800 0.9857954545454546\n",
      "10804 0.953125\n",
      "10807 1.0\n",
      "10809 1.0\n",
      "10810 1.0\n",
      "10811 1.0\n",
      "10814 1.0\n",
      "10817 0.9375\n",
      "10821 1.0\n",
      "10823 0.9140625\n",
      "10824 0.9799107142857143\n",
      "10825 1.0\n",
      "10827 1.0\n",
      "10830 1.0\n",
      "10837 1.0\n",
      "10844 1.0\n",
      "10845 0.96875\n",
      "10848 1.0\n",
      "10854 0.9635416666666666\n",
      "10857 1.0\n",
      "10859 1.0\n",
      "10860 1.0\n",
      "10872 1.0\n",
      "10874 1.0\n",
      "10877 1.0\n",
      "10882 1.0\n",
      "10884 1.0\n",
      "10885 0.9375\n",
      "10888 1.0\n",
      "10890 1.0\n",
      "10892 1.0\n",
      "10894 1.0\n",
      "10898 1.0\n",
      "10900 1.0\n",
      "10901 0.9453125\n",
      "10904 1.0\n",
      "10905 1.0\n",
      "10908 1.0\n",
      "10911 1.0\n",
      "10912 1.0\n",
      "10914 0.9421875\n",
      "10919 1.0\n",
      "10920 1.0\n",
      "10922 1.0\n",
      "10926 1.0\n",
      "10929 1.0\n",
      "10936 1.0\n",
      "10938 1.0\n",
      "10939 1.0\n",
      "10942 1.0\n",
      "10950 1.0\n",
      "10951 1.0\n",
      "10953 1.0\n",
      "10963 1.0\n",
      "10966 0.9829545454545454\n",
      "10967 1.0\n",
      "10973 1.0\n",
      "10975 0.953125\n",
      "10976 1.0\n",
      "10978 1.0\n",
      "10979 1.0\n",
      "10981 1.0\n",
      "10983 1.0\n",
      "10990 1.0\n",
      "10992 1.0\n",
      "10994 1.0\n",
      "10996 1.0\n",
      "11000 1.0\n",
      "11001 1.0\n",
      "11004 1.0\n",
      "11006 1.0\n",
      "11008 1.0\n",
      "11012 1.0\n",
      "11023 1.0\n",
      "11029 1.0\n",
      "11035 1.0\n",
      "11039 1.0\n",
      "11040 0.9453125\n",
      "11048 0.9337121212121212\n",
      "11049 0.9857954545454546\n",
      "11055 1.0\n",
      "11056 1.0\n",
      "11061 1.0\n",
      "11065 0.9609375\n",
      "11068 1.0\n",
      "11071 1.0\n",
      "11073 1.0\n",
      "11074 1.0\n",
      "11075 1.0\n",
      "11076 1.0\n",
      "11081 1.0\n",
      "11084 1.0\n",
      "11085 1.0\n",
      "11088 1.0\n",
      "11089 1.0\n",
      "11092 1.0\n",
      "11093 1.0\n",
      "11100 1.0\n",
      "11101 0.9375\n",
      "11107 1.0\n",
      "11109 0.9578125\n",
      "11113 1.0\n",
      "11123 1.0\n",
      "11124 1.0\n",
      "11125 0.9830013736263736\n",
      "11126 0.9466145833333334\n",
      "11137 1.0\n",
      "11138 1.0\n",
      "11141 0.9739583333333334\n",
      "11142 1.0\n",
      "11143 1.0\n",
      "11146 1.0\n",
      "11148 1.0\n",
      "11149 1.0\n",
      "11150 1.0\n",
      "11153 1.0\n",
      "11154 1.0\n",
      "11157 1.0\n",
      "11159 1.0\n",
      "11161 0.953125\n",
      "11163 1.0\n",
      "11170 1.0\n",
      "11171 1.0\n",
      "11172 0.9296875\n",
      "11173 1.0\n",
      "11183 1.0\n",
      "11186 1.0\n",
      "11187 1.0\n",
      "11189 1.0\n",
      "11194 0.9675324675324676\n",
      "11199 1.0\n",
      "11200 1.0\n",
      "11206 1.0\n",
      "11208 0.9729567307692307\n",
      "11210 1.0\n",
      "11213 0.9415922619047619\n",
      "11214 1.0\n",
      "11217 1.0\n",
      "11225 1.0\n",
      "11226 1.0\n",
      "11227 1.0\n",
      "11228 1.0\n",
      "11234 0.9801377118644068\n",
      "11235 1.0\n",
      "11247 1.0\n",
      "11253 0.962071718931475\n",
      "11262 0.953125\n",
      "11266 1.0\n",
      "11267 1.0\n",
      "11269 1.0\n",
      "11271 0.953125\n",
      "11272 0.925\n",
      "11282 0.962071718931475\n",
      "11286 1.0\n",
      "11291 1.0\n",
      "11292 1.0\n",
      "11297 1.0\n",
      "11299 1.0\n",
      "11302 1.0\n",
      "11308 1.0\n",
      "11309 0.9453125\n",
      "11311 1.0\n",
      "11313 1.0\n",
      "11314 1.0\n",
      "11317 1.0\n",
      "11320 0.9625\n",
      "11323 1.0\n",
      "11324 1.0\n",
      "11325 1.0\n",
      "11327 0.9651041666666667\n",
      "11329 0.958984375\n",
      "11330 0.9453125\n",
      "11331 1.0\n",
      "11333 1.0\n",
      "11334 0.9801377118644068\n",
      "11342 1.0\n",
      "11343 0.9559294871794872\n",
      "11344 1.0\n",
      "11345 1.0\n",
      "11351 1.0\n",
      "11353 1.0\n",
      "11357 1.0\n",
      "11360 1.0\n",
      "11362 1.0\n",
      "11363 1.0\n",
      "11364 1.0\n",
      "11365 1.0\n",
      "11367 1.0\n",
      "11368 1.0\n",
      "11370 0.9621975806451613\n",
      "11372 1.0\n",
      "11381 1.0\n",
      "11387 1.0\n",
      "11389 1.0\n",
      "11390 1.0\n",
      "11398 1.0\n",
      "11403 1.0\n",
      "11406 1.0\n",
      "11408 1.0\n",
      "11414 0.9754901960784313\n",
      "11416 1.0\n",
      "11418 1.0\n",
      "11419 0.9583333333333334\n",
      "11420 1.0\n",
      "11444 1.0\n",
      "11445 1.0\n",
      "11449 1.0\n",
      "11456 1.0\n",
      "11457 1.0\n",
      "11459 1.0\n",
      "11461 1.0\n",
      "11464 1.0\n",
      "11465 1.0\n",
      "11467 1.0\n",
      "11468 1.0\n",
      "11471 0.962071718931475\n",
      "11473 1.0\n",
      "11477 0.96875\n",
      "11479 1.0\n",
      "11486 1.0\n",
      "11487 1.0\n",
      "11488 1.0\n",
      "11490 1.0\n",
      "11500 1.0\n",
      "11503 1.0\n",
      "11504 1.0\n",
      "11513 1.0\n",
      "11516 1.0\n",
      "11518 1.0\n",
      "11520 1.0\n",
      "11524 1.0\n",
      "11529 0.9505494505494505\n",
      "11530 0.96875\n",
      "11531 1.0\n",
      "11532 1.0\n",
      "11534 1.0\n",
      "11544 1.0\n",
      "11545 1.0\n",
      "11546 1.0\n",
      "11547 0.9495192307692307\n",
      "11548 1.0\n",
      "11555 0.9801377118644068\n",
      "11562 0.9817708333333334\n",
      "11563 1.0\n",
      "11564 1.0\n",
      "11569 1.0\n",
      "11574 1.0\n",
      "11575 1.0\n",
      "11577 1.0\n",
      "11579 1.0\n",
      "11581 1.0\n",
      "11583 1.0\n",
      "11587 1.0\n",
      "11588 1.0\n",
      "11592 1.0\n",
      "11597 1.0\n",
      "11600 1.0\n",
      "11601 0.98046875\n",
      "11602 1.0\n",
      "11603 1.0\n",
      "11605 1.0\n",
      "11612 1.0\n",
      "11616 1.0\n",
      "11617 0.9652300824175825\n",
      "11621 1.0\n",
      "11622 1.0\n",
      "11623 0.9464285714285714\n",
      "11625 1.0\n",
      "11630 1.0\n",
      "11633 1.0\n",
      "11635 1.0\n",
      "11648 0.9296875\n",
      "11650 1.0\n",
      "11654 1.0\n",
      "11660 1.0\n",
      "11661 1.0\n",
      "11665 0.9739583333333334\n",
      "11674 1.0\n",
      "11677 1.0\n",
      "11678 0.9186197916666666\n",
      "11679 1.0\n",
      "11681 1.0\n",
      "11683 1.0\n",
      "11685 1.0\n",
      "11687 1.0\n",
      "11692 0.962071718931475\n",
      "11707 1.0\n",
      "11710 1.0\n",
      "11711 1.0\n",
      "11712 1.0\n",
      "11713 1.0\n",
      "11714 1.0\n",
      "11715 1.0\n",
      "11717 0.9375\n",
      "11718 1.0\n",
      "11719 1.0\n",
      "11722 1.0\n",
      "11724 1.0\n",
      "11728 1.0\n",
      "11731 0.9635416666666666\n",
      "11738 1.0\n",
      "11745 1.0\n",
      "11747 1.0\n",
      "11748 1.0\n",
      "11749 1.0\n",
      "11754 0.9453125\n",
      "11755 1.0\n",
      "11756 1.0\n",
      "11757 1.0\n",
      "11759 0.9422679227941176\n",
      "11760 1.0\n",
      "11762 0.9643342391304348\n",
      "11763 1.0\n",
      "11764 1.0\n",
      "11773 1.0\n",
      "11774 1.0\n",
      "11778 1.0\n",
      "11781 1.0\n",
      "11783 1.0\n",
      "11784 1.0\n",
      "11789 1.0\n",
      "11797 1.0\n",
      "11799 1.0\n",
      "11812 1.0\n",
      "11818 1.0\n",
      "11819 1.0\n",
      "11820 1.0\n",
      "11822 1.0\n",
      "11829 0.96875\n",
      "11836 0.9801377118644068\n",
      "11837 0.9375\n",
      "11838 1.0\n",
      "11841 1.0\n",
      "11843 0.9583333333333334\n",
      "11846 1.0\n",
      "11847 1.0\n",
      "11851 1.0\n",
      "11855 0.9375\n",
      "11856 1.0\n",
      "11863 1.0\n",
      "11868 1.0\n",
      "11869 1.0\n",
      "11871 1.0\n",
      "11890 0.9632932692307692\n",
      "11894 0.9765625\n",
      "11902 1.0\n",
      "11903 0.9241071428571429\n",
      "11910 0.971875\n",
      "11916 1.0\n",
      "11917 0.8828125\n",
      "11919 1.0\n",
      "11923 1.0\n",
      "11930 1.0\n",
      "11940 0.953125\n",
      "11941 1.0\n",
      "11943 1.0\n",
      "11963 1.0\n",
      "11964 1.0\n",
      "11969 1.0\n",
      "11970 1.0\n",
      "11971 1.0\n",
      "11972 1.0\n",
      "11974 1.0\n",
      "11977 1.0\n",
      "11978 1.0\n",
      "11980 1.0\n",
      "11991 1.0\n",
      "11992 1.0\n",
      "11993 1.0\n",
      "11994 1.0\n",
      "11996 1.0\n",
      "12000 1.0\n",
      "12001 1.0\n",
      "12007 1.0\n",
      "12009 1.0\n",
      "12010 1.0\n",
      "12012 1.0\n",
      "12015 1.0\n",
      "12020 1.0\n",
      "12023 1.0\n",
      "12035 1.0\n",
      "12036 1.0\n",
      "12041 1.0\n",
      "12042 1.0\n",
      "12043 0.98046875\n",
      "12044 1.0\n",
      "12046 1.0\n",
      "12048 0.9801377118644068\n",
      "12053 1.0\n",
      "12054 1.0\n",
      "12057 1.0\n",
      "12060 0.96875\n",
      "12067 1.0\n",
      "12068 0.96875\n",
      "12072 1.0\n",
      "12073 1.0\n",
      "12074 1.0\n",
      "12076 0.9613042840375586\n",
      "12078 1.0\n",
      "12085 0.9337121212121212\n",
      "12094 0.9621975806451613\n",
      "12096 1.0\n",
      "12100 1.0\n",
      "12104 1.0\n",
      "12114 1.0\n",
      "12115 1.0\n",
      "12121 1.0\n",
      "12122 1.0\n",
      "12123 0.9583333333333334\n",
      "12128 0.9296875\n",
      "12141 0.984375\n",
      "12143 1.0\n",
      "12147 1.0\n",
      "12148 1.0\n",
      "12154 0.9572458791208791\n",
      "12157 1.0\n",
      "12158 1.0\n",
      "12163 1.0\n",
      "12168 1.0\n",
      "12171 0.962071718931475\n",
      "12179 1.0\n",
      "12181 1.0\n",
      "12185 1.0\n",
      "12187 1.0\n",
      "12196 1.0\n",
      "12198 1.0\n",
      "12201 1.0\n",
      "12202 1.0\n",
      "12205 1.0\n",
      "12209 1.0\n",
      "12211 1.0\n",
      "12213 1.0\n",
      "12215 1.0\n",
      "12218 1.0\n",
      "12225 0.94921875\n",
      "12226 1.0\n",
      "12227 1.0\n",
      "12232 1.0\n",
      "12234 0.9625\n",
      "12241 0.9375\n",
      "12246 1.0\n",
      "12247 1.0\n",
      "12252 1.0\n",
      "12255 1.0\n",
      "12265 1.0\n",
      "12270 1.0\n",
      "12273 1.0\n",
      "12277 1.0\n",
      "12282 1.0\n",
      "12283 1.0\n",
      "12286 1.0\n",
      "12287 1.0\n",
      "12289 1.0\n",
      "12292 1.0\n",
      "12294 0.9479166666666666\n",
      "12296 1.0\n",
      "12301 0.953125\n",
      "12302 1.0\n",
      "12303 1.0\n",
      "12304 1.0\n",
      "12306 1.0\n",
      "12308 1.0\n",
      "12309 1.0\n",
      "12310 1.0\n",
      "12313 1.0\n",
      "12320 0.9453125\n",
      "12329 1.0\n",
      "12330 1.0\n",
      "12338 1.0\n",
      "12340 1.0\n",
      "12343 1.0\n",
      "12345 1.0\n",
      "12346 1.0\n",
      "12348 1.0\n",
      "12351 1.0\n",
      "12352 1.0\n",
      "12356 1.0\n",
      "12358 1.0\n",
      "12361 1.0\n",
      "12366 0.9791666666666666\n",
      "12368 1.0\n",
      "12376 1.0\n",
      "12389 1.0\n",
      "12392 1.0\n",
      "12396 0.9517463235294118\n",
      "12398 0.9583333333333334\n",
      "12400 0.9453125\n",
      "12409 1.0\n",
      "12414 1.0\n",
      "12416 1.0\n",
      "12417 1.0\n",
      "12419 1.0\n",
      "12421 1.0\n",
      "12423 1.0\n",
      "12428 1.0\n",
      "12430 1.0\n",
      "12432 1.0\n",
      "12440 1.0\n",
      "12442 0.9497767857142857\n",
      "12447 1.0\n",
      "12455 1.0\n",
      "12461 1.0\n",
      "12462 1.0\n",
      "12465 1.0\n",
      "12474 1.0\n",
      "12475 0.9140625\n",
      "12482 1.0\n",
      "12491 1.0\n",
      "12493 1.0\n",
      "12508 1.0\n",
      "12509 1.0\n",
      "12511 1.0\n",
      "12515 1.0\n",
      "12522 1.0\n",
      "12529 1.0\n",
      "12530 1.0\n",
      "12531 0.9598214285714286\n",
      "12533 1.0\n",
      "12546 1.0\n",
      "12547 0.9453125\n",
      "12549 1.0\n",
      "12551 1.0\n",
      "12560 1.0\n",
      "12561 1.0\n",
      "12563 1.0\n",
      "12569 1.0\n",
      "12572 1.0\n",
      "12577 1.0\n",
      "12578 0.9857954545454546\n",
      "12581 1.0\n",
      "12595 1.0\n",
      "12597 1.0\n",
      "12599 1.0\n",
      "12604 1.0\n",
      "12605 1.0\n",
      "12609 1.0\n",
      "12610 0.875\n",
      "12621 1.0\n",
      "12622 1.0\n",
      "12627 1.0\n",
      "12628 1.0\n",
      "12632 0.953125\n",
      "12637 0.96875\n",
      "12642 1.0\n",
      "12645 1.0\n",
      "12647 1.0\n",
      "12657 1.0\n",
      "12658 1.0\n",
      "12661 1.0\n",
      "12662 1.0\n",
      "12663 1.0\n",
      "12667 1.0\n",
      "12669 1.0\n",
      "12670 1.0\n",
      "12676 1.0\n",
      "12680 0.953125\n",
      "12682 0.953125\n",
      "12684 1.0\n",
      "12688 1.0\n",
      "12703 1.0\n",
      "12710 1.0\n",
      "12718 1.0\n",
      "12720 1.0\n",
      "12721 1.0\n",
      "12724 1.0\n",
      "12725 1.0\n",
      "12730 0.9296875\n",
      "12735 1.0\n",
      "12740 1.0\n",
      "12746 0.9517463235294118\n",
      "12751 1.0\n",
      "12752 1.0\n",
      "12753 0.9765625\n",
      "12754 1.0\n",
      "12755 1.0\n",
      "12756 1.0\n",
      "12759 1.0\n",
      "12760 1.0\n",
      "12762 0.9556107954545454\n",
      "12763 1.0\n",
      "12765 1.0\n",
      "12769 1.0\n",
      "12771 1.0\n",
      "12774 1.0\n",
      "12776 1.0\n",
      "12777 1.0\n",
      "12780 1.0\n",
      "12781 1.0\n",
      "12788 1.0\n",
      "12790 1.0\n",
      "12792 1.0\n",
      "12794 1.0\n",
      "12795 0.95703125\n",
      "12806 1.0\n",
      "12807 1.0\n",
      "12809 1.0\n",
      "12820 1.0\n",
      "12822 0.94921875\n",
      "12827 1.0\n",
      "12828 1.0\n",
      "12829 1.0\n",
      "12833 0.9921875\n",
      "12836 0.9801377118644068\n",
      "12839 1.0\n",
      "12841 1.0\n",
      "12847 1.0\n",
      "12848 1.0\n",
      "12852 1.0\n",
      "12860 1.0\n",
      "12867 1.0\n",
      "12868 1.0\n",
      "12871 0.94921875\n",
      "12872 0.9652300824175825\n",
      "12874 1.0\n",
      "12875 1.0\n",
      "12877 1.0\n",
      "12878 1.0\n",
      "12882 1.0\n",
      "12885 1.0\n",
      "12888 1.0\n",
      "12893 1.0\n",
      "12894 1.0\n",
      "12900 1.0\n",
      "12901 1.0\n",
      "12903 1.0\n",
      "12905 1.0\n",
      "12908 0.9921875\n",
      "12911 1.0\n",
      "12914 0.9375\n",
      "12915 1.0\n",
      "12917 1.0\n",
      "12918 0.96875\n",
      "12920 0.96875\n",
      "12923 1.0\n",
      "12927 1.0\n",
      "12931 1.0\n",
      "12935 1.0\n",
      "12936 1.0\n",
      "12937 1.0\n",
      "12938 1.0\n",
      "12939 1.0\n",
      "12948 0.9598214285714286\n",
      "12954 1.0\n",
      "12957 1.0\n",
      "12959 0.9575892857142857\n",
      "12960 1.0\n",
      "12964 1.0\n",
      "12965 0.9553571428571429\n",
      "12966 1.0\n",
      "12970 1.0\n",
      "12973 1.0\n",
      "12975 1.0\n",
      "12978 0.9541666666666667\n",
      "12980 1.0\n",
      "12982 1.0\n",
      "12983 1.0\n",
      "12997 1.0\n",
      "12998 1.0\n",
      "13006 1.0\n",
      "13010 1.0\n",
      "13013 1.0\n",
      "13014 1.0\n",
      "13015 1.0\n",
      "13021 1.0\n",
      "13026 1.0\n",
      "13028 1.0\n",
      "13031 1.0\n",
      "13032 1.0\n",
      "13040 1.0\n",
      "13042 1.0\n",
      "13046 1.0\n",
      "13048 1.0\n",
      "13059 1.0\n",
      "13061 1.0\n",
      "13063 0.9296875\n",
      "13064 1.0\n",
      "13072 1.0\n",
      "13082 1.0\n",
      "13086 1.0\n",
      "13088 1.0\n",
      "13089 1.0\n",
      "13101 0.9609375\n",
      "13102 1.0\n",
      "13103 0.9388020833333334\n",
      "13104 1.0\n",
      "13108 1.0\n",
      "13116 1.0\n",
      "13117 1.0\n",
      "13120 1.0\n",
      "13126 0.953125\n",
      "13127 1.0\n",
      "13128 1.0\n",
      "13129 1.0\n",
      "13133 1.0\n",
      "13141 1.0\n",
      "13142 1.0\n",
      "13147 1.0\n",
      "13151 1.0\n",
      "13152 0.9793198529411765\n",
      "13153 0.9765625\n",
      "13154 1.0\n",
      "13155 1.0\n",
      "13163 1.0\n",
      "13165 1.0\n",
      "13169 1.0\n",
      "13172 1.0\n",
      "13175 1.0\n",
      "13176 1.0\n",
      "13180 1.0\n",
      "13182 1.0\n",
      "13183 1.0\n",
      "13186 1.0\n",
      "13187 1.0\n",
      "13192 1.0\n",
      "13193 0.9739583333333334\n",
      "13197 0.9583333333333334\n",
      "13201 1.0\n",
      "13205 1.0\n",
      "13207 1.0\n",
      "13209 1.0\n",
      "13213 1.0\n",
      "13214 1.0\n",
      "13219 1.0\n",
      "13221 1.0\n",
      "13223 1.0\n",
      "13227 1.0\n",
      "13228 0.953125\n",
      "13232 1.0\n",
      "13233 0.96875\n",
      "13238 0.9453125\n",
      "13239 1.0\n",
      "13241 1.0\n",
      "13243 1.0\n",
      "13246 1.0\n",
      "13248 1.0\n",
      "13250 0.84375\n",
      "13252 1.0\n",
      "13253 1.0\n",
      "13255 1.0\n",
      "13258 1.0\n",
      "13264 1.0\n",
      "13265 1.0\n",
      "13266 0.96875\n",
      "13267 1.0\n",
      "13271 1.0\n",
      "13273 1.0\n",
      "13284 0.9464285714285714\n",
      "13289 0.9422679227941176\n",
      "13294 1.0\n",
      "13295 1.0\n",
      "13298 1.0\n",
      "13310 1.0\n",
      "13311 1.0\n",
      "13315 1.0\n",
      "13316 1.0\n",
      "13320 1.0\n",
      "13326 1.0\n",
      "13329 1.0\n",
      "13333 1.0\n",
      "13338 1.0\n",
      "13339 1.0\n",
      "13342 1.0\n",
      "13343 1.0\n",
      "13344 1.0\n",
      "13346 1.0\n",
      "13347 1.0\n",
      "13351 1.0\n",
      "13353 1.0\n",
      "13354 0.962071718931475\n",
      "13355 1.0\n",
      "13362 0.9696691176470589\n",
      "13364 1.0\n",
      "13367 1.0\n",
      "13378 1.0\n",
      "13383 1.0\n",
      "13388 1.0\n",
      "13392 1.0\n",
      "13395 1.0\n",
      "13397 1.0\n",
      "13400 1.0\n",
      "13402 1.0\n",
      "13403 1.0\n",
      "13404 0.953125\n",
      "13406 1.0\n",
      "13407 0.9375\n",
      "13408 1.0\n",
      "13409 1.0\n",
      "13410 1.0\n",
      "13418 1.0\n",
      "13419 0.8828125\n",
      "13424 1.0\n",
      "13427 1.0\n",
      "13433 0.9553571428571429\n",
      "13448 1.0\n",
      "13451 0.97265625\n",
      "13458 1.0\n",
      "13459 0.9783653846153846\n",
      "13467 1.0\n",
      "13472 1.0\n",
      "13476 0.953125\n",
      "13477 1.0\n",
      "13478 0.9801377118644068\n",
      "13485 0.9583333333333334\n",
      "13487 1.0\n",
      "13488 0.9613042840375586\n",
      "13495 1.0\n",
      "13501 1.0\n",
      "13505 1.0\n",
      "13510 1.0\n",
      "13514 1.0\n",
      "13518 1.0\n",
      "13523 1.0\n",
      "13524 1.0\n",
      "13527 1.0\n",
      "13532 1.0\n",
      "13533 1.0\n",
      "13535 1.0\n",
      "13537 1.0\n",
      "13545 1.0\n",
      "13549 1.0\n",
      "13555 0.9558035714285714\n",
      "13557 1.0\n",
      "13562 1.0\n",
      "13566 1.0\n",
      "13568 1.0\n",
      "13574 1.0\n",
      "13576 1.0\n",
      "13579 1.0\n",
      "13586 1.0\n",
      "13590 1.0\n",
      "13595 1.0\n",
      "13599 1.0\n",
      "13605 0.9479166666666666\n",
      "13607 1.0\n",
      "13614 0.9583333333333334\n",
      "13622 1.0\n",
      "13629 1.0\n",
      "13633 1.0\n",
      "13634 1.0\n",
      "13636 1.0\n",
      "13638 1.0\n",
      "13640 0.9652300824175825\n",
      "13642 1.0\n",
      "13650 1.0\n",
      "13653 1.0\n",
      "13654 1.0\n",
      "13655 0.9517463235294118\n",
      "13666 1.0\n",
      "13668 1.0\n",
      "13672 1.0\n",
      "13675 0.9765625\n",
      "13678 1.0\n",
      "13680 1.0\n",
      "13681 1.0\n",
      "13683 1.0\n",
      "13686 1.0\n",
      "13688 1.0\n",
      "13690 0.9765625\n",
      "13692 1.0\n",
      "13695 1.0\n",
      "13697 1.0\n",
      "13702 1.0\n",
      "13703 1.0\n",
      "13706 1.0\n",
      "13709 1.0\n",
      "13721 0.9427083333333334\n",
      "13722 1.0\n",
      "13723 1.0\n",
      "13724 1.0\n",
      "13728 0.9484375\n",
      "13729 1.0\n",
      "13733 1.0\n",
      "13741 1.0\n",
      "13743 1.0\n",
      "13744 1.0\n",
      "13752 1.0\n",
      "13755 1.0\n",
      "13759 1.0\n",
      "13761 1.0\n",
      "13771 1.0\n",
      "13773 1.0\n",
      "13774 0.9375\n",
      "13777 1.0\n",
      "13783 1.0\n",
      "13785 1.0\n",
      "13797 1.0\n",
      "13798 0.875\n",
      "13801 1.0\n",
      "13802 1.0\n",
      "13807 0.9453125\n",
      "13808 1.0\n",
      "13814 0.9588815789473685\n",
      "13822 1.0\n",
      "13828 1.0\n",
      "13829 1.0\n",
      "13831 0.9765625\n",
      "13837 1.0\n",
      "13838 0.90625\n",
      "13843 1.0\n",
      "13845 1.0\n",
      "13849 1.0\n",
      "13851 0.9453125\n",
      "13855 1.0\n",
      "13856 1.0\n",
      "13857 1.0\n",
      "13866 1.0\n",
      "13869 1.0\n",
      "13870 1.0\n",
      "13874 1.0\n",
      "13875 1.0\n",
      "13877 0.9783653846153846\n",
      "13881 1.0\n",
      "13887 0.9635416666666666\n",
      "13890 1.0\n",
      "13891 0.9453125\n",
      "13892 1.0\n",
      "13900 1.0\n",
      "13902 0.921875\n",
      "13910 1.0\n",
      "13912 1.0\n",
      "13915 1.0\n",
      "13918 1.0\n",
      "13930 1.0\n",
      "13933 1.0\n",
      "13937 0.96875\n",
      "13938 1.0\n",
      "13944 1.0\n",
      "13947 1.0\n",
      "13954 1.0\n",
      "13955 1.0\n",
      "13957 1.0\n",
      "13967 1.0\n",
      "13971 0.9541666666666667\n",
      "13973 1.0\n",
      "13977 1.0\n",
      "13978 1.0\n",
      "13982 1.0\n",
      "13983 1.0\n",
      "13984 1.0\n",
      "13991 1.0\n",
      "13992 1.0\n",
      "13999 1.0\n",
      "14003 1.0\n",
      "14004 1.0\n",
      "14006 1.0\n",
      "14007 1.0\n",
      "14011 0.96875\n",
      "14019 0.9583333333333334\n",
      "14022 1.0\n",
      "14023 1.0\n",
      "14029 1.0\n",
      "14034 0.953125\n",
      "14038 1.0\n",
      "14039 1.0\n",
      "14045 1.0\n",
      "14046 1.0\n",
      "14048 1.0\n",
      "14050 1.0\n",
      "14051 1.0\n",
      "14052 1.0\n",
      "14055 1.0\n",
      "14063 1.0\n",
      "14064 1.0\n",
      "14068 1.0\n",
      "14072 1.0\n",
      "14073 1.0\n",
      "14076 1.0\n",
      "14080 1.0\n",
      "14082 1.0\n",
      "14091 1.0\n",
      "14094 1.0\n",
      "14097 1.0\n",
      "14102 1.0\n",
      "14105 1.0\n",
      "14111 1.0\n",
      "14115 1.0\n",
      "14123 1.0\n",
      "14128 1.0\n",
      "14130 1.0\n",
      "14135 1.0\n",
      "14143 0.9801377118644068\n",
      "14144 1.0\n",
      "14150 1.0\n",
      "14151 1.0\n",
      "14158 1.0\n",
      "14160 0.975\n",
      "14162 1.0\n",
      "14163 1.0\n",
      "14164 1.0\n",
      "14165 0.96875\n",
      "14166 1.0\n",
      "14171 1.0\n",
      "14177 1.0\n",
      "14181 1.0\n",
      "14182 0.953125\n",
      "14189 1.0\n",
      "14198 0.9588815789473685\n",
      "14204 1.0\n",
      "14205 1.0\n",
      "14206 1.0\n",
      "14210 1.0\n",
      "14213 1.0\n",
      "14215 1.0\n",
      "14219 0.9609375\n",
      "14220 1.0\n",
      "14232 1.0\n",
      "14236 1.0\n",
      "14238 1.0\n",
      "14241 0.96484375\n",
      "14244 1.0\n",
      "14246 1.0\n",
      "14249 1.0\n",
      "14250 1.0\n",
      "14253 1.0\n",
      "14257 1.0\n",
      "14261 1.0\n",
      "14262 0.9739583333333334\n",
      "14264 1.0\n",
      "14268 1.0\n",
      "14279 1.0\n",
      "14282 1.0\n",
      "14285 0.9643342391304348\n",
      "14286 1.0\n",
      "14292 1.0\n",
      "14301 1.0\n",
      "14306 1.0\n",
      "14307 0.890625\n",
      "14309 1.0\n",
      "14312 1.0\n",
      "14313 1.0\n",
      "14316 1.0\n",
      "14322 0.953125\n",
      "14330 1.0\n",
      "14334 1.0\n",
      "14336 1.0\n",
      "14343 1.0\n",
      "14345 1.0\n",
      "14357 0.9352678571428571\n",
      "14359 1.0\n",
      "14369 0.9453125\n",
      "14371 1.0\n",
      "14373 1.0\n",
      "14374 0.9765625\n",
      "14378 1.0\n",
      "14379 1.0\n",
      "14381 1.0\n",
      "14382 1.0\n",
      "14384 1.0\n",
      "14387 1.0\n",
      "14388 0.9453125\n",
      "14392 1.0\n",
      "14393 1.0\n",
      "14399 0.9418402777777778\n",
      "14401 1.0\n",
      "14412 1.0\n",
      "14414 1.0\n",
      "14419 1.0\n",
      "14426 1.0\n",
      "14434 1.0\n",
      "14437 1.0\n",
      "14439 1.0\n",
      "14441 1.0\n",
      "14457 1.0\n",
      "14458 1.0\n",
      "14481 0.97265625\n",
      "14484 1.0\n",
      "14486 0.94921875\n",
      "14487 1.0\n",
      "14491 1.0\n",
      "14494 1.0\n",
      "14495 1.0\n",
      "14506 1.0\n",
      "14511 1.0\n",
      "14513 1.0\n",
      "14517 1.0\n",
      "14520 1.0\n",
      "14525 0.962071718931475\n",
      "14526 1.0\n",
      "14534 1.0\n",
      "14536 1.0\n",
      "14537 1.0\n",
      "14539 1.0\n",
      "14545 1.0\n",
      "14550 0.9621975806451613\n",
      "14551 1.0\n",
      "14554 1.0\n",
      "14560 1.0\n",
      "14562 1.0\n",
      "14563 1.0\n",
      "14567 1.0\n",
      "14571 1.0\n",
      "14573 1.0\n",
      "14574 1.0\n",
      "14575 1.0\n",
      "14581 1.0\n",
      "14583 1.0\n",
      "14584 1.0\n",
      "14590 0.9583333333333334\n",
      "14595 1.0\n",
      "14596 1.0\n",
      "14600 1.0\n",
      "14607 1.0\n",
      "14608 0.953125\n",
      "14613 1.0\n",
      "14626 1.0\n",
      "14627 1.0\n",
      "14628 1.0\n",
      "14631 1.0\n",
      "14633 1.0\n",
      "14640 1.0\n",
      "14644 1.0\n",
      "14645 1.0\n",
      "14646 0.965625\n",
      "14647 1.0\n",
      "14648 1.0\n",
      "14662 1.0\n",
      "14667 0.9583333333333334\n",
      "14677 1.0\n",
      "14681 1.0\n",
      "14683 1.0\n",
      "14689 1.0\n",
      "14691 1.0\n",
      "14695 1.0\n",
      "14698 1.0\n",
      "14705 1.0\n",
      "14708 1.0\n",
      "14712 0.9806547619047619\n",
      "14720 1.0\n",
      "14737 1.0\n",
      "14742 1.0\n",
      "14743 1.0\n",
      "14749 1.0\n",
      "14763 1.0\n",
      "14765 1.0\n",
      "14771 1.0\n",
      "14782 1.0\n",
      "14786 1.0\n",
      "14791 0.921875\n",
      "14795 1.0\n",
      "14799 0.9666666666666667\n",
      "14800 1.0\n",
      "14805 1.0\n",
      "14807 1.0\n",
      "14808 1.0\n",
      "14812 1.0\n",
      "14814 1.0\n",
      "14825 0.9583333333333334\n",
      "14828 0.9541666666666667\n",
      "14845 0.9578125\n",
      "14853 0.9862132352941176\n",
      "14857 1.0\n",
      "14861 1.0\n",
      "14862 1.0\n",
      "14884 1.0\n",
      "14886 1.0\n",
      "14887 1.0\n",
      "14892 1.0\n",
      "14895 1.0\n",
      "14899 1.0\n",
      "14900 1.0\n",
      "14901 1.0\n",
      "14902 1.0\n",
      "14912 1.0\n",
      "14913 1.0\n",
      "14924 1.0\n",
      "14933 1.0\n",
      "14939 1.0\n",
      "14946 1.0\n",
      "14951 1.0\n",
      "14954 0.9921875\n",
      "14958 0.9526041666666667\n",
      "14975 0.9609375\n",
      "14981 0.921875\n",
      "14983 0.9416666666666667\n",
      "14988 1.0\n",
      "14991 1.0\n",
      "14992 1.0\n",
      "14997 1.0\n",
      "14998 1.0\n",
      "15003 0.96875\n",
      "15005 1.0\n",
      "15007 0.946875\n",
      "15009 0.9671875\n",
      "15011 1.0\n",
      "15013 1.0\n",
      "15015 0.9609375\n",
      "15016 1.0\n",
      "15020 1.0\n",
      "15024 1.0\n",
      "15027 1.0\n",
      "15028 0.953125\n",
      "15031 1.0\n",
      "15035 1.0\n",
      "15037 0.9322916666666666\n",
      "15040 1.0\n",
      "15045 1.0\n",
      "15053 1.0\n",
      "15057 1.0\n",
      "15061 1.0\n",
      "15062 0.9375\n",
      "15064 1.0\n",
      "15065 1.0\n",
      "15066 1.0\n",
      "15067 0.9578125\n",
      "15069 1.0\n",
      "15077 1.0\n",
      "15080 1.0\n",
      "15085 1.0\n",
      "15091 1.0\n",
      "15101 1.0\n",
      "15109 1.0\n",
      "15110 1.0\n",
      "15112 1.0\n",
      "15113 1.0\n",
      "15114 1.0\n",
      "15117 1.0\n",
      "15121 1.0\n",
      "15127 1.0\n",
      "15131 1.0\n",
      "15136 1.0\n",
      "15137 0.8828125\n",
      "15139 1.0\n",
      "15142 0.9791666666666666\n",
      "15145 1.0\n",
      "15149 1.0\n",
      "15150 1.0\n",
      "15152 1.0\n",
      "15154 1.0\n",
      "15156 1.0\n",
      "15162 1.0\n",
      "15165 1.0\n",
      "15166 1.0\n",
      "15168 1.0\n",
      "15174 1.0\n",
      "15182 1.0\n",
      "15186 1.0\n",
      "15187 1.0\n",
      "15192 1.0\n",
      "15206 1.0\n",
      "15212 1.0\n",
      "15213 1.0\n",
      "15222 1.0\n",
      "15223 1.0\n",
      "15235 1.0\n",
      "15241 1.0\n",
      "15242 1.0\n",
      "15246 0.9479166666666666\n",
      "15247 0.9643342391304348\n",
      "15257 1.0\n",
      "15258 1.0\n",
      "15264 1.0\n",
      "15265 1.0\n",
      "15268 1.0\n",
      "15271 1.0\n",
      "15272 1.0\n",
      "15275 1.0\n",
      "15276 1.0\n",
      "15277 1.0\n",
      "15283 1.0\n",
      "15284 1.0\n",
      "15288 1.0\n",
      "15295 1.0\n",
      "15296 1.0\n",
      "15299 0.9609375\n",
      "15301 0.9140625\n",
      "15303 1.0\n",
      "15310 1.0\n",
      "15313 1.0\n",
      "15314 1.0\n",
      "15315 1.0\n",
      "15317 1.0\n",
      "15318 1.0\n",
      "15322 1.0\n",
      "15324 1.0\n",
      "15325 1.0\n",
      "15326 1.0\n",
      "15328 1.0\n",
      "15329 1.0\n",
      "15339 1.0\n",
      "15341 1.0\n",
      "15348 1.0\n",
      "15349 1.0\n",
      "15353 1.0\n",
      "15356 1.0\n",
      "15358 1.0\n",
      "15359 1.0\n",
      "15362 1.0\n",
      "15364 1.0\n",
      "15372 1.0\n",
      "15380 1.0\n",
      "15381 1.0\n",
      "15382 1.0\n",
      "15383 0.9635416666666666\n",
      "15393 0.9583333333333334\n",
      "15395 1.0\n",
      "15400 1.0\n",
      "15404 1.0\n",
      "15413 1.0\n",
      "15416 1.0\n",
      "15424 1.0\n",
      "15430 1.0\n",
      "15434 1.0\n",
      "15444 1.0\n",
      "15448 1.0\n",
      "15449 1.0\n",
      "15454 0.9337121212121212\n",
      "15455 1.0\n",
      "15459 0.9556107954545454\n",
      "15462 1.0\n",
      "15464 1.0\n",
      "15468 0.9638097426470589\n",
      "15469 1.0\n",
      "15478 1.0\n",
      "15481 0.921875\n",
      "15485 1.0\n",
      "15488 1.0\n",
      "15489 1.0\n",
      "15490 1.0\n",
      "15496 1.0\n",
      "15499 1.0\n",
      "15500 0.9642857142857143\n",
      "15501 1.0\n",
      "15504 1.0\n",
      "15507 1.0\n",
      "15520 1.0\n",
      "15523 1.0\n",
      "15525 1.0\n",
      "15526 1.0\n",
      "15531 0.9517463235294118\n",
      "15533 1.0\n",
      "15535 1.0\n",
      "15536 0.9241071428571429\n",
      "15540 1.0\n",
      "15552 1.0\n",
      "15554 1.0\n",
      "15555 0.9422679227941176\n",
      "15556 1.0\n",
      "15560 1.0\n",
      "15562 0.96875\n",
      "15569 1.0\n",
      "15570 1.0\n",
      "15578 1.0\n",
      "15583 1.0\n",
      "15584 1.0\n",
      "15596 1.0\n",
      "15599 1.0\n",
      "15603 1.0\n",
      "15604 1.0\n",
      "15607 1.0\n",
      "15611 1.0\n",
      "15615 1.0\n",
      "15616 1.0\n",
      "15618 1.0\n",
      "15621 1.0\n",
      "15623 1.0\n",
      "15624 1.0\n",
      "15625 0.9625\n",
      "15629 1.0\n",
      "15630 1.0\n",
      "15633 1.0\n",
      "15635 1.0\n",
      "15639 1.0\n",
      "15640 1.0\n",
      "15641 1.0\n",
      "15642 1.0\n",
      "15643 1.0\n",
      "15644 1.0\n",
      "15646 1.0\n",
      "15651 1.0\n",
      "15653 0.8828125\n",
      "15654 1.0\n",
      "15655 1.0\n",
      "15659 0.9517463235294118\n",
      "15661 1.0\n",
      "15663 1.0\n",
      "15666 1.0\n",
      "15677 1.0\n",
      "15681 1.0\n",
      "15683 1.0\n",
      "15688 1.0\n",
      "15690 1.0\n",
      "15691 1.0\n",
      "15692 1.0\n",
      "15702 0.9635416666666666\n",
      "15706 1.0\n",
      "15712 1.0\n",
      "15713 1.0\n",
      "15718 1.0\n",
      "15724 1.0\n",
      "15730 1.0\n",
      "15731 0.9642857142857143\n",
      "15735 1.0\n",
      "15736 1.0\n",
      "15744 1.0\n",
      "15762 1.0\n",
      "15765 1.0\n",
      "15769 0.9729567307692307\n",
      "15770 1.0\n",
      "15771 0.984375\n",
      "15773 1.0\n",
      "15776 1.0\n",
      "15778 1.0\n",
      "15780 1.0\n",
      "15785 1.0\n",
      "15794 1.0\n",
      "15796 0.9453125\n",
      "15803 1.0\n",
      "15814 1.0\n",
      "15815 1.0\n",
      "15817 0.9422679227941176\n",
      "15821 1.0\n",
      "15822 1.0\n",
      "15838 1.0\n",
      "15839 1.0\n",
      "15841 1.0\n",
      "15848 1.0\n",
      "15853 1.0\n",
      "15855 0.96875\n",
      "15858 0.9801377118644068\n",
      "15859 1.0\n",
      "15872 1.0\n",
      "15874 1.0\n",
      "15875 1.0\n",
      "15882 1.0\n",
      "15887 1.0\n",
      "15889 1.0\n",
      "15890 1.0\n",
      "15893 1.0\n",
      "15901 1.0\n",
      "15904 1.0\n",
      "15905 1.0\n",
      "15906 1.0\n",
      "15907 1.0\n",
      "15910 1.0\n",
      "15913 1.0\n",
      "15915 1.0\n",
      "15916 1.0\n",
      "15917 1.0\n",
      "15918 1.0\n",
      "15919 1.0\n",
      "15922 0.9583333333333334\n",
      "15923 1.0\n",
      "15925 1.0\n",
      "15940 1.0\n",
      "15945 1.0\n",
      "15953 1.0\n",
      "15954 1.0\n",
      "15956 1.0\n",
      "15961 1.0\n",
      "15964 1.0\n",
      "15965 1.0\n",
      "15973 1.0\n",
      "15974 1.0\n",
      "15976 1.0\n",
      "15983 0.9609375\n",
      "15989 1.0\n",
      "15990 0.9375\n",
      "15995 0.9625\n",
      "15997 0.9829545454545454\n",
      "16005 1.0\n",
      "16013 1.0\n",
      "16024 1.0\n",
      "16025 0.9505494505494505\n",
      "16027 1.0\n",
      "16030 1.0\n",
      "16034 1.0\n",
      "16037 0.9602272727272727\n",
      "16038 1.0\n",
      "16043 1.0\n",
      "16054 1.0\n",
      "16057 1.0\n",
      "16062 1.0\n",
      "16063 1.0\n",
      "16075 1.0\n",
      "16078 1.0\n",
      "16079 1.0\n",
      "16080 1.0\n",
      "16082 1.0\n",
      "16086 1.0\n",
      "16094 1.0\n",
      "16097 1.0\n",
      "16102 1.0\n",
      "16106 1.0\n",
      "16112 1.0\n",
      "16117 1.0\n",
      "16121 1.0\n",
      "16131 1.0\n",
      "16136 1.0\n",
      "16145 1.0\n",
      "16147 1.0\n",
      "16149 1.0\n",
      "16159 1.0\n",
      "16160 1.0\n",
      "16169 1.0\n",
      "16170 1.0\n",
      "16171 1.0\n",
      "16173 1.0\n",
      "16175 1.0\n",
      "16181 1.0\n",
      "16186 1.0\n",
      "16210 1.0\n",
      "16217 1.0\n",
      "16218 1.0\n",
      "16221 1.0\n",
      "16224 1.0\n",
      "16226 1.0\n",
      "16227 1.0\n",
      "16230 1.0\n",
      "16232 1.0\n",
      "16236 1.0\n",
      "16239 1.0\n",
      "16242 1.0\n",
      "16245 1.0\n",
      "16246 0.9450334821428571\n",
      "16247 1.0\n",
      "16255 1.0\n",
      "16276 1.0\n",
      "16282 1.0\n",
      "16283 1.0\n",
      "16285 0.9453125\n",
      "16294 0.9497767857142857\n",
      "16305 0.9375\n",
      "16306 1.0\n",
      "16307 1.0\n",
      "16308 0.9754901960784313\n",
      "16311 0.9609375\n",
      "16312 1.0\n",
      "16314 1.0\n",
      "16327 1.0\n",
      "16328 1.0\n",
      "16332 1.0\n",
      "16350 1.0\n",
      "16354 1.0\n",
      "16355 1.0\n",
      "16356 0.953125\n",
      "16357 1.0\n",
      "16358 0.971875\n",
      "16361 1.0\n",
      "16362 1.0\n",
      "16372 1.0\n",
      "16377 0.96875\n",
      "16378 1.0\n",
      "16379 0.921875\n",
      "16381 1.0\n",
      "16382 1.0\n",
      "16387 1.0\n",
      "16392 1.0\n",
      "16393 1.0\n",
      "16395 0.9635416666666666\n",
      "16396 1.0\n",
      "16397 1.0\n",
      "16398 1.0\n",
      "16399 1.0\n",
      "16400 1.0\n",
      "16401 0.9791666666666666\n",
      "16402 0.953125\n",
      "16404 1.0\n",
      "16406 1.0\n",
      "16412 0.9801377118644068\n",
      "16413 1.0\n",
      "16414 1.0\n",
      "16418 1.0\n",
      "16422 1.0\n",
      "16428 1.0\n",
      "16430 1.0\n",
      "16431 1.0\n",
      "16436 1.0\n",
      "16438 1.0\n",
      "16439 1.0\n",
      "16447 1.0\n",
      "16451 1.0\n",
      "16455 1.0\n",
      "16459 0.9296875\n",
      "16462 1.0\n",
      "16463 1.0\n",
      "16464 1.0\n",
      "16471 1.0\n",
      "16472 1.0\n",
      "16474 1.0\n",
      "16493 1.0\n",
      "16495 1.0\n",
      "16497 1.0\n",
      "16498 1.0\n",
      "16502 1.0\n",
      "16505 1.0\n",
      "16513 1.0\n",
      "16514 1.0\n",
      "16516 1.0\n",
      "16517 0.9729567307692307\n",
      "16518 1.0\n",
      "16524 1.0\n",
      "16529 0.9739583333333334\n",
      "16530 1.0\n",
      "16531 1.0\n",
      "16532 1.0\n",
      "16536 1.0\n",
      "16537 1.0\n",
      "16541 1.0\n",
      "16542 1.0\n",
      "16553 1.0\n",
      "16556 1.0\n",
      "16563 1.0\n",
      "16570 0.9505494505494505\n",
      "16571 1.0\n",
      "16572 1.0\n",
      "16580 1.0\n",
      "16585 1.0\n",
      "16586 1.0\n",
      "16590 0.9361979166666666\n",
      "16591 1.0\n",
      "16593 1.0\n",
      "16594 0.9806547619047619\n",
      "16595 1.0\n",
      "16601 1.0\n",
      "16610 1.0\n",
      "16611 1.0\n",
      "16618 0.9765625\n",
      "16623 1.0\n",
      "16635 1.0\n",
      "16638 1.0\n",
      "16639 1.0\n",
      "16640 1.0\n",
      "16647 1.0\n",
      "16653 1.0\n",
      "16655 0.9806547619047619\n",
      "16660 1.0\n",
      "16661 1.0\n",
      "16664 1.0\n",
      "16670 1.0\n",
      "16671 0.9643342391304348\n",
      "16672 1.0\n",
      "16678 1.0\n",
      "16682 1.0\n",
      "16687 1.0\n",
      "16688 1.0\n",
      "16696 1.0\n",
      "16703 0.9609375\n",
      "16705 1.0\n",
      "16708 1.0\n",
      "16713 1.0\n",
      "16717 1.0\n",
      "16720 1.0\n",
      "16722 1.0\n",
      "16725 1.0\n",
      "16726 1.0\n",
      "16727 1.0\n",
      "16731 1.0\n",
      "16732 1.0\n",
      "16733 0.9609375\n",
      "16735 1.0\n",
      "16736 1.0\n",
      "16737 1.0\n",
      "16739 1.0\n",
      "16741 1.0\n",
      "16744 1.0\n",
      "16748 1.0\n",
      "16749 1.0\n",
      "16755 0.9495192307692307\n",
      "16757 1.0\n",
      "16761 1.0\n",
      "16763 1.0\n",
      "16767 1.0\n",
      "16768 1.0\n",
      "16769 0.94140625\n",
      "16772 1.0\n",
      "16776 1.0\n",
      "16781 1.0\n",
      "16784 1.0\n",
      "16787 1.0\n",
      "16788 1.0\n",
      "16796 1.0\n",
      "16797 1.0\n",
      "16798 1.0\n",
      "16808 0.9337121212121212\n",
      "16814 1.0\n",
      "16819 1.0\n",
      "16820 1.0\n",
      "16821 1.0\n",
      "16822 0.9437872023809524\n",
      "16823 1.0\n",
      "16827 1.0\n",
      "16834 1.0\n",
      "16838 1.0\n",
      "16847 1.0\n",
      "16848 1.0\n",
      "16850 0.9675324675324676\n",
      "16857 1.0\n",
      "16860 0.9754901960784313\n",
      "16863 1.0\n",
      "16864 1.0\n",
      "16865 1.0\n",
      "16868 1.0\n",
      "16873 1.0\n",
      "16876 1.0\n",
      "16878 1.0\n",
      "16884 1.0\n",
      "16885 1.0\n",
      "16893 1.0\n",
      "16894 1.0\n",
      "16898 1.0\n",
      "16902 1.0\n",
      "16905 1.0\n",
      "16908 1.0\n",
      "16909 0.984375\n",
      "16912 1.0\n",
      "16915 1.0\n",
      "16916 0.9791666666666666\n",
      "16919 1.0\n",
      "16921 1.0\n",
      "16932 0.9505494505494505\n",
      "16934 1.0\n",
      "16937 1.0\n",
      "16944 1.0\n",
      "16945 1.0\n",
      "16946 1.0\n",
      "16947 1.0\n",
      "16949 1.0\n",
      "16951 1.0\n",
      "16956 0.9296875\n",
      "16957 1.0\n",
      "16958 0.946875\n",
      "16960 1.0\n",
      "16961 0.9495192307692307\n",
      "16963 1.0\n",
      "16971 0.9495192307692307\n",
      "16975 1.0\n",
      "16976 1.0\n",
      "16978 1.0\n",
      "16980 1.0\n",
      "16982 1.0\n",
      "16984 0.9541666666666667\n",
      "16987 1.0\n",
      "16990 1.0\n",
      "16992 1.0\n",
      "16997 1.0\n",
      "17004 1.0\n",
      "17015 1.0\n",
      "17016 1.0\n",
      "17025 0.9337121212121212\n",
      "17030 1.0\n",
      "17031 1.0\n",
      "17034 0.9437872023809524\n",
      "17035 1.0\n",
      "17039 1.0\n",
      "17040 1.0\n",
      "17042 1.0\n",
      "17046 1.0\n",
      "17047 1.0\n",
      "17052 1.0\n",
      "17055 1.0\n",
      "17059 1.0\n",
      "17062 1.0\n",
      "17063 1.0\n",
      "17068 1.0\n",
      "17076 1.0\n",
      "17078 0.9484375\n",
      "17082 0.9296875\n",
      "17084 1.0\n",
      "17086 1.0\n",
      "17087 1.0\n",
      "17091 0.9140625\n",
      "17094 1.0\n",
      "17095 1.0\n",
      "17096 1.0\n",
      "17100 1.0\n",
      "17101 1.0\n",
      "17102 1.0\n",
      "17107 1.0\n",
      "17116 1.0\n",
      "17119 1.0\n",
      "17123 1.0\n",
      "17127 1.0\n",
      "17129 1.0\n",
      "17130 1.0\n",
      "17133 1.0\n",
      "17136 0.953125\n",
      "17141 0.9598214285714286\n",
      "17142 1.0\n",
      "17144 1.0\n",
      "17148 1.0\n",
      "17151 1.0\n",
      "17163 1.0\n",
      "17165 0.9813988095238095\n",
      "17171 1.0\n",
      "17172 1.0\n",
      "17176 1.0\n",
      "17177 0.9352678571428571\n",
      "17179 1.0\n",
      "17181 1.0\n",
      "17186 1.0\n",
      "17188 1.0\n",
      "17191 1.0\n",
      "17192 1.0\n",
      "17193 1.0\n",
      "17199 1.0\n",
      "17201 1.0\n",
      "17203 1.0\n",
      "17204 0.9635416666666666\n",
      "17206 1.0\n",
      "17210 1.0\n",
      "17213 0.9296875\n",
      "17221 1.0\n",
      "17222 1.0\n",
      "17224 1.0\n",
      "17225 0.95703125\n",
      "17229 1.0\n",
      "17232 1.0\n",
      "17233 1.0\n",
      "17240 1.0\n",
      "17242 0.9375\n",
      "17249 1.0\n",
      "17253 1.0\n",
      "17257 1.0\n",
      "17267 1.0\n",
      "17278 1.0\n",
      "17284 1.0\n",
      "17286 1.0\n",
      "17287 1.0\n",
      "17289 1.0\n",
      "17291 1.0\n",
      "17294 1.0\n",
      "17300 1.0\n",
      "17301 1.0\n",
      "17304 1.0\n",
      "17311 1.0\n",
      "17312 0.93359375\n",
      "17313 1.0\n",
      "17321 1.0\n",
      "17323 0.9625\n",
      "17325 1.0\n",
      "17327 1.0\n",
      "17328 1.0\n",
      "17329 1.0\n",
      "17331 0.9739583333333334\n",
      "17338 1.0\n",
      "17344 1.0\n",
      "17348 1.0\n",
      "17350 1.0\n",
      "17352 1.0\n",
      "17353 1.0\n",
      "17355 1.0\n",
      "17360 1.0\n",
      "17363 1.0\n",
      "17364 1.0\n",
      "17365 1.0\n",
      "17366 0.9449404761904762\n",
      "17369 1.0\n",
      "17374 1.0\n",
      "17375 1.0\n",
      "17376 1.0\n",
      "17377 1.0\n",
      "17378 1.0\n",
      "17379 1.0\n",
      "17381 1.0\n",
      "17395 1.0\n",
      "17397 1.0\n",
      "17402 0.9186197916666666\n",
      "17405 1.0\n",
      "17413 1.0\n",
      "17417 0.94921875\n",
      "17419 1.0\n",
      "17421 1.0\n",
      "17424 1.0\n",
      "17428 1.0\n",
      "17430 1.0\n",
      "17439 0.9296875\n",
      "17446 1.0\n",
      "17447 0.9296875\n",
      "17449 0.93359375\n",
      "17453 1.0\n",
      "17456 0.9621975806451613\n",
      "17457 1.0\n",
      "17461 1.0\n",
      "17465 1.0\n",
      "17469 0.9415922619047619\n",
      "17477 1.0\n",
      "17481 1.0\n",
      "17482 1.0\n",
      "17484 1.0\n",
      "17488 1.0\n",
      "17489 1.0\n",
      "17491 1.0\n",
      "17492 1.0\n",
      "17493 0.953125\n",
      "17494 1.0\n",
      "17500 1.0\n",
      "17503 1.0\n",
      "17506 1.0\n",
      "17507 1.0\n",
      "17518 1.0\n",
      "17519 1.0\n",
      "17520 0.9739583333333334\n",
      "17529 1.0\n",
      "17531 1.0\n",
      "17535 1.0\n",
      "17542 1.0\n",
      "17545 1.0\n",
      "17546 1.0\n",
      "17549 1.0\n",
      "17551 0.90625\n",
      "17552 1.0\n",
      "17556 1.0\n",
      "17567 0.921875\n",
      "17568 1.0\n",
      "17575 1.0\n",
      "17591 1.0\n",
      "17593 1.0\n",
      "17597 1.0\n",
      "17601 1.0\n",
      "17603 1.0\n",
      "17617 1.0\n",
      "17618 1.0\n",
      "17620 0.962071718931475\n",
      "17621 1.0\n",
      "17622 1.0\n",
      "17628 1.0\n",
      "17643 1.0\n",
      "17654 1.0\n",
      "17656 1.0\n",
      "17659 1.0\n",
      "17661 0.9517463235294118\n",
      "17662 1.0\n",
      "17665 1.0\n",
      "17670 1.0\n",
      "17674 1.0\n",
      "17679 1.0\n",
      "17680 0.9801377118644068\n",
      "17686 1.0\n",
      "17689 1.0\n",
      "17691 0.953125\n",
      "17692 1.0\n",
      "17697 1.0\n",
      "17699 1.0\n",
      "17700 1.0\n",
      "17702 0.9609375\n",
      "17703 1.0\n",
      "17704 1.0\n",
      "17708 0.9732142857142857\n",
      "17709 1.0\n",
      "17727 1.0\n",
      "17733 1.0\n",
      "17745 1.0\n",
      "17751 1.0\n",
      "17753 0.9453125\n",
      "17754 1.0\n",
      "17758 1.0\n",
      "17761 1.0\n",
      "17762 1.0\n",
      "17764 1.0\n",
      "17774 1.0\n",
      "17782 0.9296875\n",
      "17784 1.0\n",
      "17786 1.0\n",
      "17787 1.0\n",
      "17791 0.9609375\n",
      "17794 1.0\n",
      "17799 0.9559294871794872\n",
      "17801 1.0\n",
      "17802 1.0\n",
      "17808 1.0\n",
      "17810 1.0\n",
      "17816 1.0\n",
      "17818 0.9696691176470589\n",
      "17819 0.953125\n",
      "17823 1.0\n",
      "17831 1.0\n",
      "17833 1.0\n",
      "17837 1.0\n",
      "17846 1.0\n",
      "17847 0.921875\n",
      "17849 1.0\n",
      "17857 1.0\n",
      "17862 1.0\n",
      "17872 0.9497767857142857\n",
      "17876 1.0\n",
      "17880 0.9621975806451613\n",
      "17881 1.0\n",
      "17884 0.9638097426470589\n",
      "17885 1.0\n",
      "17893 1.0\n",
      "17895 1.0\n",
      "17899 1.0\n",
      "17903 1.0\n",
      "17914 1.0\n",
      "17915 1.0\n",
      "17916 0.9765625\n",
      "17917 1.0\n",
      "17921 1.0\n",
      "17923 1.0\n",
      "17925 0.9799107142857143\n",
      "17929 1.0\n",
      "17932 1.0\n",
      "17933 1.0\n",
      "17934 1.0\n",
      "17935 1.0\n",
      "17941 0.953125\n",
      "17945 0.9449404761904762\n",
      "17952 1.0\n",
      "17954 1.0\n",
      "17961 1.0\n",
      "17963 0.9583333333333334\n",
      "17964 1.0\n",
      "17965 0.9642857142857143\n",
      "17971 1.0\n",
      "17977 1.0\n",
      "17978 1.0\n",
      "17987 1.0\n",
      "17989 1.0\n",
      "17992 0.9427083333333334\n",
      "17993 1.0\n",
      "17994 0.9352678571428571\n",
      "17995 1.0\n",
      "17999 1.0\n",
      "18005 0.9806547619047619\n",
      "18008 1.0\n",
      "18012 0.96875\n",
      "18013 0.9739583333333334\n",
      "18017 1.0\n",
      "18018 1.0\n",
      "18027 1.0\n",
      "18034 0.9739583333333334\n",
      "18035 1.0\n",
      "18041 1.0\n",
      "18042 1.0\n",
      "18043 1.0\n",
      "18048 1.0\n",
      "18050 1.0\n",
      "18052 1.0\n",
      "18053 1.0\n",
      "18055 0.9665178571428571\n",
      "18061 1.0\n",
      "18062 0.9830013736263736\n",
      "18063 1.0\n",
      "18067 1.0\n",
      "18068 1.0\n",
      "18069 1.0\n",
      "18071 0.9375\n",
      "18078 1.0\n",
      "18079 1.0\n",
      "18088 0.9621975806451613\n",
      "18089 1.0\n",
      "18090 1.0\n",
      "18093 1.0\n",
      "18095 1.0\n",
      "18115 1.0\n",
      "18118 1.0\n",
      "18119 1.0\n",
      "18125 1.0\n",
      "18128 1.0\n",
      "18129 1.0\n",
      "18130 0.9801377118644068\n",
      "18131 1.0\n",
      "18134 1.0\n",
      "18138 1.0\n",
      "18143 1.0\n",
      "18146 1.0\n",
      "18147 1.0\n",
      "18152 0.8359375\n",
      "18155 1.0\n",
      "18156 1.0\n",
      "18162 0.9375\n",
      "18166 1.0\n",
      "18167 1.0\n",
      "18179 1.0\n",
      "18183 1.0\n",
      "18184 1.0\n",
      "18187 1.0\n",
      "18189 1.0\n",
      "18190 1.0\n",
      "18202 1.0\n",
      "18206 1.0\n",
      "18207 1.0\n",
      "18209 1.0\n",
      "18218 1.0\n",
      "18221 1.0\n",
      "18223 1.0\n",
      "18227 0.9575892857142857\n",
      "18228 1.0\n",
      "18230 1.0\n",
      "18236 1.0\n",
      "18240 1.0\n",
      "18243 1.0\n",
      "18246 1.0\n",
      "18247 1.0\n",
      "18249 1.0\n",
      "18253 1.0\n",
      "18254 1.0\n",
      "18262 1.0\n",
      "18263 1.0\n",
      "18266 1.0\n",
      "18272 1.0\n",
      "18273 0.9558035714285714\n",
      "18274 1.0\n",
      "18279 1.0\n",
      "18283 1.0\n",
      "18284 1.0\n",
      "18292 1.0\n",
      "18293 1.0\n",
      "18297 1.0\n",
      "18303 1.0\n",
      "18304 1.0\n",
      "18306 0.921875\n",
      "18308 1.0\n",
      "18309 1.0\n",
      "18313 1.0\n",
      "18315 1.0\n",
      "18322 1.0\n",
      "18323 1.0\n",
      "18325 1.0\n",
      "18327 1.0\n",
      "18330 1.0\n",
      "18338 1.0\n",
      "18339 1.0\n",
      "18351 1.0\n",
      "18352 0.97265625\n",
      "18353 0.921875\n",
      "18354 0.9765625\n",
      "18357 1.0\n",
      "18362 1.0\n",
      "18369 0.9765625\n",
      "18374 1.0\n",
      "18377 1.0\n",
      "18378 1.0\n",
      "18381 1.0\n",
      "18384 1.0\n",
      "18385 1.0\n",
      "18386 1.0\n",
      "18389 1.0\n",
      "18395 1.0\n",
      "18400 1.0\n",
      "18404 1.0\n",
      "18405 1.0\n",
      "18406 1.0\n",
      "18414 0.9675324675324676\n",
      "18415 1.0\n",
      "18420 1.0\n",
      "18422 0.9375\n",
      "18423 1.0\n",
      "18425 0.9422679227941176\n",
      "18428 1.0\n",
      "18432 0.953125\n",
      "18433 0.9665178571428571\n",
      "18437 1.0\n",
      "18443 1.0\n",
      "18449 1.0\n",
      "18456 1.0\n",
      "18457 1.0\n",
      "18465 0.9793198529411765\n",
      "18468 1.0\n",
      "18473 1.0\n",
      "18475 0.9609375\n",
      "18478 1.0\n",
      "18479 1.0\n",
      "18482 0.921875\n",
      "18490 1.0\n",
      "18491 0.96875\n",
      "18498 0.9375\n",
      "18508 1.0\n",
      "18509 1.0\n",
      "18521 1.0\n",
      "18530 0.9517463235294118\n",
      "18535 0.9729567307692307\n",
      "18536 1.0\n",
      "18537 1.0\n",
      "18538 1.0\n",
      "18539 0.8984375\n",
      "18540 1.0\n",
      "18541 1.0\n",
      "18542 1.0\n",
      "18543 1.0\n",
      "18547 1.0\n",
      "18548 1.0\n",
      "18550 0.9388020833333334\n",
      "18551 1.0\n",
      "18554 1.0\n",
      "18555 1.0\n",
      "18559 1.0\n",
      "18560 1.0\n",
      "18563 1.0\n",
      "18566 1.0\n",
      "18568 1.0\n",
      "18571 1.0\n",
      "18578 1.0\n",
      "18579 0.9270833333333334\n",
      "18581 1.0\n",
      "18582 1.0\n",
      "18583 1.0\n",
      "18584 1.0\n",
      "18595 1.0\n",
      "18596 1.0\n",
      "18602 0.9609375\n",
      "18603 1.0\n",
      "18613 1.0\n",
      "18634 1.0\n",
      "18635 1.0\n",
      "18636 1.0\n",
      "18637 1.0\n",
      "18638 1.0\n",
      "18646 1.0\n",
      "18648 1.0\n",
      "18650 1.0\n",
      "18656 1.0\n",
      "18657 1.0\n",
      "18662 1.0\n",
      "18672 1.0\n",
      "18673 1.0\n",
      "18682 1.0\n",
      "18683 1.0\n",
      "18684 1.0\n",
      "18685 1.0\n",
      "18687 0.96484375\n",
      "18688 0.9427083333333334\n",
      "18692 1.0\n",
      "18697 0.9791666666666666\n",
      "18698 1.0\n",
      "18705 1.0\n",
      "18707 1.0\n",
      "18710 1.0\n",
      "18711 1.0\n",
      "18714 1.0\n",
      "18718 1.0\n",
      "18719 0.9375\n",
      "18722 0.9583333333333334\n",
      "18723 0.9609375\n",
      "18730 1.0\n",
      "18731 0.9375\n",
      "18734 0.8359375\n",
      "18736 1.0\n",
      "18740 1.0\n",
      "18750 1.0\n",
      "18760 1.0\n",
      "18764 0.9296875\n",
      "18766 1.0\n",
      "18767 1.0\n",
      "18770 1.0\n",
      "18772 1.0\n",
      "18776 1.0\n",
      "18777 1.0\n",
      "18785 1.0\n",
      "18794 1.0\n",
      "18796 1.0\n",
      "18797 1.0\n",
      "18801 1.0\n",
      "18804 1.0\n",
      "18808 1.0\n",
      "18812 1.0\n",
      "18814 1.0\n",
      "18815 1.0\n",
      "18816 1.0\n",
      "18827 1.0\n",
      "18829 1.0\n",
      "18833 0.96875\n",
      "18836 1.0\n",
      "18839 1.0\n",
      "18844 1.0\n",
      "18861 1.0\n",
      "18862 0.875\n",
      "18865 1.0\n",
      "18867 1.0\n",
      "18873 1.0\n",
      "18879 1.0\n",
      "18887 1.0\n",
      "18890 1.0\n",
      "18892 0.9791666666666666\n",
      "18893 1.0\n",
      "18906 1.0\n",
      "18908 1.0\n",
      "18910 1.0\n",
      "18922 1.0\n",
      "18924 1.0\n",
      "18927 0.9453125\n",
      "18929 1.0\n",
      "18930 0.9602272727272727\n",
      "18933 1.0\n",
      "18934 0.953125\n",
      "18938 1.0\n",
      "18940 1.0\n",
      "18942 1.0\n",
      "18946 1.0\n",
      "18956 1.0\n",
      "18957 1.0\n",
      "18961 1.0\n",
      "18967 1.0\n",
      "18968 1.0\n",
      "18971 1.0\n",
      "18974 1.0\n",
      "18976 1.0\n",
      "18977 1.0\n",
      "18981 1.0\n",
      "19002 1.0\n",
      "19014 1.0\n",
      "19020 1.0\n",
      "19021 1.0\n",
      "19025 0.9375\n",
      "19026 1.0\n",
      "19030 1.0\n",
      "19031 1.0\n",
      "19033 1.0\n",
      "19034 0.9652300824175825\n",
      "19040 1.0\n",
      "19042 1.0\n",
      "19045 0.9696691176470589\n",
      "19050 0.9739583333333334\n",
      "19052 1.0\n",
      "19054 1.0\n",
      "19066 1.0\n",
      "19074 1.0\n",
      "19075 1.0\n",
      "19077 1.0\n",
      "19078 1.0\n",
      "19079 1.0\n",
      "19084 1.0\n",
      "19089 1.0\n",
      "19094 1.0\n",
      "19096 1.0\n",
      "19101 1.0\n",
      "19108 0.9583333333333334\n",
      "19109 1.0\n",
      "19110 0.9801377118644068\n",
      "19112 1.0\n",
      "19114 1.0\n",
      "19115 1.0\n",
      "19123 1.0\n",
      "19131 1.0\n",
      "19132 1.0\n",
      "19138 0.9418402777777778\n",
      "19139 1.0\n",
      "19144 1.0\n",
      "19146 1.0\n",
      "19149 1.0\n",
      "19153 1.0\n",
      "19156 0.96484375\n",
      "19163 1.0\n",
      "19183 0.9643342391304348\n",
      "19186 1.0\n",
      "19193 1.0\n",
      "19194 1.0\n",
      "19201 1.0\n",
      "19202 1.0\n",
      "19205 1.0\n",
      "19210 1.0\n",
      "19213 0.9638097426470589\n",
      "19214 1.0\n",
      "19215 1.0\n",
      "19217 1.0\n",
      "19220 1.0\n",
      "19221 1.0\n",
      "19224 1.0\n",
      "19227 0.962071718931475\n",
      "19229 1.0\n",
      "19231 1.0\n",
      "19242 1.0\n",
      "19244 1.0\n",
      "19246 1.0\n",
      "19247 1.0\n",
      "19248 1.0\n",
      "19251 1.0\n",
      "19260 1.0\n",
      "19261 1.0\n",
      "19263 1.0\n",
      "19268 1.0\n",
      "19270 1.0\n",
      "19271 1.0\n",
      "19276 1.0\n",
      "19278 1.0\n",
      "19283 1.0\n",
      "19287 0.9230171783625731\n",
      "19289 1.0\n",
      "19291 1.0\n",
      "19292 1.0\n",
      "19293 0.9415922619047619\n",
      "19301 1.0\n",
      "19304 1.0\n",
      "19306 1.0\n",
      "19313 1.0\n",
      "19314 0.9296875\n",
      "19321 1.0\n",
      "19323 1.0\n",
      "19331 1.0\n",
      "19337 1.0\n",
      "19344 1.0\n",
      "19347 0.953125\n",
      "19348 1.0\n",
      "19351 1.0\n",
      "19354 1.0\n",
      "19366 1.0\n",
      "19367 0.9613042840375586\n",
      "19374 1.0\n",
      "19377 1.0\n",
      "19380 1.0\n",
      "19385 1.0\n",
      "19391 1.0\n",
      "19392 1.0\n",
      "19393 1.0\n",
      "19394 1.0\n",
      "19395 0.96875\n",
      "19396 1.0\n",
      "19397 1.0\n",
      "19401 1.0\n",
      "19405 1.0\n",
      "19409 1.0\n",
      "19413 1.0\n",
      "19415 1.0\n",
      "19417 1.0\n",
      "19418 1.0\n",
      "19420 1.0\n",
      "19421 0.9583333333333334\n",
      "19422 1.0\n",
      "19426 1.0\n",
      "19432 1.0\n",
      "19433 1.0\n",
      "19434 1.0\n",
      "19436 1.0\n",
      "19437 1.0\n",
      "19438 1.0\n",
      "19440 1.0\n",
      "19445 0.9583333333333334\n",
      "19446 1.0\n",
      "19447 0.9453125\n",
      "19448 1.0\n",
      "19451 1.0\n",
      "19454 1.0\n",
      "19455 1.0\n",
      "19456 1.0\n",
      "19458 0.9526041666666667\n",
      "19463 0.9453125\n",
      "19465 1.0\n",
      "19471 0.9166666666666666\n",
      "19478 1.0\n",
      "19483 1.0\n",
      "19485 1.0\n",
      "19490 1.0\n",
      "19491 0.9801377118644068\n",
      "19501 1.0\n",
      "19511 1.0\n",
      "19512 1.0\n",
      "19519 1.0\n",
      "19521 1.0\n",
      "19524 1.0\n",
      "19529 1.0\n",
      "19535 1.0\n",
      "19537 1.0\n",
      "19538 1.0\n",
      "19539 1.0\n",
      "19541 1.0\n",
      "19543 1.0\n",
      "19548 1.0\n",
      "19551 1.0\n",
      "19553 1.0\n",
      "19556 1.0\n",
      "19566 1.0\n",
      "19575 0.953125\n",
      "19576 1.0\n",
      "19577 1.0\n",
      "19594 0.962071718931475\n",
      "19596 1.0\n",
      "19597 1.0\n",
      "19605 1.0\n",
      "19610 0.9630208333333333\n",
      "19612 1.0\n",
      "19613 0.9541666666666667\n",
      "19614 1.0\n",
      "19625 1.0\n",
      "19627 1.0\n",
      "19628 0.9453125\n",
      "19633 1.0\n",
      "19635 1.0\n",
      "19643 1.0\n",
      "19645 1.0\n",
      "19646 1.0\n",
      "19649 1.0\n",
      "19653 0.9732142857142857\n",
      "19663 1.0\n",
      "19668 0.96875\n",
      "19677 1.0\n",
      "19679 1.0\n",
      "19683 1.0\n",
      "19689 1.0\n",
      "19690 1.0\n",
      "19691 1.0\n",
      "19692 1.0\n",
      "19693 1.0\n",
      "19694 1.0\n",
      "19696 1.0\n",
      "19697 1.0\n",
      "19698 1.0\n",
      "19699 0.9602272727272727\n",
      "19701 1.0\n",
      "19702 0.9415922619047619\n",
      "19707 1.0\n",
      "19711 1.0\n",
      "19712 0.9309895833333334\n",
      "19714 1.0\n",
      "19716 1.0\n",
      "19719 1.0\n",
      "19721 1.0\n",
      "19722 1.0\n",
      "19724 1.0\n",
      "19725 1.0\n",
      "19726 1.0\n",
      "19727 1.0\n",
      "19733 1.0\n",
      "19734 1.0\n",
      "19752 1.0\n",
      "19753 1.0\n",
      "19759 1.0\n",
      "19766 1.0\n",
      "19767 1.0\n",
      "19768 1.0\n",
      "19775 0.9793198529411765\n",
      "19776 1.0\n",
      "19781 1.0\n",
      "19785 1.0\n",
      "19787 1.0\n",
      "19793 1.0\n",
      "19799 1.0\n",
      "19801 1.0\n",
      "19802 1.0\n",
      "19803 1.0\n",
      "19810 1.0\n",
      "19811 1.0\n",
      "19812 1.0\n",
      "19813 1.0\n",
      "19815 1.0\n",
      "19819 0.9791666666666666\n",
      "19820 1.0\n",
      "19823 0.9140625\n",
      "19825 1.0\n",
      "19827 0.9625\n",
      "19829 0.9375\n",
      "19830 1.0\n",
      "19831 0.96875\n",
      "19832 1.0\n",
      "19837 0.953125\n",
      "19838 1.0\n",
      "19847 1.0\n",
      "19850 0.9652300824175825\n",
      "19853 1.0\n",
      "19859 0.9813988095238095\n",
      "19860 1.0\n",
      "19867 1.0\n",
      "19871 1.0\n",
      "19872 1.0\n",
      "19873 1.0\n",
      "19874 0.9464285714285714\n",
      "19887 1.0\n",
      "19890 1.0\n",
      "19905 0.953125\n",
      "19906 1.0\n",
      "19913 1.0\n",
      "19917 0.921875\n",
      "19918 1.0\n",
      "19919 1.0\n",
      "19926 0.962071718931475\n",
      "19931 0.96875\n",
      "19933 1.0\n",
      "19935 1.0\n",
      "19942 1.0\n",
      "19946 1.0\n",
      "19948 1.0\n",
      "19951 1.0\n",
      "19958 0.9166666666666666\n",
      "19961 1.0\n",
      "19969 1.0\n",
      "19973 1.0\n",
      "19974 1.0\n",
      "19975 1.0\n",
      "19979 1.0\n",
      "19980 1.0\n",
      "19985 1.0\n",
      "19987 1.0\n",
      "19995 1.0\n",
      "19997 1.0\n",
      "20000 1.0\n",
      "20003 1.0\n",
      "20006 1.0\n",
      "20010 1.0\n",
      "20013 1.0\n",
      "20023 1.0\n",
      "20025 1.0\n",
      "20027 1.0\n",
      "20032 1.0\n",
      "20034 1.0\n",
      "20036 0.96875\n",
      "20042 1.0\n",
      "20044 0.9583333333333334\n",
      "20049 0.9497767857142857\n",
      "20050 1.0\n",
      "20063 1.0\n",
      "20064 1.0\n",
      "20067 1.0\n",
      "20068 0.9652300824175825\n",
      "20069 1.0\n",
      "20072 1.0\n",
      "20077 1.0\n",
      "20080 0.984375\n",
      "20082 1.0\n",
      "20089 1.0\n",
      "20090 1.0\n",
      "20092 1.0\n",
      "20096 1.0\n",
      "20102 1.0\n",
      "20107 1.0\n",
      "20112 1.0\n",
      "20114 1.0\n",
      "20122 1.0\n",
      "20132 1.0\n",
      "20134 1.0\n",
      "20136 1.0\n",
      "20140 1.0\n",
      "20141 0.9801377118644068\n",
      "20142 1.0\n",
      "20156 0.9575892857142857\n",
      "20158 1.0\n",
      "20159 1.0\n",
      "20160 0.9449404761904762\n",
      "20162 1.0\n",
      "20166 1.0\n",
      "20167 1.0\n",
      "20172 1.0\n",
      "20173 0.962071718931475\n",
      "20176 1.0\n",
      "20178 1.0\n",
      "20182 1.0\n",
      "20188 1.0\n",
      "20190 1.0\n",
      "20191 1.0\n",
      "20194 1.0\n",
      "20197 1.0\n",
      "20199 0.96875\n",
      "20202 1.0\n",
      "20205 1.0\n",
      "20209 0.953125\n",
      "20212 0.9375\n",
      "20215 1.0\n",
      "20216 1.0\n",
      "20218 0.9765625\n",
      "20221 1.0\n",
      "20222 1.0\n",
      "20226 1.0\n",
      "20227 1.0\n",
      "20232 1.0\n",
      "20235 1.0\n",
      "20237 1.0\n",
      "20242 1.0\n",
      "20245 0.9583333333333334\n",
      "20246 0.9642857142857143\n",
      "20247 1.0\n",
      "20250 1.0\n",
      "20252 1.0\n",
      "20253 1.0\n",
      "20254 1.0\n",
      "20257 1.0\n",
      "20269 1.0\n",
      "20274 1.0\n",
      "20276 1.0\n",
      "20277 1.0\n",
      "20283 1.0\n",
      "20284 1.0\n",
      "20285 1.0\n",
      "20286 1.0\n",
      "20287 0.9791666666666666\n",
      "20290 1.0\n",
      "20291 1.0\n",
      "20301 1.0\n",
      "20308 1.0\n",
      "20311 1.0\n",
      "20315 1.0\n",
      "20320 1.0\n",
      "20321 1.0\n",
      "20327 1.0\n",
      "20335 1.0\n",
      "20338 1.0\n",
      "20348 1.0\n",
      "20349 1.0\n",
      "20352 1.0\n",
      "20353 0.9497767857142857\n",
      "20360 1.0\n",
      "20364 0.9609375\n",
      "20365 1.0\n",
      "20366 1.0\n",
      "20372 0.9765625\n",
      "20374 1.0\n",
      "20376 0.9296875\n",
      "20377 1.0\n",
      "20386 1.0\n",
      "20397 1.0\n",
      "20399 1.0\n",
      "20400 1.0\n",
      "20401 0.9754901960784313\n",
      "20404 1.0\n",
      "20405 1.0\n",
      "20407 1.0\n",
      "20410 1.0\n",
      "20421 1.0\n",
      "20422 1.0\n",
      "20424 1.0\n",
      "20429 1.0\n",
      "20436 1.0\n",
      "20446 1.0\n",
      "20448 1.0\n",
      "20459 1.0\n",
      "20469 0.9337121212121212\n",
      "20473 1.0\n",
      "20476 0.9857954545454546\n",
      "20477 1.0\n",
      "20479 1.0\n",
      "20496 0.9635416666666666\n",
      "20509 1.0\n",
      "20510 1.0\n",
      "20512 0.9696691176470589\n",
      "20514 0.9609375\n",
      "20524 1.0\n",
      "20527 1.0\n",
      "20529 1.0\n",
      "20532 1.0\n",
      "20534 1.0\n",
      "20536 0.9375\n",
      "20538 1.0\n",
      "20544 1.0\n",
      "20552 1.0\n",
      "20556 1.0\n",
      "20557 1.0\n",
      "20558 1.0\n",
      "20564 1.0\n",
      "20565 1.0\n",
      "20566 0.9296875\n",
      "20567 0.9437872023809524\n",
      "20571 1.0\n",
      "20576 1.0\n",
      "20582 1.0\n",
      "20583 1.0\n",
      "20584 1.0\n",
      "20585 1.0\n",
      "20589 1.0\n",
      "20592 0.921875\n",
      "20601 1.0\n",
      "20602 0.9140625\n",
      "20606 1.0\n",
      "20610 1.0\n",
      "20613 1.0\n",
      "20614 1.0\n",
      "20616 1.0\n",
      "20617 1.0\n",
      "20620 1.0\n",
      "20621 1.0\n",
      "20625 1.0\n",
      "20627 0.9578125\n",
      "20628 0.9337121212121212\n",
      "20631 1.0\n",
      "20639 1.0\n",
      "20642 1.0\n",
      "20643 1.0\n",
      "20655 0.9635416666666666\n",
      "20660 1.0\n",
      "20661 1.0\n",
      "20662 0.9241071428571429\n",
      "20664 1.0\n",
      "20666 1.0\n",
      "20669 1.0\n",
      "20671 1.0\n",
      "20674 0.9088541666666666\n",
      "20675 1.0\n",
      "20678 1.0\n",
      "20680 0.958984375\n",
      "20685 1.0\n",
      "20691 0.9783653846153846\n",
      "20692 1.0\n",
      "20693 1.0\n",
      "20695 1.0\n",
      "20698 0.9449404761904762\n",
      "20700 1.0\n",
      "20707 1.0\n",
      "20708 1.0\n",
      "20711 1.0\n",
      "20713 1.0\n",
      "20716 1.0\n",
      "20722 1.0\n",
      "20723 0.9739583333333334\n",
      "20729 1.0\n",
      "20730 1.0\n",
      "20731 1.0\n",
      "20735 0.9375\n",
      "20740 1.0\n",
      "20741 1.0\n",
      "20758 1.0\n",
      "20761 1.0\n",
      "20763 1.0\n",
      "20765 0.9588815789473685\n",
      "20769 0.9598214285714286\n",
      "20774 1.0\n",
      "20776 1.0\n",
      "20781 1.0\n",
      "20782 1.0\n",
      "20785 1.0\n",
      "20786 1.0\n",
      "20794 1.0\n",
      "20797 0.9729567307692307\n",
      "20801 1.0\n",
      "20804 1.0\n",
      "20807 0.96484375\n",
      "20808 1.0\n",
      "20813 1.0\n",
      "20818 1.0\n",
      "20821 1.0\n",
      "20829 1.0\n",
      "20836 1.0\n",
      "20839 1.0\n",
      "20845 1.0\n",
      "20846 1.0\n",
      "20847 1.0\n",
      "20850 1.0\n",
      "20857 1.0\n",
      "20859 1.0\n",
      "20861 1.0\n",
      "20865 0.9783653846153846\n",
      "20867 0.962071718931475\n",
      "20873 1.0\n",
      "20875 1.0\n",
      "20876 1.0\n",
      "20883 1.0\n",
      "20884 1.0\n",
      "20885 1.0\n",
      "20889 0.921875\n",
      "20895 1.0\n",
      "20901 1.0\n",
      "20903 0.9296875\n",
      "20908 1.0\n",
      "20911 1.0\n",
      "20920 1.0\n",
      "20921 1.0\n",
      "20925 1.0\n",
      "20927 1.0\n",
      "20929 1.0\n",
      "20932 1.0\n",
      "20937 1.0\n",
      "20940 1.0\n",
      "20944 1.0\n",
      "20948 1.0\n",
      "20951 1.0\n",
      "20952 1.0\n",
      "20954 1.0\n",
      "20959 1.0\n",
      "20960 1.0\n",
      "20962 1.0\n",
      "20966 0.9588815789473685\n",
      "20972 0.9729567307692307\n",
      "20982 0.921875\n",
      "20987 1.0\n",
      "21000 1.0\n",
      "21001 0.9422679227941176\n",
      "21002 1.0\n",
      "21004 1.0\n",
      "21010 1.0\n",
      "21015 0.9665178571428571\n",
      "21017 0.890625\n",
      "21019 1.0\n",
      "21022 1.0\n",
      "21023 1.0\n",
      "21028 1.0\n",
      "21038 1.0\n",
      "21039 0.9526041666666667\n",
      "21041 1.0\n",
      "21043 1.0\n",
      "21044 1.0\n",
      "21048 1.0\n",
      "21053 1.0\n",
      "21055 0.9375\n",
      "21063 1.0\n",
      "21064 1.0\n",
      "21070 1.0\n",
      "21076 1.0\n",
      "21077 1.0\n",
      "21080 1.0\n",
      "21085 1.0\n",
      "21088 1.0\n",
      "21092 0.9375\n",
      "21093 1.0\n",
      "21095 1.0\n",
      "21100 0.9449404761904762\n",
      "21101 0.9583333333333334\n",
      "21103 1.0\n",
      "21105 0.9495192307692307\n",
      "21107 1.0\n",
      "21108 0.90625\n",
      "21112 0.9791666666666666\n",
      "21115 1.0\n",
      "21119 1.0\n",
      "21121 1.0\n",
      "21125 1.0\n",
      "21141 0.9296875\n",
      "21147 1.0\n",
      "21148 1.0\n",
      "21149 1.0\n",
      "21150 1.0\n",
      "21156 1.0\n",
      "21160 1.0\n",
      "21169 1.0\n",
      "21170 1.0\n",
      "21171 1.0\n",
      "21174 0.9765625\n",
      "21176 1.0\n",
      "21180 0.965625\n",
      "21182 0.9621975806451613\n",
      "21184 0.9375\n",
      "21185 1.0\n",
      "21186 1.0\n",
      "21190 1.0\n",
      "21194 1.0\n",
      "21206 1.0\n",
      "21211 1.0\n",
      "21218 1.0\n",
      "21219 1.0\n",
      "21221 1.0\n",
      "21223 1.0\n",
      "21224 1.0\n",
      "21227 1.0\n",
      "21228 1.0\n",
      "21232 1.0\n",
      "21239 1.0\n",
      "21243 1.0\n",
      "21244 1.0\n",
      "21252 1.0\n",
      "21263 1.0\n",
      "21269 1.0\n",
      "21270 1.0\n",
      "21271 0.953125\n",
      "21273 0.984375\n",
      "21280 1.0\n",
      "21281 1.0\n",
      "21290 1.0\n",
      "21291 1.0\n",
      "21294 1.0\n",
      "21297 1.0\n",
      "21298 1.0\n",
      "21299 1.0\n",
      "21300 1.0\n",
      "21303 1.0\n",
      "21307 1.0\n",
      "21310 1.0\n",
      "21314 1.0\n",
      "21317 0.9140625\n",
      "21318 1.0\n",
      "21321 1.0\n",
      "21336 1.0\n",
      "21337 1.0\n",
      "21339 1.0\n",
      "21340 0.9558035714285714\n",
      "21344 0.96875\n",
      "21350 1.0\n",
      "21352 1.0\n",
      "21353 1.0\n",
      "21355 1.0\n",
      "21357 1.0\n",
      "21358 1.0\n",
      "21362 1.0\n",
      "21367 1.0\n",
      "21370 1.0\n",
      "21375 1.0\n",
      "21378 1.0\n",
      "21383 1.0\n",
      "21385 1.0\n",
      "21396 1.0\n",
      "21397 1.0\n",
      "21398 1.0\n",
      "21402 1.0\n",
      "21409 1.0\n",
      "21414 0.96875\n",
      "21419 1.0\n",
      "21422 1.0\n",
      "21426 1.0\n",
      "21431 1.0\n",
      "21434 1.0\n",
      "21440 1.0\n",
      "21446 0.9484375\n",
      "21450 1.0\n",
      "21453 1.0\n",
      "21454 1.0\n",
      "21455 1.0\n",
      "21456 1.0\n",
      "21459 0.953125\n",
      "21464 0.9556107954545454\n",
      "21465 0.96875\n",
      "21466 1.0\n",
      "21473 1.0\n",
      "21474 0.9765625\n",
      "21475 1.0\n",
      "21476 1.0\n",
      "21478 1.0\n",
      "21487 1.0\n",
      "21488 1.0\n",
      "21493 1.0\n",
      "21496 1.0\n",
      "21500 1.0\n",
      "21506 1.0\n",
      "21507 1.0\n",
      "21509 1.0\n",
      "21514 0.9453125\n",
      "21516 1.0\n",
      "21517 1.0\n",
      "21518 1.0\n",
      "21522 1.0\n",
      "21528 1.0\n",
      "21531 1.0\n",
      "21534 1.0\n",
      "21535 0.9765625\n",
      "21538 0.9453125\n",
      "21539 1.0\n",
      "21544 1.0\n",
      "21545 0.953125\n",
      "21563 1.0\n",
      "21568 1.0\n",
      "21569 1.0\n",
      "21572 1.0\n",
      "21576 1.0\n",
      "21580 0.9732142857142857\n",
      "21582 1.0\n",
      "21583 1.0\n",
      "21584 1.0\n",
      "21586 1.0\n",
      "21593 1.0\n",
      "21594 1.0\n",
      "21596 0.9453125\n",
      "21598 1.0\n",
      "21599 1.0\n",
      "21600 1.0\n",
      "21601 1.0\n",
      "21605 1.0\n",
      "21607 1.0\n",
      "21608 1.0\n",
      "21610 1.0\n",
      "21615 0.96875\n",
      "21617 1.0\n",
      "21625 0.9696691176470589\n",
      "21627 1.0\n",
      "21631 0.890625\n",
      "21637 1.0\n",
      "21641 1.0\n",
      "21642 1.0\n",
      "21644 1.0\n",
      "21645 1.0\n",
      "21646 1.0\n",
      "21650 1.0\n",
      "21656 0.84375\n",
      "21660 1.0\n",
      "21667 1.0\n",
      "21673 1.0\n",
      "21677 1.0\n",
      "21682 0.9609375\n",
      "21683 1.0\n",
      "21687 1.0\n",
      "21688 1.0\n",
      "21689 0.9635416666666666\n",
      "21705 0.9453125\n",
      "21714 1.0\n",
      "21716 1.0\n",
      "21722 1.0\n",
      "21725 1.0\n",
      "21730 1.0\n",
      "21738 0.9793198529411765\n",
      "21740 1.0\n",
      "21748 1.0\n",
      "21749 0.96484375\n",
      "21773 0.9609375\n",
      "21778 1.0\n",
      "21780 1.0\n",
      "21784 1.0\n",
      "21787 1.0\n",
      "21791 0.9765625\n",
      "21792 1.0\n",
      "21796 1.0\n",
      "21800 0.9817708333333334\n",
      "21803 1.0\n",
      "21814 1.0\n",
      "21822 0.9541666666666667\n",
      "21825 0.9583333333333334\n",
      "21826 1.0\n",
      "21829 1.0\n",
      "21835 1.0\n",
      "21837 1.0\n",
      "21844 1.0\n",
      "21845 0.9643342391304348\n",
      "21849 1.0\n",
      "21852 1.0\n",
      "21857 1.0\n",
      "21860 1.0\n",
      "21864 1.0\n",
      "21867 1.0\n",
      "21873 1.0\n",
      "21876 0.9801377118644068\n",
      "21879 1.0\n",
      "21895 0.9352678571428571\n",
      "21896 1.0\n",
      "21902 1.0\n",
      "21906 1.0\n",
      "21907 1.0\n",
      "21909 1.0\n",
      "21911 1.0\n",
      "21912 1.0\n",
      "21913 1.0\n",
      "21916 1.0\n",
      "21917 1.0\n",
      "21918 1.0\n",
      "21920 1.0\n",
      "21924 1.0\n",
      "21926 1.0\n",
      "21931 1.0\n",
      "21938 1.0\n",
      "21944 1.0\n",
      "21951 1.0\n",
      "21954 1.0\n",
      "21957 1.0\n",
      "21961 1.0\n",
      "21962 0.971875\n",
      "21965 1.0\n",
      "21967 1.0\n",
      "21969 1.0\n",
      "21978 0.953125\n",
      "21985 0.9140625\n",
      "21986 1.0\n",
      "21987 1.0\n",
      "21988 0.9697916666666667\n",
      "21990 1.0\n",
      "21997 1.0\n",
      "22002 1.0\n",
      "22004 1.0\n",
      "22005 1.0\n",
      "22009 1.0\n",
      "22011 0.9541666666666667\n",
      "22013 1.0\n",
      "22017 1.0\n",
      "22018 1.0\n",
      "22038 1.0\n",
      "22045 1.0\n",
      "22054 0.9817708333333334\n",
      "22057 1.0\n",
      "22058 1.0\n",
      "22059 1.0\n",
      "22061 1.0\n",
      "22062 1.0\n",
      "22071 1.0\n",
      "22073 1.0\n",
      "22077 1.0\n",
      "22086 0.9479166666666666\n",
      "22087 0.96875\n",
      "22092 0.9801377118644068\n",
      "22103 0.9397321428571429\n",
      "22106 1.0\n",
      "22107 1.0\n",
      "22108 1.0\n",
      "22114 1.0\n",
      "22116 1.0\n",
      "22121 1.0\n",
      "22122 1.0\n",
      "22124 1.0\n",
      "22125 1.0\n",
      "22128 1.0\n",
      "22132 1.0\n",
      "22136 1.0\n",
      "22142 1.0\n",
      "22147 1.0\n",
      "22148 0.921875\n",
      "22156 0.953125\n",
      "22167 1.0\n",
      "22170 1.0\n",
      "22172 1.0\n",
      "22173 0.9375\n",
      "22176 1.0\n",
      "22181 1.0\n",
      "22185 1.0\n",
      "22187 0.875\n",
      "22190 0.9453125\n",
      "22197 1.0\n",
      "22198 1.0\n",
      "22212 1.0\n",
      "22214 1.0\n",
      "22219 1.0\n",
      "22221 1.0\n",
      "22229 1.0\n",
      "22230 1.0\n",
      "22233 1.0\n",
      "22236 0.971875\n",
      "22238 0.9609375\n",
      "22254 1.0\n",
      "22258 1.0\n",
      "22259 1.0\n",
      "22262 1.0\n",
      "22263 1.0\n",
      "22264 1.0\n",
      "22269 0.9635416666666666\n",
      "22271 1.0\n",
      "22273 1.0\n",
      "22275 1.0\n",
      "22283 1.0\n",
      "22285 1.0\n",
      "22293 1.0\n",
      "22294 1.0\n",
      "22295 0.9375\n",
      "22298 0.9541666666666667\n",
      "22302 1.0\n",
      "22304 0.9765625\n",
      "22308 1.0\n",
      "22314 0.9464285714285714\n",
      "22317 1.0\n",
      "22324 1.0\n",
      "22325 0.9427083333333334\n",
      "22334 1.0\n",
      "22343 0.9621975806451613\n",
      "22344 1.0\n",
      "22345 1.0\n",
      "22346 0.9665178571428571\n",
      "22350 1.0\n",
      "22351 1.0\n",
      "22352 1.0\n",
      "22361 1.0\n",
      "22362 0.9497767857142857\n",
      "22366 1.0\n",
      "22375 1.0\n",
      "22376 1.0\n",
      "22377 1.0\n",
      "22380 1.0\n",
      "22381 1.0\n",
      "22384 1.0\n",
      "22388 1.0\n",
      "22389 1.0\n",
      "22390 1.0\n",
      "22391 1.0\n",
      "22393 1.0\n",
      "22397 1.0\n",
      "22410 1.0\n",
      "22413 1.0\n",
      "22415 1.0\n",
      "22416 0.9375\n",
      "22420 1.0\n",
      "22427 1.0\n",
      "22429 1.0\n",
      "22430 1.0\n",
      "22435 1.0\n",
      "22441 1.0\n",
      "22443 1.0\n",
      "22449 1.0\n",
      "22450 1.0\n",
      "22452 0.9765625\n",
      "22464 1.0\n",
      "22469 0.9621975806451613\n",
      "22474 0.9765625\n",
      "22476 1.0\n",
      "22478 1.0\n",
      "22482 0.9186197916666666\n",
      "22483 1.0\n",
      "22484 1.0\n",
      "22486 1.0\n",
      "22489 1.0\n",
      "22497 0.9166666666666666\n",
      "22499 1.0\n",
      "22508 1.0\n",
      "22513 1.0\n",
      "22515 1.0\n",
      "22523 1.0\n",
      "22525 1.0\n",
      "22528 1.0\n",
      "22530 1.0\n",
      "22532 1.0\n",
      "22543 1.0\n",
      "22544 0.921875\n",
      "22549 1.0\n",
      "22551 1.0\n",
      "22555 1.0\n",
      "22556 1.0\n",
      "22558 1.0\n",
      "22568 1.0\n",
      "22576 1.0\n",
      "22578 1.0\n",
      "22581 0.9388020833333334\n",
      "22583 1.0\n",
      "22586 1.0\n",
      "22588 1.0\n",
      "22591 0.9609375\n",
      "22592 1.0\n",
      "22596 1.0\n",
      "22599 1.0\n",
      "22601 1.0\n",
      "22604 0.9296875\n",
      "22605 1.0\n",
      "22608 1.0\n",
      "22612 1.0\n",
      "22622 1.0\n",
      "22627 1.0\n",
      "22631 1.0\n",
      "22634 1.0\n",
      "22646 1.0\n",
      "22652 1.0\n",
      "22654 1.0\n",
      "22655 1.0\n",
      "22659 1.0\n",
      "22666 0.965625\n",
      "22670 1.0\n",
      "22672 1.0\n",
      "22676 1.0\n",
      "22677 1.0\n",
      "22678 0.9830013736263736\n",
      "22679 1.0\n",
      "22680 1.0\n",
      "22682 1.0\n",
      "22683 1.0\n",
      "22687 1.0\n",
      "22689 0.96875\n",
      "22690 1.0\n",
      "22698 1.0\n",
      "22707 0.9449404761904762\n",
      "22708 1.0\n",
      "22711 1.0\n",
      "22712 1.0\n",
      "22718 1.0\n",
      "22722 1.0\n",
      "22727 1.0\n",
      "22729 1.0\n",
      "22730 1.0\n",
      "22736 0.9556107954545454\n",
      "22743 1.0\n",
      "22745 1.0\n",
      "22746 1.0\n",
      "22748 0.9799107142857143\n",
      "22750 1.0\n",
      "22755 0.96875\n",
      "22762 1.0\n",
      "22763 1.0\n",
      "22764 0.9643342391304348\n",
      "22766 1.0\n",
      "22767 1.0\n",
      "22768 1.0\n",
      "22771 0.9793198529411765\n",
      "22772 0.9765625\n",
      "22775 1.0\n",
      "22776 1.0\n",
      "22779 1.0\n",
      "22790 1.0\n",
      "22796 1.0\n",
      "22800 1.0\n",
      "22801 1.0\n",
      "22803 0.97265625\n",
      "22809 1.0\n",
      "22822 0.9453125\n",
      "22827 1.0\n",
      "22828 1.0\n",
      "22829 1.0\n",
      "22830 1.0\n",
      "22838 0.9793198529411765\n",
      "22843 1.0\n",
      "22851 1.0\n",
      "22853 1.0\n",
      "22854 1.0\n",
      "22862 1.0\n",
      "22864 1.0\n",
      "22869 1.0\n",
      "22876 0.962071718931475\n",
      "22881 1.0\n",
      "22882 1.0\n",
      "22886 1.0\n",
      "22888 1.0\n",
      "22892 1.0\n",
      "22895 1.0\n",
      "22898 1.0\n",
      "22900 1.0\n",
      "22903 1.0\n",
      "22908 1.0\n",
      "22915 1.0\n",
      "22916 0.9635416666666666\n",
      "22921 1.0\n",
      "22927 1.0\n",
      "22929 1.0\n",
      "22930 1.0\n",
      "22937 1.0\n",
      "22944 1.0\n",
      "22946 1.0\n",
      "22948 1.0\n",
      "22954 1.0\n",
      "22960 1.0\n",
      "22961 1.0\n",
      "22962 1.0\n",
      "22963 1.0\n",
      "22964 1.0\n",
      "22971 1.0\n",
      "22973 1.0\n",
      "22978 1.0\n",
      "22980 1.0\n",
      "22990 0.9609375\n",
      "22991 1.0\n",
      "22998 1.0\n",
      "23006 1.0\n",
      "23012 0.9609375\n",
      "23020 1.0\n",
      "23024 1.0\n",
      "23032 1.0\n",
      "23034 1.0\n",
      "23036 1.0\n",
      "23039 0.9583333333333334\n",
      "23040 1.0\n",
      "23044 1.0\n",
      "23045 1.0\n",
      "23046 1.0\n",
      "23047 1.0\n",
      "23050 1.0\n",
      "23051 1.0\n",
      "23057 1.0\n",
      "23061 1.0\n",
      "23064 1.0\n",
      "23067 1.0\n",
      "23074 1.0\n",
      "23079 1.0\n",
      "23093 1.0\n",
      "23094 1.0\n",
      "23100 1.0\n",
      "23107 1.0\n",
      "23109 1.0\n",
      "23115 1.0\n",
      "23118 1.0\n",
      "23125 0.9739583333333334\n",
      "23128 1.0\n",
      "23129 1.0\n",
      "23134 1.0\n",
      "23140 1.0\n",
      "23144 1.0\n",
      "23146 1.0\n",
      "23147 1.0\n",
      "23150 1.0\n",
      "23160 1.0\n",
      "23169 1.0\n",
      "23180 1.0\n",
      "23183 0.9895833333333334\n",
      "23184 0.958984375\n",
      "23186 1.0\n",
      "23187 1.0\n",
      "23188 1.0\n",
      "23189 1.0\n",
      "23193 1.0\n",
      "23194 0.9140625\n",
      "23215 1.0\n",
      "23221 1.0\n",
      "23223 1.0\n",
      "23224 1.0\n",
      "23226 1.0\n",
      "23233 1.0\n",
      "23238 0.9583333333333334\n",
      "23240 0.9801377118644068\n",
      "23244 1.0\n",
      "23245 1.0\n",
      "23250 1.0\n",
      "23251 0.90625\n",
      "23252 1.0\n",
      "23254 1.0\n",
      "23255 0.962071718931475\n",
      "23256 0.9583333333333334\n",
      "23257 1.0\n",
      "23261 0.9754901960784313\n",
      "23264 0.9375\n",
      "23270 1.0\n",
      "23272 1.0\n",
      "23275 1.0\n",
      "23282 1.0\n",
      "23284 1.0\n",
      "23287 1.0\n",
      "23288 1.0\n",
      "23292 1.0\n",
      "23293 1.0\n",
      "23299 0.9638097426470589\n",
      "23300 1.0\n",
      "23304 1.0\n",
      "23306 1.0\n",
      "23307 0.9583333333333334\n",
      "23314 1.0\n",
      "23320 1.0\n",
      "23321 1.0\n",
      "23324 1.0\n",
      "23326 1.0\n",
      "23327 1.0\n",
      "23328 1.0\n",
      "23330 0.9422679227941176\n",
      "23332 1.0\n",
      "23336 1.0\n",
      "23337 1.0\n",
      "23338 1.0\n",
      "23346 0.9575892857142857\n",
      "23347 1.0\n",
      "23356 1.0\n",
      "23358 1.0\n",
      "23365 1.0\n",
      "23367 1.0\n",
      "23368 1.0\n",
      "23371 1.0\n",
      "23372 1.0\n",
      "23375 1.0\n",
      "23377 1.0\n",
      "23381 1.0\n",
      "23385 1.0\n",
      "23386 0.828125\n",
      "23388 1.0\n",
      "23389 0.965625\n",
      "23390 1.0\n",
      "23391 1.0\n",
      "23392 1.0\n",
      "23394 1.0\n",
      "23397 1.0\n",
      "23401 1.0\n",
      "23406 1.0\n",
      "23412 1.0\n",
      "23417 1.0\n",
      "23419 1.0\n",
      "23420 0.9739583333333334\n",
      "23421 1.0\n",
      "23424 1.0\n",
      "23425 1.0\n",
      "23440 1.0\n",
      "23442 1.0\n",
      "23444 0.9541666666666667\n",
      "23455 1.0\n",
      "23457 0.94140625\n",
      "23465 1.0\n",
      "23466 1.0\n",
      "23467 1.0\n",
      "23473 1.0\n",
      "23481 1.0\n",
      "23487 1.0\n",
      "23492 1.0\n",
      "23496 1.0\n",
      "23499 1.0\n",
      "23503 1.0\n",
      "23504 1.0\n",
      "23507 1.0\n",
      "23509 1.0\n",
      "23511 1.0\n",
      "23514 1.0\n",
      "23515 1.0\n",
      "23517 0.97265625\n",
      "23518 1.0\n",
      "23525 1.0\n",
      "23532 1.0\n",
      "23533 1.0\n",
      "23534 1.0\n",
      "23539 0.96484375\n",
      "23540 1.0\n",
      "23541 1.0\n",
      "23544 1.0\n",
      "23547 0.9765625\n",
      "23552 1.0\n",
      "23553 0.98046875\n",
      "23559 1.0\n",
      "23562 1.0\n",
      "23569 1.0\n",
      "23574 1.0\n",
      "23575 1.0\n",
      "23577 1.0\n",
      "23606 0.9739583333333334\n",
      "23611 1.0\n",
      "23615 1.0\n",
      "23626 1.0\n",
      "23627 1.0\n",
      "23628 1.0\n",
      "23633 1.0\n",
      "23634 1.0\n",
      "23636 1.0\n",
      "23640 1.0\n",
      "23642 1.0\n",
      "23644 1.0\n",
      "23651 1.0\n",
      "23653 1.0\n",
      "23666 1.0\n",
      "23680 1.0\n",
      "23682 1.0\n",
      "23688 0.9556107954545454\n",
      "23690 1.0\n",
      "23700 1.0\n",
      "23701 1.0\n",
      "23703 1.0\n",
      "23706 1.0\n",
      "23708 1.0\n",
      "23712 1.0\n",
      "23713 1.0\n",
      "23714 0.962071718931475\n",
      "23718 1.0\n",
      "23719 1.0\n",
      "23720 1.0\n",
      "23722 1.0\n",
      "23725 0.9665178571428571\n",
      "23726 1.0\n",
      "23728 0.9446022727272727\n",
      "23730 1.0\n",
      "23733 1.0\n",
      "23736 0.9675324675324676\n",
      "23737 1.0\n",
      "23740 1.0\n",
      "23742 1.0\n",
      "23744 1.0\n",
      "23745 1.0\n",
      "23747 0.9602272727272727\n",
      "23748 0.9427083333333334\n",
      "23749 1.0\n",
      "23751 1.0\n",
      "23753 1.0\n",
      "23756 1.0\n",
      "23757 0.9635416666666666\n",
      "23760 1.0\n",
      "23764 0.971875\n",
      "23768 1.0\n",
      "23769 0.9416666666666667\n",
      "23770 1.0\n",
      "23776 1.0\n",
      "23777 1.0\n",
      "23779 1.0\n",
      "23781 1.0\n",
      "23783 1.0\n",
      "23786 1.0\n",
      "23793 0.9558035714285714\n",
      "23794 1.0\n",
      "23798 1.0\n",
      "23799 1.0\n",
      "23800 1.0\n",
      "23802 0.9754901960784313\n",
      "23806 1.0\n",
      "23811 1.0\n",
      "23812 1.0\n",
      "23817 1.0\n",
      "23821 1.0\n",
      "23822 1.0\n",
      "23826 1.0\n",
      "23830 1.0\n",
      "23834 1.0\n",
      "23836 1.0\n",
      "23839 1.0\n",
      "23860 1.0\n",
      "23868 1.0\n",
      "23871 1.0\n",
      "23874 1.0\n",
      "23881 1.0\n",
      "23882 0.9375\n",
      "23883 1.0\n",
      "23887 1.0\n",
      "23888 1.0\n",
      "23892 1.0\n",
      "23893 1.0\n",
      "23896 1.0\n",
      "23897 1.0\n",
      "23907 0.90625\n",
      "23908 1.0\n",
      "23911 1.0\n",
      "23914 1.0\n",
      "23925 1.0\n",
      "23932 1.0\n",
      "23934 1.0\n",
      "23936 1.0\n",
      "23937 1.0\n",
      "23940 1.0\n",
      "23942 1.0\n",
      "23944 1.0\n",
      "23945 1.0\n",
      "23948 1.0\n",
      "23956 1.0\n",
      "23966 1.0\n",
      "23969 1.0\n",
      "23976 1.0\n",
      "23978 1.0\n",
      "23979 1.0\n",
      "23983 1.0\n",
      "23985 1.0\n",
      "23987 1.0\n",
      "23995 1.0\n",
      "24001 1.0\n",
      "24002 1.0\n",
      "24003 0.8958333333333334\n",
      "24005 1.0\n",
      "24009 1.0\n",
      "24010 1.0\n",
      "24012 1.0\n",
      "24022 1.0\n",
      "24026 1.0\n",
      "24039 1.0\n",
      "24041 1.0\n",
      "24042 0.9453125\n",
      "24052 1.0\n",
      "24060 1.0\n",
      "24065 1.0\n",
      "24070 1.0\n",
      "24073 1.0\n",
      "24074 1.0\n",
      "24076 1.0\n",
      "24077 1.0\n",
      "24089 1.0\n",
      "24090 1.0\n",
      "24098 1.0\n",
      "24099 0.9862132352941176\n",
      "24103 1.0\n",
      "24107 1.0\n",
      "24110 1.0\n",
      "24111 1.0\n",
      "24116 0.9609375\n",
      "24118 1.0\n",
      "24121 1.0\n",
      "24122 1.0\n",
      "24126 1.0\n",
      "24127 1.0\n",
      "24131 1.0\n",
      "24133 0.9392361111111112\n",
      "24135 1.0\n",
      "24137 1.0\n",
      "24139 1.0\n",
      "24140 0.9583333333333334\n",
      "24152 0.9635416666666666\n",
      "24162 0.9583333333333334\n",
      "24163 1.0\n",
      "24167 1.0\n",
      "24170 1.0\n",
      "24174 0.9801377118644068\n",
      "24175 1.0\n",
      "24181 1.0\n",
      "24185 1.0\n",
      "24188 1.0\n",
      "24189 1.0\n",
      "24191 1.0\n",
      "24194 1.0\n",
      "24203 1.0\n",
      "24207 1.0\n",
      "24215 1.0\n",
      "24216 1.0\n",
      "24219 1.0\n",
      "24221 1.0\n",
      "24222 1.0\n",
      "24232 1.0\n",
      "24233 0.9352678571428571\n",
      "24236 1.0\n",
      "24240 1.0\n",
      "24242 1.0\n",
      "24244 1.0\n",
      "24245 0.958984375\n",
      "24249 1.0\n",
      "24253 1.0\n",
      "24257 1.0\n",
      "24258 1.0\n",
      "24260 1.0\n",
      "24265 1.0\n",
      "24266 0.9635416666666666\n",
      "24267 1.0\n",
      "24270 1.0\n",
      "24273 1.0\n",
      "24278 1.0\n",
      "24279 1.0\n",
      "24284 1.0\n",
      "24285 1.0\n",
      "24291 1.0\n",
      "24292 1.0\n",
      "24294 1.0\n",
      "24296 1.0\n",
      "24309 1.0\n",
      "24311 1.0\n",
      "24315 1.0\n",
      "24319 1.0\n",
      "24323 0.9296875\n",
      "24324 1.0\n",
      "24325 1.0\n",
      "24331 0.9801377118644068\n",
      "24336 0.962071718931475\n",
      "24340 0.921875\n",
      "24343 1.0\n",
      "24345 0.9453125\n",
      "24350 1.0\n",
      "24351 1.0\n",
      "24356 1.0\n",
      "24359 1.0\n",
      "24363 1.0\n",
      "24365 1.0\n",
      "24367 1.0\n",
      "24373 1.0\n",
      "24379 1.0\n",
      "24381 1.0\n",
      "24383 1.0\n",
      "24384 1.0\n",
      "24387 1.0\n",
      "24389 1.0\n",
      "24391 1.0\n",
      "24392 0.9609375\n",
      "24396 0.9497767857142857\n",
      "24399 0.9453125\n",
      "24403 1.0\n",
      "24409 1.0\n",
      "24425 1.0\n",
      "24428 1.0\n",
      "24432 1.0\n",
      "24435 1.0\n",
      "24444 1.0\n",
      "24445 1.0\n",
      "24449 1.0\n",
      "24450 1.0\n",
      "24451 1.0\n",
      "24454 0.9652300824175825\n",
      "24455 0.9479166666666666\n",
      "24463 1.0\n",
      "24464 1.0\n",
      "24466 1.0\n",
      "24468 1.0\n",
      "24472 1.0\n",
      "24473 0.953125\n",
      "24474 1.0\n",
      "24479 1.0\n",
      "24482 1.0\n",
      "24485 1.0\n",
      "24486 1.0\n",
      "24491 1.0\n",
      "24498 1.0\n",
      "24500 1.0\n",
      "24501 1.0\n",
      "24506 0.9505208333333334\n",
      "24507 1.0\n",
      "24510 0.9572458791208791\n",
      "24511 1.0\n",
      "24518 0.9791666666666666\n",
      "24523 1.0\n",
      "24528 0.8671875\n",
      "24529 1.0\n",
      "24531 1.0\n",
      "24533 1.0\n",
      "24534 1.0\n",
      "24539 1.0\n",
      "24543 1.0\n",
      "24544 1.0\n",
      "24546 0.9801377118644068\n",
      "24549 1.0\n",
      "24569 0.9813988095238095\n",
      "24574 1.0\n",
      "24581 1.0\n",
      "24586 1.0\n",
      "24590 1.0\n",
      "24591 1.0\n",
      "24592 1.0\n",
      "24593 1.0\n",
      "24600 1.0\n",
      "24602 1.0\n",
      "24603 1.0\n",
      "24604 1.0\n",
      "24612 0.9296875\n",
      "24614 1.0\n",
      "24615 1.0\n",
      "24616 1.0\n",
      "24618 1.0\n",
      "24620 1.0\n",
      "24628 1.0\n",
      "24629 1.0\n",
      "24635 1.0\n",
      "24636 1.0\n",
      "24637 1.0\n",
      "24640 1.0\n",
      "24643 1.0\n",
      "24645 1.0\n",
      "24647 1.0\n",
      "24648 0.9559294871794872\n",
      "24649 1.0\n",
      "24655 1.0\n",
      "24656 1.0\n",
      "24659 1.0\n",
      "24663 1.0\n",
      "24665 1.0\n",
      "24670 1.0\n",
      "24675 1.0\n",
      "24686 1.0\n",
      "24692 1.0\n",
      "24693 1.0\n",
      "24694 1.0\n",
      "24696 1.0\n",
      "24698 1.0\n",
      "24701 1.0\n",
      "24705 0.946875\n",
      "24712 1.0\n",
      "24714 0.9427083333333334\n",
      "24719 1.0\n",
      "24730 1.0\n",
      "24731 1.0\n",
      "24735 1.0\n",
      "24746 0.9553571428571429\n",
      "24748 1.0\n",
      "24755 1.0\n",
      "24756 1.0\n",
      "24757 0.9801377118644068\n",
      "24759 1.0\n",
      "24760 0.9791666666666666\n",
      "24761 1.0\n",
      "24763 1.0\n",
      "24768 1.0\n",
      "24770 1.0\n",
      "24774 0.9635416666666666\n",
      "24779 0.90625\n",
      "24780 1.0\n",
      "24781 1.0\n",
      "24783 1.0\n",
      "24785 1.0\n",
      "24794 1.0\n",
      "24801 0.962071718931475\n",
      "24805 1.0\n",
      "24808 1.0\n",
      "24809 0.953125\n",
      "24817 1.0\n",
      "24818 1.0\n",
      "24819 1.0\n",
      "24824 1.0\n",
      "24825 1.0\n",
      "24827 1.0\n",
      "24836 0.9801377118644068\n",
      "24838 1.0\n",
      "24840 1.0\n",
      "24849 1.0\n",
      "24850 1.0\n",
      "24854 0.9625\n",
      "24858 0.984375\n",
      "24859 1.0\n",
      "24861 1.0\n",
      "24863 1.0\n",
      "24866 1.0\n",
      "24867 1.0\n",
      "24872 0.9783653846153846\n",
      "24874 1.0\n",
      "24879 1.0\n",
      "24888 1.0\n",
      "24890 1.0\n",
      "24895 1.0\n",
      "24898 1.0\n",
      "24899 1.0\n",
      "24900 1.0\n",
      "24906 1.0\n",
      "24910 1.0\n",
      "24917 1.0\n",
      "24922 1.0\n",
      "24923 1.0\n",
      "24924 1.0\n",
      "24925 1.0\n",
      "24927 1.0\n",
      "24928 1.0\n",
      "24929 0.9857954545454546\n",
      "24937 1.0\n",
      "24939 1.0\n",
      "24945 1.0\n",
      "24952 1.0\n",
      "24956 1.0\n",
      "24957 1.0\n",
      "24962 1.0\n",
      "24965 1.0\n",
      "24970 1.0\n",
      "24971 0.921875\n",
      "24973 0.98046875\n",
      "24974 1.0\n",
      "24978 1.0\n",
      "24980 1.0\n",
      "24986 0.9553571428571429\n",
      "24993 1.0\n",
      "24997 1.0\n",
      "24998 1.0\n",
      "24999 1.0\n",
      "25002 1.0\n",
      "25004 1.0\n",
      "25012 1.0\n",
      "25015 1.0\n",
      "25016 0.9522569444444444\n",
      "25017 1.0\n",
      "25022 1.0\n",
      "25026 1.0\n",
      "25028 1.0\n",
      "25029 1.0\n",
      "25031 1.0\n",
      "25032 0.9801377118644068\n",
      "25035 1.0\n",
      "25043 0.9388020833333334\n",
      "25046 1.0\n",
      "25047 1.0\n",
      "25049 1.0\n",
      "25054 1.0\n",
      "25063 1.0\n",
      "25065 1.0\n",
      "25067 1.0\n",
      "25070 0.890625\n",
      "25071 1.0\n",
      "25076 1.0\n",
      "25077 1.0\n",
      "25079 1.0\n",
      "25081 1.0\n",
      "25083 1.0\n",
      "25084 1.0\n",
      "25086 1.0\n",
      "25088 1.0\n",
      "25092 0.9765625\n",
      "25098 1.0\n",
      "25104 1.0\n",
      "25111 0.9583333333333334\n",
      "25112 1.0\n",
      "25113 1.0\n",
      "25115 1.0\n",
      "25118 1.0\n",
      "25124 0.9517463235294118\n",
      "25126 1.0\n",
      "25127 1.0\n",
      "25128 1.0\n",
      "25139 1.0\n",
      "25140 1.0\n",
      "25143 0.890625\n",
      "25145 0.921875\n",
      "25152 1.0\n",
      "25158 1.0\n",
      "25160 1.0\n",
      "25167 1.0\n",
      "25171 1.0\n",
      "25172 1.0\n",
      "25179 0.9505494505494505\n",
      "25188 1.0\n",
      "25190 1.0\n",
      "25193 0.8984375\n",
      "25197 1.0\n",
      "25200 1.0\n",
      "25202 1.0\n",
      "25208 1.0\n",
      "25214 1.0\n",
      "25218 0.9140625\n",
      "25219 1.0\n",
      "25224 1.0\n",
      "25237 1.0\n",
      "25251 1.0\n",
      "25252 1.0\n",
      "25258 0.9801377118644068\n",
      "25263 1.0\n",
      "25267 1.0\n",
      "25270 1.0\n",
      "25272 1.0\n",
      "25275 1.0\n",
      "25278 0.9696691176470589\n",
      "25282 1.0\n",
      "25283 1.0\n",
      "25290 1.0\n",
      "25292 1.0\n",
      "25297 1.0\n",
      "25299 1.0\n",
      "25300 0.965625\n",
      "25304 1.0\n",
      "25308 1.0\n",
      "25314 1.0\n",
      "25319 0.9401041666666666\n",
      "25320 1.0\n",
      "25327 1.0\n",
      "25334 1.0\n",
      "25335 1.0\n",
      "25336 1.0\n",
      "25341 0.90625\n",
      "25349 1.0\n",
      "25353 1.0\n",
      "25355 1.0\n",
      "25364 1.0\n",
      "25369 0.9829545454545454\n",
      "25371 0.9739583333333334\n",
      "25372 1.0\n",
      "25377 1.0\n",
      "25380 0.9375\n",
      "25383 1.0\n",
      "25387 0.97265625\n",
      "25389 1.0\n",
      "25390 1.0\n",
      "25396 1.0\n",
      "25399 1.0\n",
      "25404 1.0\n",
      "25407 1.0\n",
      "25416 1.0\n",
      "25417 1.0\n",
      "25422 1.0\n",
      "25425 0.9801377118644068\n",
      "25429 1.0\n",
      "25431 0.9609375\n",
      "25435 1.0\n",
      "25436 1.0\n",
      "25440 1.0\n",
      "25444 0.96875\n",
      "25447 1.0\n",
      "25448 0.962071718931475\n",
      "25450 1.0\n",
      "25451 1.0\n",
      "25452 1.0\n",
      "25453 1.0\n",
      "25456 1.0\n",
      "25459 1.0\n",
      "25461 1.0\n",
      "25462 1.0\n",
      "25463 1.0\n",
      "25466 1.0\n",
      "25468 1.0\n",
      "25469 1.0\n",
      "25471 1.0\n",
      "25477 1.0\n",
      "25480 1.0\n",
      "25484 1.0\n",
      "25497 1.0\n",
      "25500 1.0\n",
      "25507 1.0\n",
      "25512 1.0\n",
      "25516 1.0\n",
      "25517 1.0\n",
      "25519 1.0\n",
      "25525 1.0\n",
      "25527 1.0\n",
      "25528 1.0\n",
      "25530 1.0\n",
      "25531 0.96875\n",
      "25537 0.96875\n",
      "25539 1.0\n",
      "25540 0.9337121212121212\n",
      "25544 0.9427083333333334\n",
      "25548 1.0\n",
      "25555 1.0\n",
      "25559 0.971875\n",
      "25561 1.0\n",
      "25564 1.0\n",
      "25565 1.0\n",
      "25567 1.0\n",
      "25568 1.0\n",
      "25571 1.0\n",
      "25577 1.0\n",
      "25580 0.9609375\n",
      "25586 1.0\n",
      "25588 1.0\n",
      "25590 1.0\n",
      "25594 0.94921875\n",
      "25598 0.9453125\n",
      "25599 1.0\n",
      "25601 1.0\n",
      "25604 1.0\n",
      "25609 1.0\n",
      "25614 1.0\n",
      "25615 1.0\n",
      "25621 1.0\n",
      "25624 1.0\n",
      "25629 1.0\n",
      "25631 1.0\n",
      "25639 1.0\n",
      "25640 0.9609375\n",
      "25641 1.0\n",
      "25645 1.0\n",
      "25646 1.0\n",
      "25653 1.0\n",
      "25654 0.9497767857142857\n",
      "25655 0.9862132352941176\n",
      "25664 1.0\n",
      "25670 1.0\n",
      "25673 1.0\n",
      "25676 0.9621975806451613\n",
      "25678 0.953125\n",
      "25679 1.0\n",
      "25687 1.0\n",
      "25690 1.0\n",
      "25693 1.0\n",
      "25696 1.0\n",
      "25701 1.0\n",
      "25704 1.0\n",
      "25707 1.0\n",
      "25709 0.96875\n",
      "25711 1.0\n",
      "25713 1.0\n",
      "25715 1.0\n",
      "25726 1.0\n",
      "25728 0.9621975806451613\n",
      "25733 1.0\n",
      "25734 1.0\n",
      "25735 1.0\n",
      "25737 0.9489583333333333\n",
      "25740 1.0\n",
      "25747 1.0\n",
      "25752 1.0\n",
      "25755 1.0\n",
      "25763 1.0\n",
      "25768 1.0\n",
      "25770 1.0\n",
      "25779 1.0\n",
      "25788 1.0\n",
      "25792 1.0\n",
      "25795 1.0\n",
      "25798 1.0\n",
      "25799 0.9630208333333333\n",
      "25805 0.9375\n",
      "25806 1.0\n",
      "25812 1.0\n",
      "25814 0.962071718931475\n",
      "25815 1.0\n",
      "25818 1.0\n",
      "25824 1.0\n",
      "25826 1.0\n",
      "25827 1.0\n",
      "25829 1.0\n",
      "25832 1.0\n",
      "25837 1.0\n",
      "25839 1.0\n",
      "25842 1.0\n",
      "25846 1.0\n",
      "25849 1.0\n",
      "25858 0.9651041666666667\n",
      "25862 1.0\n",
      "25864 1.0\n",
      "25866 0.9572458791208791\n",
      "25869 1.0\n",
      "25872 1.0\n",
      "25876 0.9296875\n",
      "25880 1.0\n",
      "25881 1.0\n",
      "25886 1.0\n",
      "25889 0.9558035714285714\n",
      "25895 1.0\n",
      "25898 0.9862132352941176\n",
      "25899 1.0\n",
      "25904 1.0\n",
      "25906 1.0\n",
      "25908 1.0\n",
      "25909 1.0\n",
      "25916 0.9553571428571429\n",
      "25917 1.0\n",
      "25918 1.0\n",
      "25930 1.0\n",
      "25937 1.0\n",
      "25942 1.0\n",
      "25943 1.0\n",
      "25948 1.0\n",
      "25955 1.0\n",
      "25957 0.96875\n",
      "25962 1.0\n",
      "25969 1.0\n",
      "25970 0.9453125\n",
      "25972 1.0\n",
      "25974 0.9296875\n",
      "25976 0.9375\n",
      "25987 1.0\n",
      "25994 1.0\n",
      "25996 1.0\n",
      "25999 1.0\n",
      "26001 1.0\n",
      "26006 0.9829545454545454\n",
      "26007 1.0\n",
      "26008 1.0\n",
      "26014 1.0\n",
      "26015 0.953125\n",
      "26025 1.0\n",
      "26031 1.0\n",
      "26036 1.0\n",
      "26038 0.90625\n",
      "26042 1.0\n",
      "26045 1.0\n",
      "26048 1.0\n",
      "26052 1.0\n",
      "26053 1.0\n",
      "26055 1.0\n",
      "26057 1.0\n",
      "26058 1.0\n",
      "26059 1.0\n",
      "26066 0.9583333333333334\n",
      "26069 1.0\n",
      "26070 0.9765625\n",
      "26076 1.0\n",
      "26080 1.0\n",
      "26083 1.0\n",
      "26087 0.9296875\n",
      "26088 1.0\n",
      "26091 1.0\n",
      "26093 1.0\n",
      "26094 1.0\n",
      "26095 1.0\n",
      "26099 1.0\n",
      "26117 1.0\n",
      "26122 1.0\n",
      "26126 1.0\n",
      "26136 1.0\n",
      "26141 1.0\n",
      "26147 1.0\n",
      "26149 1.0\n",
      "26153 1.0\n",
      "26161 1.0\n",
      "26167 1.0\n",
      "26171 1.0\n",
      "26175 1.0\n",
      "26180 1.0\n",
      "26182 1.0\n",
      "26186 1.0\n",
      "26187 1.0\n",
      "26191 0.9453125\n",
      "26192 1.0\n",
      "26196 1.0\n",
      "26199 1.0\n",
      "26200 0.921875\n",
      "26206 1.0\n",
      "26213 1.0\n",
      "26222 1.0\n",
      "26235 1.0\n",
      "26249 1.0\n",
      "26251 0.9558035714285714\n",
      "26252 1.0\n",
      "26255 1.0\n",
      "26261 1.0\n",
      "26264 1.0\n",
      "26267 1.0\n",
      "26269 1.0\n",
      "26278 1.0\n",
      "26279 1.0\n",
      "26281 1.0\n",
      "26284 1.0\n",
      "26285 1.0\n",
      "26286 1.0\n",
      "26287 1.0\n",
      "26290 0.9453125\n",
      "26294 1.0\n",
      "26300 1.0\n",
      "26303 1.0\n",
      "26304 1.0\n",
      "26307 1.0\n",
      "26308 0.9446022727272727\n",
      "26309 1.0\n",
      "26316 1.0\n",
      "26322 1.0\n",
      "26326 1.0\n",
      "26330 1.0\n",
      "26331 1.0\n",
      "26333 0.9830013736263736\n",
      "26335 1.0\n",
      "26336 1.0\n",
      "26338 1.0\n",
      "26347 1.0\n",
      "26350 1.0\n",
      "26353 1.0\n",
      "26354 1.0\n",
      "26356 1.0\n",
      "26357 1.0\n",
      "26361 1.0\n",
      "26362 1.0\n",
      "26364 1.0\n",
      "26366 1.0\n",
      "26369 1.0\n",
      "26374 1.0\n",
      "26375 1.0\n",
      "26376 1.0\n",
      "26384 1.0\n",
      "26386 1.0\n",
      "26388 1.0\n",
      "26393 1.0\n",
      "26395 1.0\n",
      "26396 0.90625\n",
      "26397 1.0\n",
      "26402 1.0\n",
      "26414 1.0\n",
      "26418 1.0\n",
      "26421 1.0\n",
      "26425 1.0\n",
      "26427 1.0\n",
      "26432 1.0\n",
      "26434 1.0\n",
      "26438 1.0\n",
      "26440 1.0\n",
      "26441 1.0\n",
      "26445 1.0\n",
      "26446 1.0\n",
      "26449 1.0\n",
      "26450 1.0\n",
      "26453 1.0\n",
      "26455 0.9635416666666666\n",
      "26460 1.0\n",
      "26461 0.9739583333333334\n",
      "26464 1.0\n",
      "26466 0.9739583333333334\n",
      "26474 1.0\n",
      "26486 1.0\n",
      "26490 0.9621975806451613\n",
      "26491 1.0\n",
      "26492 1.0\n",
      "26493 1.0\n",
      "26496 1.0\n",
      "26504 1.0\n",
      "26508 1.0\n",
      "26514 1.0\n",
      "26517 1.0\n",
      "26518 1.0\n",
      "26530 1.0\n",
      "26531 1.0\n",
      "26533 1.0\n",
      "26535 1.0\n",
      "26539 1.0\n",
      "26540 1.0\n",
      "26544 0.9675324675324676\n",
      "26545 1.0\n",
      "26546 0.9783653846153846\n",
      "26554 1.0\n",
      "26556 1.0\n",
      "26558 1.0\n",
      "26563 1.0\n",
      "26566 1.0\n",
      "26575 1.0\n",
      "26584 1.0\n",
      "26585 1.0\n",
      "26596 1.0\n",
      "26600 1.0\n",
      "26608 0.9765625\n",
      "26610 1.0\n",
      "26611 1.0\n",
      "26615 1.0\n",
      "26619 1.0\n",
      "26623 1.0\n",
      "26627 1.0\n",
      "26630 1.0\n",
      "26631 1.0\n",
      "26636 0.9495192307692307\n",
      "26637 1.0\n",
      "26644 1.0\n",
      "26647 1.0\n",
      "26652 1.0\n",
      "26653 1.0\n",
      "26654 1.0\n",
      "26657 1.0\n",
      "26659 0.9642857142857143\n",
      "26662 1.0\n",
      "26663 1.0\n",
      "26670 1.0\n",
      "26672 1.0\n",
      "26674 1.0\n",
      "26676 0.971875\n",
      "26679 1.0\n",
      "26684 1.0\n",
      "26686 1.0\n",
      "26691 1.0\n",
      "26693 0.95546875\n",
      "26694 1.0\n",
      "26699 1.0\n",
      "26701 1.0\n",
      "26703 0.962071718931475\n",
      "26707 1.0\n",
      "26708 1.0\n",
      "26711 1.0\n",
      "26722 1.0\n",
      "26723 1.0\n",
      "26725 1.0\n",
      "26728 1.0\n",
      "26730 1.0\n",
      "26732 1.0\n",
      "26733 1.0\n",
      "26736 1.0\n",
      "26744 0.953125\n",
      "26747 0.8671875\n",
      "26750 0.9497767857142857\n",
      "26752 1.0\n",
      "26757 0.9140625\n",
      "26758 1.0\n",
      "26759 1.0\n",
      "26761 1.0\n",
      "26772 0.9765625\n",
      "26773 1.0\n",
      "26782 1.0\n",
      "26786 1.0\n",
      "26795 1.0\n",
      "26800 1.0\n",
      "26806 1.0\n",
      "26809 1.0\n",
      "26816 1.0\n",
      "26817 1.0\n",
      "26818 1.0\n",
      "26828 1.0\n",
      "26834 1.0\n",
      "26840 1.0\n",
      "26845 1.0\n",
      "26847 1.0\n",
      "26850 1.0\n",
      "26856 0.96875\n",
      "26857 1.0\n",
      "26859 1.0\n",
      "26860 1.0\n",
      "26863 1.0\n",
      "26864 1.0\n",
      "26865 1.0\n",
      "26866 1.0\n",
      "26867 1.0\n",
      "26869 1.0\n",
      "26872 1.0\n",
      "26879 1.0\n",
      "26881 0.9643342391304348\n",
      "26887 1.0\n",
      "26890 0.9541666666666667\n",
      "26896 1.0\n",
      "26898 1.0\n",
      "26905 1.0\n",
      "26907 1.0\n",
      "26910 1.0\n",
      "26912 1.0\n",
      "26914 1.0\n",
      "26916 1.0\n",
      "26917 1.0\n",
      "26919 1.0\n",
      "26926 1.0\n",
      "26928 1.0\n",
      "26930 1.0\n",
      "26931 1.0\n",
      "26932 1.0\n",
      "26937 1.0\n",
      "26939 1.0\n",
      "26940 0.9696691176470589\n",
      "26948 1.0\n",
      "26953 1.0\n",
      "26954 1.0\n",
      "26956 1.0\n",
      "26958 1.0\n",
      "26962 0.91015625\n",
      "26964 1.0\n",
      "26966 1.0\n",
      "26968 1.0\n",
      "26973 1.0\n",
      "26974 1.0\n",
      "26977 1.0\n",
      "26979 0.953125\n",
      "26982 1.0\n",
      "26983 1.0\n",
      "26985 1.0\n",
      "26988 1.0\n",
      "26989 1.0\n",
      "26991 1.0\n",
      "26993 1.0\n",
      "26994 1.0\n",
      "26995 0.9526041666666667\n",
      "26996 1.0\n",
      "26997 1.0\n",
      "27005 1.0\n",
      "27006 1.0\n",
      "27008 1.0\n",
      "27009 1.0\n",
      "27012 0.953125\n",
      "27014 1.0\n",
      "27016 1.0\n",
      "27019 0.9675324675324676\n",
      "27020 1.0\n",
      "27030 1.0\n",
      "27037 1.0\n",
      "27041 1.0\n",
      "27042 1.0\n",
      "27050 0.9675324675324676\n",
      "27052 1.0\n",
      "27057 1.0\n",
      "27062 1.0\n",
      "27064 1.0\n",
      "27073 1.0\n",
      "27076 1.0\n",
      "27077 1.0\n",
      "27079 1.0\n",
      "27084 1.0\n",
      "27086 1.0\n",
      "27088 1.0\n",
      "27090 1.0\n",
      "27093 1.0\n",
      "27097 1.0\n",
      "27098 1.0\n",
      "27099 1.0\n",
      "27101 1.0\n",
      "27104 1.0\n",
      "27105 1.0\n",
      "27112 0.9464285714285714\n",
      "27113 1.0\n",
      "27115 1.0\n",
      "27127 1.0\n",
      "27128 1.0\n",
      "27130 1.0\n",
      "27133 1.0\n",
      "27137 1.0\n",
      "27141 1.0\n",
      "27152 1.0\n",
      "27153 1.0\n",
      "27154 1.0\n",
      "27169 1.0\n",
      "27170 0.953125\n",
      "27171 1.0\n",
      "27172 1.0\n",
      "27173 1.0\n",
      "27175 1.0\n",
      "27184 1.0\n",
      "27185 0.96875\n",
      "27192 1.0\n",
      "27193 1.0\n",
      "27198 1.0\n",
      "27199 1.0\n",
      "27201 1.0\n",
      "27203 1.0\n",
      "27205 1.0\n",
      "27207 1.0\n",
      "27215 1.0\n",
      "27221 1.0\n",
      "27224 1.0\n",
      "27232 1.0\n",
      "27236 1.0\n",
      "27242 1.0\n",
      "27243 1.0\n",
      "27259 1.0\n",
      "27260 1.0\n",
      "27270 1.0\n",
      "27273 1.0\n",
      "27280 1.0\n",
      "27284 1.0\n",
      "27288 0.9643342391304348\n",
      "27295 1.0\n",
      "27297 1.0\n",
      "27300 1.0\n",
      "27305 1.0\n",
      "27306 1.0\n",
      "27307 1.0\n",
      "27308 1.0\n",
      "27318 1.0\n",
      "27319 1.0\n",
      "27320 1.0\n",
      "27325 0.9635416666666666\n",
      "27331 1.0\n",
      "27337 1.0\n",
      "27347 1.0\n",
      "27350 1.0\n",
      "27351 0.984375\n",
      "27353 1.0\n",
      "27363 1.0\n",
      "27364 1.0\n",
      "27370 1.0\n",
      "27372 1.0\n",
      "27373 0.9559294871794872\n",
      "27379 1.0\n",
      "27381 1.0\n",
      "27385 1.0\n",
      "27387 1.0\n",
      "27392 1.0\n",
      "27393 1.0\n",
      "27397 0.9765625\n",
      "27398 0.96875\n",
      "27407 1.0\n",
      "27415 1.0\n",
      "27419 0.9479166666666666\n",
      "27420 1.0\n",
      "27421 1.0\n",
      "27422 1.0\n",
      "27441 1.0\n",
      "27443 0.953125\n",
      "27446 1.0\n",
      "27448 1.0\n",
      "27449 1.0\n",
      "27456 1.0\n",
      "27457 1.0\n",
      "27460 1.0\n",
      "27461 1.0\n",
      "27468 0.9801377118644068\n",
      "27472 0.9296875\n",
      "27474 1.0\n",
      "27475 1.0\n",
      "27484 1.0\n",
      "27486 1.0\n",
      "27488 1.0\n",
      "27494 1.0\n",
      "27497 1.0\n",
      "27505 1.0\n",
      "27506 1.0\n",
      "27509 1.0\n",
      "27512 1.0\n",
      "27515 1.0\n",
      "27518 1.0\n",
      "27523 1.0\n",
      "27529 1.0\n",
      "27533 1.0\n",
      "27534 1.0\n",
      "27536 1.0\n",
      "27537 0.9309895833333334\n",
      "27543 1.0\n",
      "27544 1.0\n",
      "27546 1.0\n",
      "27547 1.0\n",
      "27548 1.0\n",
      "27556 1.0\n",
      "27563 0.9375\n",
      "27565 0.9765625\n",
      "27566 1.0\n",
      "27567 1.0\n",
      "27570 0.9375\n",
      "27576 0.9638097426470589\n",
      "27578 1.0\n",
      "27582 0.9270833333333334\n",
      "27584 0.9625\n",
      "27585 1.0\n",
      "27593 1.0\n",
      "27594 1.0\n",
      "27596 1.0\n",
      "27598 1.0\n",
      "27602 1.0\n",
      "27604 1.0\n",
      "27606 1.0\n",
      "27607 1.0\n",
      "27609 1.0\n",
      "27614 0.9505494505494505\n",
      "27618 1.0\n",
      "27622 1.0\n",
      "27625 1.0\n",
      "27627 1.0\n",
      "27628 1.0\n",
      "27629 0.9675324675324676\n",
      "27635 1.0\n",
      "27643 1.0\n",
      "27645 1.0\n",
      "27648 1.0\n",
      "27657 1.0\n",
      "27658 1.0\n",
      "27660 1.0\n",
      "27670 1.0\n",
      "27676 1.0\n",
      "27677 1.0\n",
      "27679 1.0\n",
      "27687 1.0\n",
      "27688 1.0\n",
      "27689 1.0\n",
      "27696 1.0\n",
      "27697 1.0\n",
      "27704 0.9621975806451613\n",
      "27705 1.0\n",
      "27716 0.9421875\n",
      "27718 0.921875\n",
      "27724 1.0\n",
      "27725 1.0\n",
      "27728 1.0\n",
      "27730 1.0\n",
      "27731 1.0\n",
      "27733 1.0\n",
      "27734 1.0\n",
      "27739 1.0\n",
      "27744 1.0\n",
      "27756 1.0\n",
      "27760 1.0\n",
      "27765 1.0\n",
      "27769 1.0\n",
      "27788 0.9588815789473685\n",
      "27789 1.0\n",
      "27791 1.0\n",
      "27792 1.0\n",
      "27801 1.0\n",
      "27803 1.0\n",
      "27806 1.0\n",
      "27815 1.0\n",
      "27820 1.0\n",
      "27824 1.0\n",
      "27827 1.0\n",
      "27830 0.9541666666666667\n",
      "27837 1.0\n",
      "27843 1.0\n",
      "27845 1.0\n",
      "27846 0.75\n",
      "27864 1.0\n",
      "27866 1.0\n",
      "27867 1.0\n",
      "27872 1.0\n",
      "27880 1.0\n",
      "27883 1.0\n",
      "27884 1.0\n",
      "27885 1.0\n",
      "27890 1.0\n",
      "27894 1.0\n",
      "27897 0.96875\n",
      "27898 1.0\n",
      "27900 1.0\n",
      "27907 1.0\n",
      "27915 1.0\n",
      "27919 0.9422679227941176\n",
      "27921 1.0\n",
      "27924 1.0\n",
      "27926 1.0\n",
      "27936 1.0\n",
      "27939 1.0\n",
      "27951 1.0\n",
      "27952 1.0\n",
      "27961 1.0\n",
      "27966 1.0\n",
      "27969 1.0\n",
      "27970 1.0\n",
      "27972 1.0\n",
      "27974 1.0\n",
      "27988 1.0\n",
      "27990 1.0\n",
      "27996 1.0\n",
      "27997 0.9375\n",
      "28001 1.0\n",
      "28008 1.0\n",
      "28011 1.0\n",
      "28012 1.0\n",
      "28013 0.97265625\n",
      "28015 1.0\n",
      "28018 1.0\n",
      "28022 1.0\n",
      "28029 1.0\n",
      "28030 1.0\n",
      "28033 1.0\n",
      "28034 1.0\n",
      "28036 1.0\n",
      "28037 1.0\n",
      "28039 0.96875\n",
      "28041 1.0\n",
      "28043 1.0\n",
      "28044 1.0\n",
      "28045 1.0\n",
      "28051 1.0\n",
      "28056 1.0\n",
      "28059 1.0\n",
      "28063 1.0\n",
      "28066 0.9522569444444444\n",
      "28067 1.0\n",
      "28074 1.0\n",
      "28081 1.0\n",
      "28082 1.0\n",
      "28083 1.0\n",
      "28089 1.0\n",
      "28092 1.0\n",
      "28094 1.0\n",
      "28097 1.0\n",
      "28104 1.0\n",
      "28105 0.9230171783625731\n",
      "28106 1.0\n",
      "28107 0.9517463235294118\n",
      "28111 1.0\n",
      "28114 1.0\n",
      "28115 1.0\n",
      "28120 0.9793198529411765\n",
      "28121 1.0\n",
      "28122 1.0\n",
      "28123 1.0\n",
      "28134 1.0\n",
      "28137 0.96875\n",
      "28141 0.9296875\n",
      "28145 1.0\n",
      "28148 1.0\n",
      "28149 1.0\n",
      "28150 1.0\n",
      "28151 1.0\n",
      "28153 0.9713541666666666\n",
      "28155 1.0\n",
      "28162 0.953125\n",
      "28164 1.0\n",
      "28175 0.9675324675324676\n",
      "28178 1.0\n",
      "28179 1.0\n",
      "28181 0.9453125\n",
      "28182 1.0\n",
      "28184 1.0\n",
      "28187 1.0\n",
      "28188 1.0\n",
      "28192 1.0\n",
      "28197 1.0\n",
      "28199 1.0\n",
      "28200 1.0\n",
      "28201 1.0\n",
      "28203 1.0\n",
      "28207 1.0\n",
      "28208 1.0\n",
      "28209 1.0\n",
      "28211 1.0\n",
      "28215 0.9793198529411765\n",
      "28216 1.0\n",
      "28218 1.0\n",
      "28231 1.0\n",
      "28232 1.0\n",
      "28235 1.0\n",
      "28238 1.0\n",
      "28240 0.9635416666666666\n",
      "28244 1.0\n",
      "28247 1.0\n",
      "28249 1.0\n",
      "28259 1.0\n",
      "28262 1.0\n",
      "28263 1.0\n",
      "28264 1.0\n",
      "28265 1.0\n",
      "28269 1.0\n",
      "28274 1.0\n",
      "28275 1.0\n",
      "28276 1.0\n",
      "28286 1.0\n",
      "28292 1.0\n",
      "28293 1.0\n",
      "28298 0.9166666666666666\n",
      "28300 1.0\n",
      "28303 1.0\n",
      "28305 0.9375\n",
      "28306 1.0\n",
      "28310 1.0\n",
      "28311 1.0\n",
      "28314 1.0\n",
      "28316 1.0\n",
      "28321 1.0\n",
      "28323 1.0\n",
      "28325 1.0\n",
      "28332 1.0\n",
      "28336 0.9729567307692307\n",
      "28337 1.0\n",
      "28339 1.0\n",
      "28342 1.0\n",
      "28349 1.0\n",
      "28360 1.0\n",
      "28362 1.0\n",
      "28365 1.0\n",
      "28368 1.0\n",
      "28369 0.9453125\n",
      "28375 1.0\n",
      "28376 0.9793198529411765\n",
      "28381 1.0\n",
      "28387 1.0\n",
      "28393 0.9296875\n",
      "28399 1.0\n",
      "28401 0.9559294871794872\n",
      "28402 0.96875\n",
      "28404 1.0\n",
      "28406 1.0\n",
      "28417 1.0\n",
      "28422 1.0\n",
      "28427 1.0\n",
      "28429 0.9801377118644068\n",
      "28431 1.0\n",
      "28437 1.0\n",
      "28438 1.0\n",
      "28440 1.0\n",
      "28441 1.0\n",
      "28442 1.0\n",
      "28443 1.0\n",
      "28448 1.0\n",
      "28450 1.0\n",
      "28451 0.9375\n",
      "28455 1.0\n",
      "28456 1.0\n",
      "28458 1.0\n",
      "28460 0.921875\n",
      "28461 1.0\n",
      "28462 1.0\n",
      "28466 1.0\n",
      "28467 1.0\n",
      "28473 1.0\n",
      "28475 1.0\n",
      "28476 1.0\n",
      "28478 1.0\n",
      "28480 1.0\n",
      "28483 1.0\n",
      "28486 1.0\n",
      "28490 1.0\n",
      "28493 1.0\n",
      "28495 1.0\n",
      "28499 1.0\n",
      "28500 1.0\n",
      "28503 1.0\n",
      "28516 1.0\n",
      "28517 1.0\n",
      "28518 0.9453125\n",
      "28519 0.9583333333333334\n",
      "28525 1.0\n",
      "28529 1.0\n",
      "28534 1.0\n",
      "28537 0.96875\n",
      "28549 1.0\n",
      "28552 0.9609375\n",
      "28557 1.0\n",
      "28559 1.0\n",
      "28573 0.8828125\n",
      "28579 0.96875\n",
      "28580 0.9505208333333334\n",
      "28584 1.0\n",
      "28588 1.0\n",
      "28595 1.0\n",
      "28598 1.0\n",
      "28602 1.0\n",
      "28605 1.0\n",
      "28606 0.953125\n",
      "28610 1.0\n",
      "28613 1.0\n",
      "28615 1.0\n",
      "28618 1.0\n",
      "28622 1.0\n",
      "28623 1.0\n",
      "28624 1.0\n",
      "28628 1.0\n",
      "28631 1.0\n",
      "28635 1.0\n",
      "28636 1.0\n",
      "28637 0.96875\n",
      "28638 1.0\n",
      "28640 1.0\n",
      "28642 1.0\n",
      "28643 0.9638097426470589\n",
      "28650 0.9793198529411765\n",
      "28651 0.9201388888888888\n",
      "28653 1.0\n",
      "28654 1.0\n",
      "28658 0.9415922619047619\n",
      "28660 1.0\n",
      "28664 1.0\n",
      "28671 0.97265625\n",
      "28672 1.0\n",
      "28673 0.9505208333333334\n",
      "28680 1.0\n",
      "28682 1.0\n",
      "28684 1.0\n",
      "28685 0.9415922619047619\n",
      "28691 1.0\n",
      "28693 1.0\n",
      "28695 1.0\n",
      "28696 1.0\n",
      "28698 1.0\n",
      "28702 1.0\n",
      "28704 1.0\n",
      "28707 1.0\n",
      "28715 1.0\n",
      "28725 1.0\n",
      "28736 1.0\n",
      "28743 1.0\n",
      "28744 1.0\n",
      "28752 0.9638097426470589\n",
      "28754 1.0\n",
      "28756 1.0\n",
      "28758 1.0\n",
      "28759 1.0\n",
      "28762 1.0\n",
      "28765 1.0\n",
      "28768 1.0\n",
      "28772 0.9453125\n",
      "28775 1.0\n",
      "28776 1.0\n",
      "28780 0.9862132352941176\n",
      "28781 1.0\n",
      "28782 1.0\n",
      "28783 0.9602272727272727\n",
      "28784 1.0\n",
      "28786 1.0\n",
      "28798 1.0\n",
      "28800 1.0\n",
      "28802 1.0\n",
      "28811 1.0\n",
      "28812 0.971875\n",
      "28820 1.0\n",
      "28826 0.9453125\n",
      "28829 1.0\n",
      "28830 1.0\n",
      "28835 1.0\n",
      "28837 0.9713541666666666\n",
      "28839 1.0\n",
      "28840 1.0\n",
      "28843 1.0\n",
      "28844 0.9643342391304348\n",
      "28852 1.0\n",
      "28853 1.0\n",
      "28859 1.0\n",
      "28862 1.0\n",
      "28863 1.0\n",
      "28870 1.0\n",
      "28872 0.9765625\n",
      "28873 0.9791666666666666\n",
      "28877 0.9578125\n",
      "28881 1.0\n",
      "28883 1.0\n",
      "28885 1.0\n",
      "28891 1.0\n",
      "28894 0.9598214285714286\n",
      "28896 0.9375\n",
      "28897 1.0\n",
      "28898 0.9186197916666666\n",
      "28902 1.0\n",
      "28904 1.0\n",
      "28909 1.0\n",
      "28912 1.0\n",
      "28919 0.9765625\n",
      "28920 1.0\n",
      "28925 1.0\n",
      "28928 1.0\n",
      "28932 1.0\n",
      "28935 1.0\n",
      "28938 1.0\n",
      "28942 1.0\n",
      "28943 0.984375\n",
      "28945 1.0\n",
      "28946 1.0\n",
      "28947 0.96875\n",
      "28951 0.9609375\n",
      "28963 1.0\n",
      "28971 1.0\n",
      "28972 1.0\n",
      "28974 1.0\n",
      "28976 0.971875\n",
      "28979 1.0\n",
      "28986 1.0\n",
      "28992 1.0\n",
      "28994 1.0\n",
      "28995 1.0\n",
      "29000 1.0\n",
      "29004 1.0\n",
      "29007 1.0\n",
      "29009 0.9765625\n",
      "29012 1.0\n",
      "29016 0.9375\n",
      "29019 1.0\n",
      "29020 1.0\n",
      "29026 1.0\n",
      "29028 0.9806547619047619\n",
      "29029 1.0\n",
      "29035 1.0\n",
      "29044 1.0\n",
      "29046 1.0\n",
      "29047 1.0\n",
      "29049 0.9609375\n",
      "29050 0.9375\n",
      "29051 0.96875\n",
      "29055 1.0\n",
      "29058 1.0\n",
      "29062 1.0\n",
      "29065 1.0\n",
      "29077 1.0\n",
      "29090 1.0\n",
      "29096 1.0\n",
      "29105 1.0\n",
      "29110 1.0\n",
      "29112 1.0\n",
      "29114 1.0\n",
      "29119 1.0\n",
      "29122 1.0\n",
      "29131 1.0\n",
      "29134 1.0\n",
      "29137 1.0\n",
      "29138 1.0\n",
      "29141 1.0\n",
      "29153 1.0\n",
      "29155 1.0\n",
      "29156 1.0\n",
      "29158 1.0\n",
      "29165 1.0\n",
      "29166 1.0\n",
      "29167 1.0\n",
      "29169 0.9401041666666666\n",
      "29173 1.0\n",
      "29179 1.0\n",
      "29180 0.9830013736263736\n",
      "29192 1.0\n",
      "29202 1.0\n",
      "29204 1.0\n",
      "29205 0.96875\n",
      "29208 1.0\n",
      "29212 1.0\n",
      "29219 1.0\n",
      "29226 1.0\n",
      "29227 1.0\n",
      "29237 0.8671875\n",
      "29244 0.94140625\n",
      "29245 1.0\n",
      "29246 1.0\n",
      "29248 1.0\n",
      "29251 1.0\n",
      "29254 0.9453125\n",
      "29255 1.0\n",
      "29260 1.0\n",
      "29262 1.0\n",
      "29268 1.0\n",
      "29269 1.0\n",
      "29273 1.0\n",
      "29274 1.0\n",
      "29275 0.96875\n",
      "29280 1.0\n",
      "29283 1.0\n",
      "29284 1.0\n",
      "29288 1.0\n",
      "29289 1.0\n",
      "29295 1.0\n",
      "29298 0.9765625\n",
      "29313 1.0\n",
      "29315 1.0\n",
      "29316 1.0\n",
      "29321 0.9643342391304348\n",
      "29325 1.0\n",
      "29326 1.0\n",
      "29329 1.0\n",
      "29335 0.9375\n",
      "29338 1.0\n",
      "29346 1.0\n",
      "29348 1.0\n",
      "29350 1.0\n",
      "29355 0.96484375\n",
      "29357 1.0\n",
      "29366 0.9828869047619048\n",
      "29376 1.0\n",
      "29377 0.9602272727272727\n",
      "29384 1.0\n",
      "29386 1.0\n",
      "29387 0.953125\n",
      "29388 0.9375\n",
      "29392 1.0\n",
      "29395 0.9801377118644068\n",
      "29396 0.828125\n",
      "29405 1.0\n",
      "29408 0.9857954545454546\n",
      "29411 0.9505494505494505\n",
      "29414 1.0\n",
      "29415 1.0\n",
      "29416 1.0\n",
      "29418 0.9450334821428571\n",
      "29421 1.0\n",
      "29427 1.0\n",
      "29428 1.0\n",
      "29442 1.0\n",
      "29443 0.9588815789473685\n",
      "29446 1.0\n",
      "29452 1.0\n",
      "29453 0.9517463235294118\n",
      "29457 1.0\n",
      "29462 0.9541666666666667\n",
      "29474 1.0\n",
      "29476 1.0\n",
      "29477 1.0\n",
      "29480 1.0\n",
      "29481 1.0\n",
      "29486 1.0\n",
      "29494 1.0\n",
      "29500 1.0\n",
      "29510 1.0\n",
      "29511 1.0\n",
      "29514 0.953125\n",
      "29517 1.0\n",
      "29519 1.0\n",
      "29522 1.0\n",
      "29524 1.0\n",
      "29531 1.0\n",
      "29536 1.0\n",
      "29537 1.0\n",
      "29547 1.0\n",
      "29549 1.0\n",
      "29553 1.0\n",
      "29557 1.0\n",
      "29558 1.0\n",
      "29563 1.0\n",
      "29564 1.0\n",
      "29568 1.0\n",
      "29570 1.0\n",
      "29572 1.0\n",
      "29573 1.0\n",
      "29574 1.0\n",
      "29576 0.9652300824175825\n",
      "29586 1.0\n",
      "29587 1.0\n",
      "29597 1.0\n",
      "29598 0.9643342391304348\n",
      "29599 0.9186197916666666\n",
      "29600 0.9375\n",
      "29604 1.0\n",
      "29605 1.0\n",
      "29607 1.0\n",
      "29608 0.9556107954545454\n",
      "29612 1.0\n",
      "29613 1.0\n",
      "29616 1.0\n",
      "29617 1.0\n",
      "29618 0.9375\n",
      "29620 0.9296875\n",
      "29621 1.0\n",
      "29626 1.0\n",
      "29632 1.0\n",
      "29634 1.0\n",
      "29637 1.0\n",
      "29639 1.0\n",
      "29646 1.0\n",
      "29647 0.9609375\n",
      "29648 1.0\n",
      "29650 1.0\n",
      "29651 1.0\n",
      "29658 1.0\n",
      "29659 1.0\n",
      "29663 1.0\n",
      "29665 1.0\n",
      "29671 1.0\n",
      "29673 1.0\n",
      "29675 1.0\n",
      "29676 1.0\n",
      "29683 1.0\n",
      "29690 1.0\n",
      "29691 1.0\n",
      "29692 1.0\n",
      "29694 1.0\n",
      "29696 1.0\n",
      "29699 1.0\n",
      "29701 1.0\n",
      "29705 1.0\n",
      "29709 1.0\n",
      "29715 1.0\n",
      "29718 1.0\n",
      "29720 1.0\n",
      "29725 0.9453125\n",
      "29729 1.0\n",
      "29742 1.0\n",
      "29750 1.0\n",
      "29752 1.0\n",
      "29756 1.0\n",
      "29761 1.0\n",
      "29763 1.0\n",
      "29766 1.0\n",
      "29767 1.0\n",
      "29770 1.0\n",
      "29771 1.0\n",
      "29785 1.0\n",
      "29787 1.0\n",
      "29790 1.0\n",
      "29795 1.0\n",
      "29797 1.0\n",
      "29801 0.953125\n",
      "29802 1.0\n",
      "29803 1.0\n",
      "29811 0.9583333333333334\n",
      "29812 1.0\n",
      "29813 1.0\n",
      "29817 1.0\n",
      "29823 1.0\n",
      "29833 1.0\n",
      "29834 1.0\n",
      "29839 1.0\n",
      "29850 1.0\n",
      "29861 1.0\n",
      "29865 0.9375\n",
      "29866 0.9453125\n",
      "29868 0.9696691176470589\n",
      "29871 0.9140625\n",
      "29873 1.0\n",
      "29874 1.0\n",
      "29880 1.0\n",
      "29884 1.0\n",
      "29885 1.0\n",
      "29891 1.0\n",
      "29896 0.9479166666666666\n",
      "29899 1.0\n",
      "29900 1.0\n",
      "29904 1.0\n",
      "29905 1.0\n",
      "29908 1.0\n",
      "29911 1.0\n",
      "29913 1.0\n",
      "29914 1.0\n",
      "29924 1.0\n",
      "29926 1.0\n",
      "29928 1.0\n",
      "29929 1.0\n",
      "29931 1.0\n",
      "29932 1.0\n",
      "29935 1.0\n",
      "29936 0.9635416666666666\n",
      "29937 0.9609375\n",
      "29939 1.0\n",
      "29945 1.0\n",
      "29946 1.0\n",
      "29952 1.0\n",
      "29960 1.0\n",
      "29961 0.9621975806451613\n",
      "29962 1.0\n",
      "29963 1.0\n",
      "29967 1.0\n",
      "29970 1.0\n",
      "29977 1.0\n",
      "29979 1.0\n",
      "29982 1.0\n",
      "29983 1.0\n",
      "29993 1.0\n",
      "29995 1.0\n",
      "29996 1.0\n",
      "30005 1.0\n",
      "30008 1.0\n",
      "30015 1.0\n",
      "30018 1.0\n",
      "30020 1.0\n",
      "30021 1.0\n",
      "30024 1.0\n",
      "30027 0.9421875\n",
      "30032 1.0\n",
      "30035 1.0\n",
      "30046 1.0\n",
      "30049 1.0\n",
      "30056 1.0\n",
      "30059 1.0\n",
      "30067 1.0\n",
      "30068 1.0\n",
      "30073 1.0\n",
      "30079 1.0\n",
      "30086 1.0\n",
      "30087 0.984375\n",
      "30088 1.0\n",
      "30090 1.0\n",
      "30096 1.0\n",
      "30098 1.0\n",
      "30099 1.0\n",
      "30102 1.0\n",
      "30108 1.0\n",
      "30109 1.0\n",
      "30110 0.921875\n",
      "30113 1.0\n",
      "30119 1.0\n",
      "30120 1.0\n",
      "30121 1.0\n",
      "30127 1.0\n",
      "30128 1.0\n",
      "30129 1.0\n",
      "30130 1.0\n",
      "30140 1.0\n",
      "30141 1.0\n",
      "30143 1.0\n",
      "30147 0.9479166666666666\n",
      "30149 1.0\n",
      "30151 1.0\n",
      "30152 1.0\n",
      "30153 1.0\n",
      "30157 1.0\n",
      "30159 0.9609375\n",
      "30160 1.0\n",
      "30161 1.0\n",
      "30165 1.0\n",
      "30171 1.0\n",
      "30172 1.0\n",
      "30180 0.90625\n",
      "30183 1.0\n",
      "30184 1.0\n",
      "30187 1.0\n",
      "30188 1.0\n",
      "30191 0.971875\n",
      "30196 1.0\n",
      "30199 1.0\n",
      "30201 1.0\n",
      "30202 1.0\n",
      "30206 1.0\n",
      "30211 1.0\n",
      "30216 1.0\n",
      "30217 1.0\n",
      "30219 1.0\n",
      "30225 1.0\n",
      "30227 1.0\n",
      "30233 1.0\n",
      "30241 0.9821428571428571\n",
      "30242 1.0\n",
      "30247 1.0\n",
      "30248 1.0\n",
      "30253 1.0\n",
      "30255 1.0\n",
      "30259 1.0\n",
      "30264 1.0\n",
      "30266 1.0\n",
      "30267 1.0\n",
      "30274 0.9583333333333334\n",
      "30289 1.0\n",
      "30294 1.0\n",
      "30298 1.0\n",
      "30305 1.0\n",
      "30306 1.0\n",
      "30317 0.921875\n",
      "30319 1.0\n",
      "30323 0.9830013736263736\n",
      "30327 1.0\n",
      "30328 1.0\n",
      "30335 1.0\n",
      "30340 1.0\n",
      "30346 1.0\n",
      "30348 1.0\n",
      "30350 1.0\n",
      "30352 0.9449404761904762\n",
      "30357 1.0\n",
      "30361 1.0\n",
      "30367 1.0\n",
      "30377 1.0\n",
      "30380 1.0\n",
      "30385 1.0\n",
      "30388 1.0\n",
      "30391 1.0\n",
      "30394 1.0\n",
      "30396 1.0\n",
      "30397 0.96875\n",
      "30399 1.0\n",
      "30404 1.0\n",
      "30412 1.0\n",
      "30413 1.0\n",
      "30416 1.0\n",
      "30421 1.0\n",
      "30422 1.0\n",
      "30423 1.0\n",
      "30427 1.0\n",
      "30430 1.0\n",
      "30431 1.0\n",
      "30434 1.0\n",
      "30441 1.0\n",
      "30447 0.9613042840375586\n",
      "30457 1.0\n",
      "30461 0.9296875\n",
      "30466 0.9140625\n",
      "30467 1.0\n",
      "30469 1.0\n",
      "30472 1.0\n",
      "30476 1.0\n",
      "30480 1.0\n",
      "30484 1.0\n",
      "30491 1.0\n",
      "30495 1.0\n",
      "30500 1.0\n",
      "30502 1.0\n",
      "30506 1.0\n",
      "30507 0.9453125\n",
      "30511 1.0\n",
      "30518 1.0\n",
      "30521 1.0\n",
      "30527 1.0\n",
      "30533 1.0\n",
      "30537 1.0\n",
      "30540 1.0\n",
      "30542 1.0\n",
      "30550 1.0\n",
      "30553 1.0\n",
      "30556 1.0\n",
      "30557 1.0\n",
      "30559 1.0\n",
      "30561 1.0\n",
      "30567 1.0\n",
      "30580 1.0\n",
      "30583 1.0\n",
      "30587 1.0\n",
      "30590 1.0\n",
      "30591 0.9765625\n",
      "30598 1.0\n",
      "30603 1.0\n",
      "30606 1.0\n",
      "30609 1.0\n",
      "30611 1.0\n",
      "30612 0.9632932692307692\n",
      "30616 1.0\n",
      "30618 1.0\n",
      "30619 0.94921875\n",
      "30620 0.9270833333333334\n",
      "30621 1.0\n",
      "30623 1.0\n",
      "30629 1.0\n",
      "30637 1.0\n",
      "30641 1.0\n",
      "30643 1.0\n",
      "30644 1.0\n",
      "30645 1.0\n",
      "30647 1.0\n",
      "30649 1.0\n",
      "30651 1.0\n",
      "30653 1.0\n",
      "30655 1.0\n",
      "30656 1.0\n",
      "30657 1.0\n",
      "30658 1.0\n",
      "30660 1.0\n",
      "30662 1.0\n",
      "30665 0.9575892857142857\n",
      "30668 1.0\n",
      "30670 0.9375\n",
      "30673 0.9609375\n",
      "30675 1.0\n",
      "30677 1.0\n",
      "30678 1.0\n",
      "30685 1.0\n",
      "30686 1.0\n",
      "30687 1.0\n",
      "30689 1.0\n",
      "30691 1.0\n",
      "30701 1.0\n",
      "30704 0.9635416666666666\n",
      "30708 1.0\n",
      "30711 1.0\n",
      "30716 1.0\n",
      "30722 1.0\n",
      "30725 1.0\n",
      "30727 1.0\n",
      "30731 1.0\n",
      "30732 1.0\n",
      "30734 1.0\n",
      "30735 0.90625\n",
      "30736 1.0\n",
      "30740 1.0\n",
      "30741 1.0\n",
      "30745 1.0\n",
      "30748 0.953125\n",
      "30753 1.0\n",
      "30759 1.0\n",
      "30760 1.0\n",
      "30762 1.0\n",
      "30763 1.0\n",
      "30765 1.0\n",
      "30773 1.0\n",
      "30782 1.0\n",
      "30784 1.0\n",
      "30786 1.0\n",
      "30787 1.0\n",
      "30788 1.0\n",
      "30792 1.0\n",
      "30794 1.0\n",
      "30801 1.0\n",
      "30802 0.93359375\n",
      "30804 1.0\n",
      "30805 1.0\n",
      "30807 1.0\n",
      "30811 1.0\n",
      "30813 1.0\n",
      "30815 1.0\n",
      "30820 1.0\n",
      "30821 1.0\n",
      "30822 1.0\n",
      "30823 1.0\n",
      "30824 0.9453125\n",
      "30833 0.96875\n",
      "30837 1.0\n",
      "30840 0.96875\n",
      "30845 1.0\n",
      "30857 1.0\n",
      "30860 0.9609375\n",
      "30861 1.0\n",
      "30864 1.0\n",
      "30865 0.953125\n",
      "30867 0.9609375\n",
      "30869 1.0\n",
      "30875 0.9495192307692307\n",
      "30877 1.0\n",
      "30879 1.0\n",
      "30880 1.0\n",
      "30887 1.0\n",
      "30888 0.9522569444444444\n",
      "30894 0.9505494505494505\n",
      "30895 1.0\n",
      "30898 1.0\n",
      "30899 1.0\n",
      "30900 1.0\n",
      "30908 1.0\n",
      "30910 1.0\n",
      "30915 1.0\n",
      "30917 1.0\n",
      "30922 1.0\n",
      "30925 1.0\n",
      "30930 1.0\n",
      "30935 1.0\n",
      "30939 1.0\n",
      "30946 1.0\n",
      "30947 1.0\n",
      "30952 1.0\n",
      "30954 1.0\n",
      "30956 1.0\n",
      "30957 1.0\n",
      "30961 1.0\n",
      "30962 1.0\n",
      "30964 1.0\n",
      "30965 1.0\n",
      "30968 1.0\n",
      "30969 0.9609375\n",
      "30979 1.0\n",
      "30986 1.0\n",
      "30988 1.0\n",
      "30991 1.0\n",
      "30993 1.0\n",
      "30994 1.0\n",
      "30995 1.0\n",
      "30998 1.0\n",
      "31000 1.0\n",
      "31001 1.0\n",
      "31002 0.9754901960784313\n",
      "31005 1.0\n",
      "31011 1.0\n",
      "31012 0.984375\n",
      "31013 1.0\n",
      "31023 1.0\n",
      "31025 1.0\n",
      "31026 1.0\n",
      "31034 1.0\n",
      "31043 1.0\n",
      "31045 0.9458333333333333\n",
      "31046 0.921875\n",
      "31051 1.0\n",
      "31055 1.0\n",
      "31057 1.0\n",
      "31067 0.9921875\n",
      "31068 1.0\n",
      "31069 0.9696691176470589\n",
      "31073 1.0\n",
      "31076 1.0\n",
      "31079 1.0\n",
      "31083 0.9783653846153846\n",
      "31084 1.0\n",
      "31086 1.0\n",
      "31091 1.0\n",
      "31098 0.9643342391304348\n",
      "31103 1.0\n",
      "31105 1.0\n",
      "31106 0.9643342391304348\n",
      "31107 1.0\n",
      "31120 1.0\n",
      "31125 1.0\n",
      "31126 1.0\n",
      "31130 1.0\n",
      "31134 0.9578125\n",
      "31139 0.9583333333333334\n",
      "31144 1.0\n",
      "31146 1.0\n",
      "31149 1.0\n",
      "31150 1.0\n",
      "31152 1.0\n",
      "31157 1.0\n",
      "31158 0.9765625\n",
      "31161 1.0\n",
      "31163 0.96875\n",
      "31164 1.0\n",
      "31166 1.0\n",
      "31168 1.0\n",
      "31176 1.0\n",
      "31180 1.0\n",
      "31187 1.0\n",
      "31189 1.0\n",
      "31193 1.0\n",
      "31195 0.96875\n",
      "31197 1.0\n",
      "31198 1.0\n",
      "31199 1.0\n",
      "31200 1.0\n",
      "31204 1.0\n",
      "31206 1.0\n",
      "31209 1.0\n",
      "31216 1.0\n",
      "31218 1.0\n",
      "31219 1.0\n",
      "31222 1.0\n",
      "31229 1.0\n",
      "31236 1.0\n",
      "31239 1.0\n",
      "31241 1.0\n",
      "31243 1.0\n",
      "31244 1.0\n",
      "31250 1.0\n",
      "31252 1.0\n",
      "31256 1.0\n",
      "31257 0.9140625\n",
      "31261 0.9857954545454546\n",
      "31262 1.0\n",
      "31263 1.0\n",
      "31266 1.0\n",
      "31268 1.0\n",
      "31282 1.0\n",
      "31285 0.9140625\n",
      "31288 1.0\n",
      "31290 1.0\n",
      "31292 1.0\n",
      "31293 1.0\n",
      "31295 1.0\n",
      "31299 1.0\n",
      "31302 1.0\n",
      "31305 0.953125\n",
      "31306 1.0\n",
      "31307 1.0\n",
      "31314 1.0\n",
      "31317 0.9801377118644068\n",
      "31319 1.0\n",
      "31321 1.0\n",
      "31324 0.9375\n",
      "31327 1.0\n",
      "31333 1.0\n",
      "31334 1.0\n",
      "31346 0.9613042840375586\n",
      "31347 0.9453125\n",
      "31349 0.9671875\n",
      "31350 1.0\n",
      "31351 1.0\n",
      "31352 0.96875\n",
      "31353 1.0\n",
      "31357 1.0\n",
      "31358 1.0\n",
      "31364 0.9497767857142857\n",
      "31367 1.0\n",
      "31369 1.0\n",
      "31375 1.0\n",
      "31379 1.0\n",
      "31380 1.0\n",
      "31383 1.0\n",
      "31384 1.0\n",
      "31386 1.0\n",
      "31387 0.9696691176470589\n",
      "31392 1.0\n",
      "31393 1.0\n",
      "31394 1.0\n",
      "31396 1.0\n",
      "31398 1.0\n",
      "31403 1.0\n",
      "31406 0.9337121212121212\n",
      "31408 1.0\n",
      "31425 1.0\n",
      "31428 1.0\n",
      "31429 1.0\n",
      "31433 1.0\n",
      "31434 1.0\n",
      "31435 1.0\n",
      "31438 0.9635416666666666\n",
      "31442 1.0\n",
      "31446 1.0\n",
      "31449 1.0\n",
      "31459 1.0\n",
      "31460 1.0\n",
      "31462 0.9186197916666666\n",
      "31467 1.0\n",
      "31469 0.9427083333333334\n",
      "31470 1.0\n",
      "31478 1.0\n",
      "31479 1.0\n",
      "31484 1.0\n",
      "31490 1.0\n",
      "31491 1.0\n",
      "31506 1.0\n",
      "31516 1.0\n",
      "31517 1.0\n",
      "31521 1.0\n",
      "31523 1.0\n",
      "31532 1.0\n",
      "31533 1.0\n",
      "31539 1.0\n",
      "31540 1.0\n",
      "31542 1.0\n",
      "31546 1.0\n",
      "31555 1.0\n",
      "31563 1.0\n",
      "31565 1.0\n",
      "31566 1.0\n",
      "31571 1.0\n",
      "31572 1.0\n",
      "31574 1.0\n",
      "31579 1.0\n",
      "31582 1.0\n",
      "31583 1.0\n",
      "31586 1.0\n",
      "31587 0.984375\n",
      "31589 1.0\n",
      "31591 1.0\n",
      "31594 1.0\n",
      "31601 1.0\n",
      "31602 1.0\n",
      "31605 1.0\n",
      "31607 0.9186197916666666\n",
      "31611 1.0\n",
      "31616 0.9427083333333334\n",
      "31626 1.0\n",
      "31633 1.0\n",
      "31635 1.0\n",
      "31636 0.9427083333333334\n",
      "31637 1.0\n",
      "31642 0.9625\n",
      "31652 1.0\n",
      "31653 1.0\n",
      "31656 1.0\n",
      "31659 1.0\n",
      "31660 1.0\n",
      "31668 1.0\n",
      "31675 1.0\n",
      "31678 1.0\n",
      "31682 1.0\n",
      "31697 1.0\n",
      "31698 1.0\n",
      "31702 1.0\n",
      "31704 1.0\n",
      "31705 1.0\n",
      "31707 0.9806547619047619\n",
      "31708 0.9732142857142857\n",
      "31711 1.0\n",
      "31715 1.0\n",
      "31717 1.0\n",
      "31720 1.0\n",
      "31723 1.0\n",
      "31727 1.0\n",
      "31729 1.0\n",
      "31734 1.0\n",
      "31735 0.9453125\n",
      "31744 1.0\n",
      "31748 1.0\n",
      "31749 1.0\n",
      "31756 1.0\n",
      "31761 0.9427083333333334\n",
      "31763 1.0\n",
      "31767 1.0\n",
      "31771 1.0\n",
      "31774 1.0\n",
      "31776 1.0\n",
      "31784 0.96875\n",
      "31787 1.0\n",
      "31790 1.0\n",
      "31791 1.0\n",
      "31792 1.0\n",
      "31803 1.0\n",
      "31806 1.0\n",
      "31808 1.0\n",
      "31810 0.9578125\n",
      "31814 1.0\n",
      "31815 1.0\n",
      "31818 1.0\n",
      "31819 1.0\n",
      "31820 1.0\n",
      "31829 1.0\n",
      "31838 0.9375\n",
      "31844 1.0\n",
      "31851 1.0\n",
      "31858 0.9559294871794872\n",
      "31863 0.9696691176470589\n",
      "31865 1.0\n",
      "31869 1.0\n",
      "31875 0.9296875\n",
      "31877 1.0\n",
      "31881 1.0\n",
      "31887 1.0\n",
      "31891 1.0\n",
      "31895 1.0\n",
      "31902 1.0\n",
      "31903 1.0\n",
      "31911 0.9829545454545454\n",
      "31916 1.0\n",
      "31917 1.0\n",
      "31921 1.0\n",
      "31922 1.0\n",
      "31925 1.0\n",
      "31926 1.0\n",
      "31928 1.0\n",
      "31929 1.0\n",
      "31933 1.0\n",
      "31937 1.0\n",
      "31951 0.91015625\n",
      "31955 1.0\n",
      "31957 1.0\n",
      "31959 1.0\n",
      "31960 1.0\n",
      "31961 0.9244791666666666\n",
      "31968 1.0\n",
      "31970 1.0\n",
      "31972 0.96875\n",
      "31976 1.0\n",
      "31977 0.9609375\n",
      "31983 1.0\n",
      "31986 0.971875\n",
      "31987 1.0\n",
      "31992 1.0\n",
      "31996 1.0\n",
      "32004 0.9375\n",
      "32006 1.0\n",
      "32008 1.0\n",
      "32012 1.0\n",
      "32014 1.0\n",
      "32015 1.0\n",
      "32018 1.0\n",
      "32027 1.0\n",
      "32029 0.9625\n",
      "32032 1.0\n",
      "32039 1.0\n",
      "32041 1.0\n",
      "32054 1.0\n",
      "32057 0.90625\n",
      "32058 1.0\n",
      "32061 1.0\n",
      "32066 1.0\n",
      "32068 1.0\n",
      "32069 1.0\n",
      "32073 1.0\n",
      "32074 1.0\n",
      "32075 1.0\n",
      "32092 1.0\n",
      "32097 1.0\n",
      "32099 1.0\n",
      "32105 1.0\n",
      "32108 1.0\n",
      "32110 1.0\n",
      "32120 0.9609375\n",
      "32121 1.0\n",
      "32125 1.0\n",
      "32127 1.0\n",
      "32128 1.0\n",
      "32134 1.0\n",
      "32135 1.0\n",
      "32142 1.0\n",
      "32144 1.0\n",
      "32148 1.0\n",
      "32150 1.0\n",
      "32152 1.0\n",
      "32155 1.0\n",
      "32159 1.0\n",
      "32161 1.0\n",
      "32165 1.0\n",
      "32172 1.0\n",
      "32174 0.9791666666666666\n",
      "32178 0.9613042840375586\n",
      "32185 1.0\n",
      "32190 1.0\n",
      "32191 1.0\n",
      "32198 0.9453125\n",
      "32201 1.0\n",
      "32202 1.0\n",
      "32203 1.0\n",
      "32204 1.0\n",
      "32205 1.0\n",
      "32207 1.0\n",
      "32209 1.0\n",
      "32217 1.0\n",
      "32218 1.0\n",
      "32222 1.0\n",
      "32226 1.0\n",
      "32228 0.91015625\n",
      "32230 1.0\n",
      "32232 1.0\n",
      "32238 1.0\n",
      "32240 1.0\n",
      "32243 1.0\n",
      "32244 1.0\n",
      "32251 1.0\n",
      "32252 1.0\n",
      "32253 1.0\n",
      "32257 0.9375\n",
      "32259 0.921875\n",
      "32264 1.0\n",
      "32281 1.0\n",
      "32285 1.0\n",
      "32291 1.0\n",
      "32294 1.0\n",
      "32295 1.0\n",
      "32300 0.9553571428571429\n",
      "32302 0.984375\n",
      "32303 1.0\n",
      "32304 0.94921875\n",
      "32308 0.9453125\n",
      "32310 1.0\n",
      "32314 0.9375\n",
      "32315 1.0\n",
      "32316 0.9652300824175825\n",
      "32318 1.0\n",
      "32320 1.0\n",
      "32323 1.0\n",
      "32325 1.0\n",
      "32330 0.9609375\n",
      "32331 0.9609375\n",
      "32336 1.0\n",
      "32338 1.0\n",
      "32339 0.96875\n",
      "32342 1.0\n",
      "32352 1.0\n",
      "32358 0.9729567307692307\n",
      "32362 1.0\n",
      "32363 0.9230171783625731\n",
      "32367 1.0\n",
      "32372 0.9583333333333334\n",
      "32374 1.0\n",
      "32376 1.0\n",
      "32378 0.9829545454545454\n",
      "32381 1.0\n",
      "32383 1.0\n",
      "32388 1.0\n",
      "32391 0.9609375\n",
      "32396 1.0\n",
      "32401 1.0\n",
      "32402 0.9453125\n",
      "32405 1.0\n",
      "32406 1.0\n",
      "32410 1.0\n",
      "32413 1.0\n",
      "32414 1.0\n",
      "32420 1.0\n",
      "32424 1.0\n",
      "32435 1.0\n",
      "32440 1.0\n",
      "32444 1.0\n",
      "32446 1.0\n",
      "32447 0.9783653846153846\n",
      "32449 1.0\n",
      "32452 0.98046875\n",
      "32456 1.0\n",
      "32460 1.0\n",
      "32463 0.9322916666666666\n",
      "32466 1.0\n",
      "32469 0.9609375\n",
      "32471 1.0\n",
      "32473 1.0\n",
      "32480 1.0\n",
      "32483 1.0\n",
      "32486 1.0\n",
      "32489 0.965625\n",
      "32495 1.0\n",
      "32496 0.9453125\n",
      "32500 0.9337121212121212\n",
      "32506 1.0\n",
      "32507 1.0\n",
      "32513 1.0\n",
      "32515 1.0\n",
      "32516 1.0\n",
      "32522 1.0\n",
      "32523 1.0\n",
      "32524 1.0\n",
      "32529 1.0\n",
      "32530 1.0\n",
      "32534 1.0\n",
      "32540 1.0\n",
      "32541 1.0\n",
      "32544 0.95\n",
      "32549 1.0\n",
      "32550 1.0\n",
      "32552 1.0\n",
      "32555 1.0\n",
      "32557 1.0\n",
      "32573 0.971875\n",
      "32576 1.0\n",
      "32578 1.0\n",
      "32580 1.0\n",
      "32590 1.0\n",
      "32592 0.9635416666666666\n",
      "32594 1.0\n",
      "32596 1.0\n",
      "32600 1.0\n",
      "32606 1.0\n",
      "32610 0.953125\n",
      "32611 1.0\n",
      "32615 1.0\n",
      "32618 1.0\n",
      "32620 1.0\n",
      "32627 1.0\n",
      "32628 1.0\n",
      "32629 1.0\n",
      "32632 1.0\n",
      "32637 1.0\n",
      "32640 1.0\n",
      "32641 1.0\n",
      "32644 0.9296875\n",
      "32651 1.0\n",
      "32655 1.0\n",
      "32656 1.0\n",
      "32660 1.0\n",
      "32664 0.9625\n",
      "32665 1.0\n",
      "32666 0.94921875\n",
      "32672 1.0\n",
      "32674 1.0\n",
      "32675 1.0\n",
      "32677 1.0\n",
      "32685 1.0\n",
      "32692 1.0\n",
      "32694 1.0\n",
      "32696 1.0\n",
      "32698 1.0\n",
      "32700 0.953125\n",
      "32705 1.0\n",
      "32709 1.0\n",
      "32718 1.0\n",
      "32721 0.9572458791208791\n",
      "32722 1.0\n",
      "32723 1.0\n",
      "32725 1.0\n",
      "32732 1.0\n",
      "32736 1.0\n",
      "32739 1.0\n",
      "32740 1.0\n",
      "32743 0.9559294871794872\n",
      "32746 1.0\n",
      "32747 0.9630208333333333\n",
      "32750 1.0\n",
      "32752 1.0\n",
      "32756 1.0\n",
      "32757 1.0\n",
      "32760 1.0\n",
      "32764 1.0\n",
      "32767 1.0\n",
      "32769 1.0\n",
      "32772 1.0\n",
      "32773 1.0\n",
      "32774 1.0\n",
      "32775 1.0\n",
      "32777 1.0\n",
      "32778 1.0\n",
      "32779 1.0\n",
      "32782 1.0\n",
      "32792 1.0\n",
      "32800 1.0\n",
      "32804 1.0\n",
      "32810 1.0\n",
      "32813 0.9453125\n",
      "32819 1.0\n",
      "32820 1.0\n",
      "32826 1.0\n",
      "32831 1.0\n",
      "32832 1.0\n",
      "32837 1.0\n",
      "32841 1.0\n",
      "32848 0.9541666666666667\n",
      "32849 1.0\n",
      "32851 1.0\n",
      "32852 0.9375\n",
      "32854 1.0\n",
      "32855 1.0\n",
      "32856 1.0\n",
      "32866 1.0\n",
      "32876 1.0\n",
      "32877 1.0\n",
      "32887 1.0\n",
      "32888 1.0\n",
      "32889 1.0\n",
      "32890 0.962071718931475\n",
      "32893 1.0\n",
      "32895 0.9375\n",
      "32898 0.953125\n",
      "32900 1.0\n",
      "32901 1.0\n",
      "32911 1.0\n",
      "32916 1.0\n",
      "32927 1.0\n",
      "32928 1.0\n",
      "32934 1.0\n",
      "32935 1.0\n",
      "32936 0.984375\n",
      "32937 1.0\n",
      "32938 1.0\n",
      "32941 1.0\n",
      "32943 1.0\n",
      "32951 1.0\n",
      "32953 0.9464285714285714\n",
      "32954 1.0\n",
      "32956 1.0\n",
      "32958 1.0\n",
      "32960 1.0\n",
      "32962 0.9375\n",
      "32964 1.0\n",
      "32965 1.0\n",
      "32966 1.0\n",
      "32967 0.9739583333333334\n",
      "32969 1.0\n",
      "32970 1.0\n",
      "32972 1.0\n",
      "32980 1.0\n",
      "32981 1.0\n",
      "32983 1.0\n",
      "32985 1.0\n",
      "32988 1.0\n",
      "32989 0.97265625\n",
      "32992 1.0\n",
      "32993 0.9625\n",
      "32994 1.0\n",
      "32996 1.0\n",
      "32997 1.0\n",
      "32998 1.0\n",
      "33001 1.0\n",
      "33002 1.0\n",
      "33010 0.9495192307692307\n",
      "33011 1.0\n",
      "33016 1.0\n",
      "33019 1.0\n",
      "33021 0.96875\n",
      "33024 1.0\n",
      "33027 1.0\n",
      "33033 0.9140625\n",
      "33034 1.0\n",
      "33035 1.0\n",
      "33038 1.0\n",
      "33039 1.0\n",
      "33043 1.0\n",
      "33050 1.0\n",
      "33051 1.0\n",
      "33052 0.953125\n",
      "33057 0.9862132352941176\n",
      "33058 0.9643342391304348\n",
      "33060 1.0\n",
      "33061 1.0\n",
      "33063 0.9754901960784313\n",
      "33064 1.0\n",
      "33068 1.0\n",
      "33069 1.0\n",
      "33071 1.0\n",
      "33072 1.0\n",
      "33073 1.0\n",
      "33078 1.0\n",
      "33080 1.0\n",
      "33085 0.9739583333333334\n",
      "33089 1.0\n",
      "33090 1.0\n",
      "33093 1.0\n",
      "33109 1.0\n",
      "33112 1.0\n",
      "33113 1.0\n",
      "33118 1.0\n",
      "33120 1.0\n",
      "33123 1.0\n",
      "33129 1.0\n",
      "33130 0.9479166666666666\n",
      "33132 1.0\n",
      "33134 0.984375\n",
      "33137 0.875\n",
      "33145 1.0\n",
      "33159 1.0\n",
      "33160 0.9765625\n",
      "33163 1.0\n",
      "33165 1.0\n",
      "33167 0.9583333333333334\n",
      "33174 1.0\n",
      "33177 1.0\n",
      "33178 0.953125\n",
      "33179 1.0\n",
      "33180 1.0\n",
      "33181 1.0\n",
      "33187 0.9583333333333334\n",
      "33189 1.0\n",
      "33193 1.0\n",
      "33195 1.0\n",
      "33196 1.0\n",
      "33199 1.0\n",
      "33209 1.0\n",
      "33211 1.0\n",
      "33215 1.0\n",
      "33217 1.0\n",
      "33218 1.0\n",
      "33219 1.0\n",
      "33221 1.0\n",
      "33226 1.0\n",
      "33243 1.0\n",
      "33245 1.0\n",
      "33247 0.921875\n",
      "33250 1.0\n",
      "33252 0.9829545454545454\n",
      "33256 1.0\n",
      "33258 1.0\n",
      "33262 1.0\n",
      "33263 0.96484375\n",
      "33264 0.962071718931475\n",
      "33265 1.0\n",
      "33270 0.9609375\n",
      "33274 1.0\n",
      "33278 1.0\n",
      "33280 1.0\n",
      "33289 1.0\n",
      "33292 1.0\n",
      "33293 1.0\n",
      "33294 1.0\n",
      "33296 1.0\n",
      "33298 1.0\n",
      "33299 1.0\n",
      "33309 1.0\n",
      "33311 1.0\n",
      "33321 1.0\n",
      "33325 1.0\n",
      "33327 1.0\n",
      "33328 1.0\n",
      "33332 1.0\n",
      "33335 1.0\n",
      "33342 1.0\n",
      "33344 1.0\n",
      "33346 1.0\n",
      "33354 1.0\n",
      "33357 1.0\n",
      "33363 1.0\n",
      "33369 1.0\n",
      "33370 0.9458333333333333\n",
      "33371 1.0\n",
      "33377 0.9505208333333334\n",
      "33382 1.0\n",
      "33386 1.0\n",
      "33387 1.0\n",
      "33389 1.0\n",
      "33390 0.962071718931475\n",
      "33411 1.0\n",
      "33412 1.0\n",
      "33415 1.0\n",
      "33418 1.0\n",
      "33427 1.0\n",
      "33428 1.0\n",
      "33429 0.9140625\n",
      "33430 1.0\n",
      "33431 1.0\n",
      "33432 0.953125\n",
      "33434 1.0\n",
      "33436 0.9666666666666667\n",
      "33437 1.0\n",
      "33439 0.9602272727272727\n",
      "33443 1.0\n",
      "33445 1.0\n",
      "33447 1.0\n",
      "33457 1.0\n",
      "33458 1.0\n",
      "33460 1.0\n",
      "33464 1.0\n",
      "33468 0.9583333333333334\n",
      "33469 0.962071718931475\n",
      "33473 0.9609375\n",
      "33478 1.0\n",
      "33493 1.0\n",
      "33494 1.0\n",
      "33504 1.0\n",
      "33509 1.0\n",
      "33514 1.0\n",
      "33517 0.9541666666666667\n",
      "33523 0.9559294871794872\n",
      "33524 1.0\n",
      "33525 0.958984375\n",
      "33526 0.9708333333333333\n",
      "33530 1.0\n",
      "33531 1.0\n",
      "33536 0.958984375\n",
      "33540 1.0\n",
      "33542 1.0\n",
      "33543 1.0\n",
      "33544 1.0\n",
      "33545 1.0\n",
      "33546 1.0\n",
      "33548 0.9449404761904762\n",
      "33555 1.0\n",
      "33556 1.0\n",
      "33560 0.8984375\n",
      "33561 1.0\n",
      "33562 1.0\n",
      "33572 1.0\n",
      "33576 1.0\n",
      "33577 1.0\n",
      "33581 1.0\n",
      "33585 1.0\n",
      "33588 1.0\n",
      "33589 1.0\n",
      "33593 1.0\n",
      "33594 0.921875\n",
      "33595 1.0\n",
      "33603 1.0\n",
      "33615 0.9140625\n",
      "33616 1.0\n",
      "33621 1.0\n",
      "33623 1.0\n",
      "33627 1.0\n",
      "33629 1.0\n",
      "33636 1.0\n",
      "33638 0.9526041666666667\n",
      "33646 1.0\n",
      "33651 1.0\n",
      "33653 1.0\n",
      "33661 0.96875\n",
      "33677 1.0\n",
      "33679 1.0\n",
      "33690 1.0\n",
      "33692 1.0\n",
      "33696 0.9361979166666666\n",
      "33698 1.0\n",
      "33700 0.9862132352941176\n",
      "33703 0.9791666666666666\n",
      "33705 1.0\n",
      "33706 1.0\n",
      "33708 1.0\n",
      "33715 1.0\n",
      "33720 1.0\n",
      "33727 1.0\n",
      "33728 1.0\n",
      "33730 1.0\n",
      "33732 0.9505208333333334\n",
      "33734 1.0\n",
      "33736 1.0\n",
      "33739 1.0\n",
      "33745 1.0\n",
      "33754 1.0\n",
      "33759 1.0\n",
      "33760 0.9642857142857143\n",
      "33768 1.0\n",
      "33778 1.0\n",
      "33785 0.9830013736263736\n",
      "33790 1.0\n",
      "33791 1.0\n",
      "33793 0.984375\n",
      "33794 1.0\n",
      "33798 0.9609375\n",
      "33803 0.9732142857142857\n",
      "33806 0.9813988095238095\n",
      "33808 0.9696691176470589\n",
      "33810 1.0\n",
      "33811 1.0\n",
      "33813 0.971875\n",
      "33817 1.0\n",
      "33824 1.0\n",
      "33825 1.0\n",
      "33831 1.0\n",
      "33840 1.0\n",
      "33841 1.0\n",
      "33843 1.0\n",
      "33844 1.0\n",
      "33852 1.0\n",
      "33853 1.0\n",
      "33854 1.0\n",
      "33856 1.0\n",
      "33859 1.0\n",
      "33860 1.0\n",
      "33862 1.0\n",
      "33866 0.9609375\n",
      "33869 1.0\n",
      "33880 0.971875\n",
      "33883 0.9635416666666666\n",
      "33884 1.0\n",
      "33906 1.0\n",
      "33929 1.0\n",
      "33930 0.9739583333333334\n",
      "33933 1.0\n",
      "33934 1.0\n",
      "33936 1.0\n",
      "33937 1.0\n",
      "33940 1.0\n",
      "33943 1.0\n",
      "33944 0.96875\n",
      "33945 1.0\n",
      "33950 1.0\n",
      "33951 1.0\n",
      "33952 1.0\n",
      "33955 1.0\n",
      "33958 0.9296875\n",
      "33961 1.0\n",
      "33964 1.0\n",
      "33968 1.0\n",
      "33970 1.0\n",
      "33974 0.96875\n",
      "33981 1.0\n",
      "33993 1.0\n",
      "33995 1.0\n",
      "33998 1.0\n",
      "33999 1.0\n",
      "34000 1.0\n",
      "34003 1.0\n",
      "34005 1.0\n",
      "34006 1.0\n",
      "34009 1.0\n",
      "34012 1.0\n",
      "34021 1.0\n",
      "34024 1.0\n",
      "34026 1.0\n",
      "34033 1.0\n",
      "34038 1.0\n",
      "34039 0.9375\n",
      "34040 1.0\n",
      "34041 1.0\n",
      "34044 1.0\n",
      "34046 1.0\n",
      "34050 0.96875\n",
      "34051 1.0\n",
      "34057 1.0\n",
      "34058 0.953125\n",
      "34066 1.0\n",
      "34068 1.0\n",
      "34069 1.0\n",
      "34070 1.0\n",
      "34071 0.953125\n",
      "34073 1.0\n",
      "34077 1.0\n",
      "34080 1.0\n",
      "34086 0.96875\n",
      "34087 1.0\n",
      "34090 1.0\n",
      "34093 1.0\n",
      "34094 1.0\n",
      "34097 1.0\n",
      "34107 1.0\n",
      "34108 1.0\n",
      "34109 0.953125\n",
      "34114 1.0\n",
      "34115 1.0\n",
      "34118 1.0\n",
      "34124 1.0\n",
      "34126 1.0\n",
      "34130 1.0\n",
      "34131 1.0\n",
      "34132 1.0\n",
      "34136 0.9801377118644068\n",
      "34139 1.0\n",
      "34141 1.0\n",
      "34146 1.0\n",
      "34148 1.0\n",
      "34153 1.0\n",
      "34155 1.0\n",
      "34157 1.0\n",
      "34159 1.0\n",
      "34168 1.0\n",
      "34169 0.9857954545454546\n",
      "34174 1.0\n",
      "34179 0.962071718931475\n",
      "34180 0.8984375\n",
      "34182 1.0\n",
      "34183 1.0\n",
      "34185 1.0\n",
      "34193 1.0\n",
      "34197 1.0\n",
      "34200 1.0\n",
      "34202 1.0\n",
      "34205 1.0\n",
      "34212 1.0\n",
      "34213 1.0\n",
      "34216 1.0\n",
      "34219 1.0\n",
      "34223 0.9821428571428571\n",
      "34225 0.9337121212121212\n",
      "34227 1.0\n",
      "34229 0.9479166666666666\n",
      "34232 1.0\n",
      "34234 1.0\n",
      "34235 1.0\n",
      "34238 1.0\n",
      "34240 1.0\n",
      "34247 0.9813988095238095\n",
      "34254 1.0\n",
      "34257 1.0\n",
      "34259 1.0\n",
      "34265 1.0\n",
      "34266 1.0\n",
      "34270 1.0\n",
      "34274 1.0\n",
      "34276 0.9621975806451613\n",
      "34277 1.0\n",
      "34278 1.0\n",
      "34280 1.0\n",
      "34284 1.0\n",
      "34285 1.0\n",
      "34287 0.953125\n",
      "34291 1.0\n",
      "34292 1.0\n",
      "34293 1.0\n",
      "34296 1.0\n",
      "34299 0.9572458791208791\n",
      "34302 1.0\n",
      "34304 0.9375\n",
      "34305 0.9613042840375586\n",
      "34306 1.0\n",
      "34308 1.0\n",
      "34309 1.0\n",
      "34318 1.0\n",
      "34320 0.9671875\n",
      "34324 1.0\n",
      "34327 1.0\n",
      "34328 1.0\n",
      "34330 1.0\n",
      "34333 1.0\n",
      "34335 1.0\n",
      "34337 0.9497767857142857\n",
      "34343 1.0\n",
      "34345 0.953125\n",
      "34350 0.953125\n",
      "34353 1.0\n",
      "34354 1.0\n",
      "34359 1.0\n",
      "34364 1.0\n",
      "34366 1.0\n",
      "34370 1.0\n",
      "34373 0.96875\n",
      "34374 1.0\n",
      "34375 1.0\n",
      "34378 1.0\n",
      "34379 1.0\n",
      "34380 1.0\n",
      "34388 1.0\n",
      "34389 1.0\n",
      "34393 1.0\n",
      "34399 1.0\n",
      "34400 1.0\n",
      "34407 1.0\n",
      "34411 1.0\n",
      "34414 1.0\n",
      "34418 1.0\n",
      "34422 1.0\n",
      "34425 1.0\n",
      "34430 1.0\n",
      "34434 1.0\n",
      "34439 1.0\n",
      "34442 0.971875\n",
      "34444 1.0\n",
      "34445 1.0\n",
      "34448 1.0\n",
      "34451 1.0\n",
      "34452 1.0\n",
      "34458 1.0\n",
      "34464 1.0\n",
      "34470 1.0\n",
      "34473 1.0\n",
      "34474 1.0\n",
      "34476 1.0\n",
      "34479 1.0\n",
      "34481 1.0\n",
      "34486 1.0\n",
      "34487 0.9671875\n",
      "34488 1.0\n",
      "34495 1.0\n",
      "34500 1.0\n",
      "34502 1.0\n",
      "34504 1.0\n",
      "34507 1.0\n",
      "34509 1.0\n",
      "34517 1.0\n",
      "34519 0.9621975806451613\n",
      "34520 1.0\n",
      "34522 1.0\n",
      "34528 1.0\n",
      "34538 1.0\n",
      "34540 1.0\n",
      "34543 0.9541666666666667\n",
      "34546 1.0\n",
      "34548 1.0\n",
      "34552 1.0\n",
      "34554 1.0\n",
      "34556 1.0\n",
      "34557 0.9541666666666667\n",
      "34558 1.0\n",
      "34559 1.0\n",
      "34560 1.0\n",
      "34568 1.0\n",
      "34569 1.0\n",
      "34571 1.0\n",
      "34575 1.0\n",
      "34576 1.0\n",
      "34577 1.0\n",
      "34583 1.0\n",
      "34589 1.0\n",
      "34590 0.9621975806451613\n",
      "34593 1.0\n",
      "34594 1.0\n",
      "34595 1.0\n",
      "34597 1.0\n",
      "34603 1.0\n",
      "34604 1.0\n",
      "34607 1.0\n",
      "34608 0.9337121212121212\n",
      "34610 0.90625\n",
      "34614 1.0\n",
      "34617 0.9857954545454546\n",
      "34618 1.0\n",
      "34619 1.0\n",
      "34620 1.0\n",
      "34625 1.0\n",
      "34627 1.0\n",
      "34629 1.0\n",
      "34631 1.0\n",
      "34636 1.0\n",
      "34647 1.0\n",
      "34648 1.0\n",
      "34650 1.0\n",
      "34653 0.9578125\n",
      "34659 1.0\n",
      "34660 1.0\n",
      "34663 1.0\n",
      "34664 1.0\n",
      "34666 1.0\n",
      "34669 0.9783653846153846\n",
      "34671 0.9598214285714286\n",
      "34679 0.9526041666666667\n",
      "34683 1.0\n",
      "34692 1.0\n",
      "34699 1.0\n",
      "34701 1.0\n",
      "34702 1.0\n",
      "34704 1.0\n",
      "34705 0.890625\n",
      "34710 0.9625\n",
      "34711 1.0\n",
      "34712 1.0\n",
      "34719 1.0\n",
      "34720 1.0\n",
      "34722 1.0\n",
      "34726 0.953125\n",
      "34727 0.953125\n",
      "34732 0.9857954545454546\n",
      "34734 1.0\n",
      "34741 1.0\n",
      "34744 1.0\n",
      "34749 1.0\n",
      "34753 1.0\n",
      "34757 1.0\n",
      "34758 0.9541666666666667\n",
      "34760 1.0\n",
      "34765 1.0\n",
      "34766 1.0\n",
      "34768 1.0\n",
      "34772 0.9140625\n",
      "34773 1.0\n",
      "34776 1.0\n",
      "34783 1.0\n",
      "34788 1.0\n",
      "34796 1.0\n",
      "34800 1.0\n",
      "34806 1.0\n",
      "34807 1.0\n",
      "34809 1.0\n",
      "34811 0.9375\n",
      "34813 1.0\n",
      "34816 1.0\n",
      "34817 1.0\n",
      "34820 1.0\n",
      "34822 1.0\n",
      "34823 1.0\n",
      "34830 1.0\n",
      "34834 0.90625\n",
      "34837 1.0\n",
      "34838 0.9793198529411765\n",
      "34839 1.0\n",
      "34840 1.0\n",
      "34841 1.0\n",
      "34844 1.0\n",
      "34845 1.0\n",
      "34846 1.0\n",
      "34847 1.0\n",
      "34848 1.0\n",
      "34853 1.0\n",
      "34855 0.9453125\n",
      "34858 1.0\n",
      "34859 1.0\n",
      "34869 1.0\n",
      "34871 1.0\n",
      "34873 1.0\n",
      "34875 1.0\n",
      "34878 1.0\n",
      "34881 0.921875\n",
      "34882 1.0\n",
      "34884 1.0\n",
      "34885 1.0\n",
      "34887 1.0\n",
      "34892 1.0\n",
      "34899 0.971875\n",
      "34900 1.0\n",
      "34901 1.0\n",
      "34902 1.0\n",
      "34904 0.9432291666666667\n",
      "34906 1.0\n",
      "34912 1.0\n",
      "34913 0.984375\n",
      "34918 1.0\n",
      "34925 1.0\n",
      "34926 0.9635416666666666\n",
      "34932 1.0\n",
      "34933 1.0\n",
      "34940 1.0\n",
      "34941 1.0\n",
      "34942 1.0\n",
      "34956 1.0\n",
      "34957 1.0\n",
      "34958 1.0\n",
      "34961 1.0\n",
      "34965 0.95703125\n",
      "34966 1.0\n",
      "34970 1.0\n",
      "34981 1.0\n",
      "34983 1.0\n",
      "34996 1.0\n",
      "34997 1.0\n",
      "34998 1.0\n",
      "35000 1.0\n",
      "35003 1.0\n",
      "35005 1.0\n",
      "35007 1.0\n",
      "35008 1.0\n",
      "35010 1.0\n",
      "35013 1.0\n",
      "35014 0.9517463235294118\n",
      "35022 1.0\n",
      "35024 1.0\n",
      "35028 1.0\n",
      "35029 0.9765625\n",
      "35033 0.9652300824175825\n",
      "35035 0.9652300824175825\n",
      "35036 1.0\n",
      "35037 1.0\n",
      "35038 1.0\n",
      "35043 1.0\n",
      "35044 1.0\n",
      "35052 0.828125\n",
      "35058 1.0\n",
      "35060 1.0\n",
      "35064 0.9296875\n",
      "35066 1.0\n",
      "35077 1.0\n",
      "35081 1.0\n",
      "35082 1.0\n",
      "35093 1.0\n",
      "35096 0.98046875\n",
      "35104 1.0\n",
      "35105 1.0\n",
      "35108 1.0\n",
      "35111 0.9505494505494505\n",
      "35118 1.0\n",
      "35120 1.0\n",
      "35122 0.9609375\n",
      "35126 1.0\n",
      "35128 1.0\n",
      "35141 1.0\n",
      "35142 1.0\n",
      "35143 1.0\n",
      "35150 0.9427083333333334\n",
      "35151 1.0\n",
      "35153 1.0\n",
      "35156 1.0\n",
      "35157 1.0\n",
      "35165 1.0\n",
      "35167 1.0\n",
      "35169 0.9801377118644068\n",
      "35172 1.0\n",
      "35179 0.96875\n",
      "35184 1.0\n",
      "35186 1.0\n",
      "35188 1.0\n",
      "35190 1.0\n",
      "35192 1.0\n",
      "35202 1.0\n",
      "35215 1.0\n",
      "35220 1.0\n",
      "35221 1.0\n",
      "35223 1.0\n",
      "35225 1.0\n",
      "35226 1.0\n",
      "35228 1.0\n",
      "35230 1.0\n",
      "35239 1.0\n",
      "35245 1.0\n",
      "35246 1.0\n",
      "35250 1.0\n",
      "35254 1.0\n",
      "35255 1.0\n",
      "35258 1.0\n",
      "35259 1.0\n",
      "35260 1.0\n",
      "35263 1.0\n",
      "35264 1.0\n",
      "35266 1.0\n",
      "35268 1.0\n",
      "35270 1.0\n",
      "35273 1.0\n",
      "35277 1.0\n",
      "35278 1.0\n",
      "35282 1.0\n",
      "35289 1.0\n",
      "35294 1.0\n",
      "35298 1.0\n",
      "35300 1.0\n",
      "35303 1.0\n",
      "35304 1.0\n",
      "35306 1.0\n",
      "35309 1.0\n",
      "35313 1.0\n",
      "35316 1.0\n",
      "35317 1.0\n",
      "35325 0.9375\n",
      "35328 1.0\n",
      "35330 1.0\n",
      "35331 1.0\n",
      "35336 1.0\n",
      "35337 1.0\n",
      "35346 0.9583333333333334\n",
      "35358 1.0\n",
      "35360 1.0\n",
      "35369 1.0\n",
      "35374 1.0\n",
      "35378 0.9375\n",
      "35381 1.0\n",
      "35383 0.9621975806451613\n",
      "35386 1.0\n",
      "35389 1.0\n",
      "35397 1.0\n",
      "35398 1.0\n",
      "35402 1.0\n",
      "35405 1.0\n",
      "35406 1.0\n",
      "35407 0.9453125\n",
      "35410 1.0\n",
      "35414 1.0\n",
      "35415 1.0\n",
      "35417 0.9375\n",
      "35422 1.0\n",
      "35425 1.0\n",
      "35437 1.0\n",
      "35443 0.9541666666666667\n",
      "35444 1.0\n",
      "35446 1.0\n",
      "35447 1.0\n",
      "35450 1.0\n",
      "35453 0.9453125\n",
      "35458 1.0\n",
      "35459 1.0\n",
      "35470 1.0\n",
      "35472 1.0\n",
      "35473 1.0\n",
      "35474 1.0\n",
      "35475 1.0\n",
      "35476 0.9635416666666666\n",
      "35477 1.0\n",
      "35481 1.0\n",
      "35486 1.0\n",
      "35487 0.958984375\n",
      "35489 1.0\n",
      "35492 0.9821428571428571\n",
      "35496 1.0\n",
      "35498 1.0\n",
      "35502 1.0\n",
      "35508 1.0\n",
      "35513 1.0\n",
      "35515 1.0\n",
      "35516 1.0\n",
      "35525 0.9548277243589743\n",
      "35527 1.0\n",
      "35530 1.0\n",
      "35534 1.0\n",
      "35535 1.0\n",
      "35539 1.0\n",
      "35552 1.0\n",
      "35556 1.0\n",
      "35561 1.0\n",
      "35562 0.9806547619047619\n",
      "35563 1.0\n",
      "35564 1.0\n",
      "35574 1.0\n",
      "35575 1.0\n",
      "35576 1.0\n",
      "35578 1.0\n",
      "35585 1.0\n",
      "35586 1.0\n",
      "35590 0.9140625\n",
      "35591 1.0\n",
      "35593 1.0\n",
      "35597 1.0\n",
      "35598 1.0\n",
      "35601 1.0\n",
      "35602 1.0\n",
      "35605 1.0\n",
      "35610 1.0\n",
      "35612 1.0\n",
      "35617 1.0\n",
      "35620 1.0\n",
      "35623 1.0\n",
      "35633 1.0\n",
      "35634 0.9652300824175825\n",
      "35636 1.0\n",
      "35638 1.0\n",
      "35641 0.953125\n",
      "35642 0.9453125\n",
      "35650 1.0\n",
      "35652 1.0\n",
      "35657 1.0\n",
      "35659 1.0\n",
      "35661 1.0\n",
      "35671 1.0\n",
      "35673 1.0\n",
      "35677 1.0\n",
      "35680 1.0\n",
      "35681 1.0\n",
      "35684 1.0\n",
      "35686 1.0\n",
      "35687 1.0\n",
      "35691 1.0\n",
      "35705 1.0\n",
      "35709 1.0\n",
      "35714 1.0\n",
      "35715 1.0\n",
      "35719 1.0\n",
      "35722 0.9609375\n",
      "35726 0.9453125\n",
      "35733 1.0\n",
      "35735 1.0\n",
      "35736 0.921875\n",
      "35739 1.0\n",
      "35744 1.0\n",
      "35745 0.9829545454545454\n",
      "35750 1.0\n",
      "35752 1.0\n",
      "35758 1.0\n",
      "35767 1.0\n",
      "35772 1.0\n",
      "35776 1.0\n",
      "35780 1.0\n",
      "35782 1.0\n",
      "35786 1.0\n",
      "35787 1.0\n",
      "35795 1.0\n",
      "35798 0.9453125\n",
      "35802 1.0\n",
      "35809 1.0\n",
      "35822 1.0\n",
      "35828 1.0\n",
      "35831 1.0\n",
      "35833 1.0\n",
      "35838 1.0\n",
      "35840 0.9497767857142857\n",
      "35841 1.0\n",
      "35842 0.9296875\n",
      "35843 1.0\n",
      "35845 0.9270833333333334\n",
      "35848 1.0\n",
      "35854 1.0\n",
      "35855 0.9621975806451613\n",
      "35857 1.0\n",
      "35859 1.0\n",
      "35861 1.0\n",
      "35866 1.0\n",
      "35867 1.0\n",
      "35869 1.0\n",
      "35871 1.0\n",
      "35880 1.0\n",
      "35881 1.0\n",
      "35883 0.96875\n",
      "35885 1.0\n",
      "35886 0.984375\n",
      "35891 0.9754901960784313\n",
      "35895 1.0\n",
      "35897 1.0\n",
      "35898 1.0\n",
      "35901 0.9793198529411765\n",
      "35903 1.0\n",
      "35909 0.9375\n",
      "35911 1.0\n",
      "35913 1.0\n",
      "35919 1.0\n",
      "35920 0.9621975806451613\n",
      "35922 1.0\n",
      "35923 0.9517463235294118\n",
      "35926 1.0\n",
      "35927 1.0\n",
      "35928 1.0\n",
      "35933 0.9453125\n",
      "35937 1.0\n",
      "35939 0.9609375\n",
      "35941 1.0\n",
      "35946 1.0\n",
      "35949 1.0\n",
      "35951 1.0\n",
      "35960 1.0\n",
      "35961 0.90625\n",
      "35962 1.0\n",
      "35966 1.0\n",
      "35967 0.9453125\n",
      "35968 1.0\n",
      "35971 1.0\n",
      "35973 1.0\n",
      "35974 0.98046875\n",
      "35975 0.9375\n",
      "35980 1.0\n",
      "35987 0.953125\n",
      "35988 1.0\n",
      "35991 1.0\n",
      "35994 1.0\n",
      "35995 1.0\n",
      "35996 1.0\n",
      "35997 1.0\n",
      "36004 1.0\n",
      "36007 1.0\n",
      "36010 1.0\n",
      "36013 1.0\n",
      "36018 1.0\n",
      "36021 1.0\n",
      "36024 1.0\n",
      "36028 1.0\n",
      "36030 0.9583333333333334\n",
      "36031 1.0\n",
      "36032 1.0\n",
      "36038 1.0\n",
      "36053 0.9754901960784313\n",
      "36056 1.0\n",
      "36062 1.0\n",
      "36063 1.0\n",
      "36065 1.0\n",
      "36066 1.0\n",
      "36067 0.9609375\n",
      "36069 1.0\n",
      "36072 1.0\n",
      "36073 0.9621975806451613\n",
      "36084 1.0\n",
      "36089 0.9526041666666667\n",
      "36095 0.9541666666666667\n",
      "36097 1.0\n",
      "36098 1.0\n",
      "36100 1.0\n",
      "36104 1.0\n",
      "36105 1.0\n",
      "36119 1.0\n",
      "36126 0.9765625\n",
      "36132 1.0\n",
      "36135 1.0\n",
      "36140 1.0\n",
      "36141 0.8203125\n",
      "36142 1.0\n",
      "36146 1.0\n",
      "36149 0.9337121212121212\n",
      "36168 1.0\n",
      "36172 1.0\n",
      "36173 1.0\n",
      "36179 1.0\n",
      "36189 1.0\n",
      "36194 1.0\n",
      "36199 1.0\n",
      "36207 0.90625\n",
      "36214 1.0\n",
      "36215 1.0\n",
      "36219 1.0\n",
      "36223 1.0\n",
      "36224 1.0\n",
      "36227 0.9801377118644068\n",
      "36230 1.0\n",
      "36234 1.0\n",
      "36238 0.94921875\n",
      "36241 1.0\n",
      "36242 1.0\n",
      "36249 1.0\n",
      "36263 1.0\n",
      "36269 0.9801377118644068\n",
      "36275 1.0\n",
      "36277 1.0\n",
      "36279 0.9415922619047619\n",
      "36280 1.0\n",
      "36281 1.0\n",
      "36285 1.0\n",
      "36291 1.0\n",
      "36298 1.0\n",
      "36304 1.0\n",
      "36306 1.0\n",
      "36308 0.9427083333333334\n",
      "36312 1.0\n",
      "36313 1.0\n",
      "36314 1.0\n",
      "36322 0.9638097426470589\n",
      "36326 1.0\n",
      "36332 1.0\n",
      "36337 1.0\n",
      "36338 1.0\n",
      "36341 0.9375\n",
      "36353 1.0\n",
      "36357 1.0\n",
      "36359 1.0\n",
      "36362 1.0\n",
      "36363 0.9609375\n",
      "36364 0.9231770833333334\n",
      "36365 1.0\n",
      "36367 0.96875\n",
      "36372 1.0\n",
      "36377 1.0\n",
      "36378 1.0\n",
      "36379 1.0\n",
      "36381 1.0\n",
      "36382 1.0\n",
      "36386 0.9583333333333334\n",
      "36388 0.9541666666666667\n",
      "36390 0.96484375\n",
      "36391 1.0\n",
      "36394 1.0\n",
      "36395 1.0\n",
      "36396 0.9497767857142857\n",
      "36398 1.0\n",
      "36401 1.0\n",
      "36402 1.0\n",
      "36407 0.9791666666666666\n",
      "36409 0.9621975806451613\n",
      "36414 1.0\n",
      "36415 1.0\n",
      "36421 1.0\n",
      "36423 1.0\n",
      "36424 1.0\n",
      "36426 1.0\n",
      "36430 1.0\n",
      "36431 1.0\n",
      "36441 1.0\n",
      "36443 0.9665178571428571\n",
      "36456 1.0\n",
      "36460 0.9895833333333334\n",
      "36461 1.0\n",
      "36465 1.0\n",
      "36471 1.0\n",
      "36475 1.0\n",
      "36477 1.0\n",
      "36481 1.0\n",
      "36484 1.0\n",
      "36488 1.0\n",
      "36490 1.0\n",
      "36496 1.0\n",
      "36497 1.0\n",
      "36499 1.0\n",
      "36500 0.9479166666666666\n",
      "36505 1.0\n",
      "36506 1.0\n",
      "36508 1.0\n",
      "36510 1.0\n",
      "36513 1.0\n",
      "36514 1.0\n",
      "36518 1.0\n",
      "36527 1.0\n",
      "36528 1.0\n",
      "36529 1.0\n",
      "36530 1.0\n",
      "36531 0.9296875\n",
      "36534 1.0\n",
      "36543 1.0\n",
      "36546 1.0\n",
      "36548 1.0\n",
      "36551 1.0\n",
      "36559 1.0\n",
      "36562 1.0\n",
      "36563 1.0\n",
      "36573 1.0\n",
      "36578 1.0\n",
      "36579 1.0\n",
      "36580 1.0\n",
      "36586 1.0\n",
      "36602 1.0\n",
      "36605 1.0\n",
      "36606 1.0\n",
      "36609 1.0\n",
      "36610 1.0\n",
      "36614 1.0\n",
      "36617 1.0\n",
      "36619 1.0\n",
      "36623 1.0\n",
      "36627 1.0\n",
      "36631 1.0\n",
      "36634 1.0\n",
      "36644 1.0\n",
      "36650 1.0\n",
      "36651 1.0\n",
      "36655 1.0\n",
      "36661 1.0\n",
      "36665 1.0\n",
      "36668 1.0\n",
      "36670 1.0\n",
      "36672 1.0\n",
      "36674 1.0\n",
      "36678 1.0\n",
      "36679 1.0\n",
      "36682 1.0\n",
      "36687 0.9732142857142857\n",
      "36690 1.0\n",
      "36698 1.0\n",
      "36704 1.0\n",
      "36714 1.0\n",
      "36719 1.0\n",
      "36720 1.0\n",
      "36722 1.0\n",
      "36723 1.0\n",
      "36728 1.0\n",
      "36739 1.0\n",
      "36742 1.0\n",
      "36743 1.0\n",
      "36744 1.0\n",
      "36751 1.0\n",
      "36752 1.0\n",
      "36755 0.8828125\n",
      "36757 1.0\n",
      "36759 0.9375\n",
      "36764 1.0\n",
      "36766 1.0\n",
      "36768 1.0\n",
      "36776 1.0\n",
      "36777 1.0\n",
      "36778 1.0\n",
      "36782 1.0\n",
      "36786 1.0\n",
      "36790 1.0\n",
      "36805 1.0\n",
      "36807 1.0\n",
      "36809 1.0\n",
      "36811 1.0\n",
      "36813 1.0\n",
      "36815 1.0\n",
      "36821 1.0\n",
      "36822 1.0\n",
      "36835 1.0\n",
      "36836 1.0\n",
      "36839 1.0\n",
      "36840 1.0\n",
      "36843 1.0\n",
      "36858 1.0\n",
      "36864 1.0\n",
      "36866 1.0\n",
      "36869 1.0\n",
      "36875 1.0\n",
      "36876 1.0\n",
      "36877 0.96875\n",
      "36879 1.0\n",
      "36881 1.0\n",
      "36884 1.0\n",
      "36886 1.0\n",
      "36888 1.0\n",
      "36889 1.0\n",
      "36897 1.0\n",
      "36900 0.9453125\n",
      "36902 0.9505494505494505\n",
      "36903 1.0\n",
      "36910 1.0\n",
      "36911 1.0\n",
      "36920 0.96875\n",
      "36928 0.9375\n",
      "36932 1.0\n",
      "36933 1.0\n",
      "36934 1.0\n",
      "36935 1.0\n",
      "36937 0.96875\n",
      "36939 1.0\n",
      "36940 1.0\n",
      "36942 0.9526041666666667\n",
      "36945 1.0\n",
      "36948 1.0\n",
      "36949 1.0\n",
      "36951 1.0\n",
      "36953 1.0\n",
      "36955 1.0\n",
      "36958 1.0\n",
      "36962 1.0\n",
      "36969 1.0\n",
      "36971 1.0\n",
      "36973 1.0\n",
      "36975 1.0\n",
      "36978 1.0\n",
      "36981 1.0\n",
      "36985 1.0\n",
      "36991 1.0\n",
      "36992 1.0\n",
      "36995 1.0\n",
      "37004 1.0\n",
      "37008 1.0\n",
      "37033 1.0\n",
      "37041 1.0\n",
      "37049 1.0\n",
      "37054 0.9754901960784313\n",
      "37055 1.0\n",
      "37059 1.0\n",
      "37060 1.0\n",
      "37063 1.0\n",
      "37080 0.953125\n",
      "37082 1.0\n",
      "37090 1.0\n",
      "37091 1.0\n",
      "37094 1.0\n",
      "37097 1.0\n",
      "37101 1.0\n",
      "37105 1.0\n",
      "37110 1.0\n",
      "37111 1.0\n",
      "37112 1.0\n",
      "37115 1.0\n",
      "37117 1.0\n",
      "37120 1.0\n",
      "37122 1.0\n",
      "37125 1.0\n",
      "37127 1.0\n",
      "37129 1.0\n",
      "37131 1.0\n",
      "37134 0.9765625\n",
      "37135 1.0\n",
      "37136 1.0\n",
      "37140 1.0\n",
      "37150 1.0\n",
      "37163 1.0\n",
      "37165 1.0\n",
      "37168 1.0\n",
      "37172 0.921875\n",
      "37175 1.0\n",
      "37177 1.0\n",
      "37180 0.9296875\n",
      "37184 1.0\n",
      "37186 1.0\n",
      "37188 1.0\n",
      "37197 1.0\n",
      "37198 1.0\n",
      "37202 1.0\n",
      "37203 1.0\n",
      "37209 1.0\n",
      "37216 1.0\n",
      "37218 0.9186197916666666\n",
      "37222 0.9739583333333334\n",
      "37224 1.0\n",
      "37225 1.0\n",
      "37227 1.0\n",
      "37242 1.0\n",
      "37245 1.0\n",
      "37248 0.9829545454545454\n",
      "37249 1.0\n",
      "37252 1.0\n",
      "37253 1.0\n",
      "37257 0.9479166666666666\n",
      "37258 1.0\n",
      "37261 1.0\n",
      "37263 1.0\n",
      "37267 1.0\n",
      "37273 1.0\n",
      "37286 1.0\n",
      "37288 1.0\n",
      "37289 1.0\n",
      "37293 1.0\n",
      "37294 1.0\n",
      "37296 1.0\n",
      "37298 1.0\n",
      "37310 1.0\n",
      "37311 0.9609375\n",
      "37317 1.0\n",
      "37318 0.9556107954545454\n",
      "37323 1.0\n",
      "37324 1.0\n",
      "37325 1.0\n",
      "37327 1.0\n",
      "37330 1.0\n",
      "37332 1.0\n",
      "37333 0.9635416666666666\n",
      "37337 1.0\n",
      "37340 1.0\n",
      "37341 1.0\n",
      "37342 1.0\n",
      "37346 1.0\n",
      "37347 1.0\n",
      "37348 1.0\n",
      "37354 1.0\n",
      "37356 0.96875\n",
      "37359 1.0\n",
      "37362 1.0\n",
      "37367 0.9765625\n",
      "37369 1.0\n",
      "37375 1.0\n",
      "37376 1.0\n",
      "37377 1.0\n",
      "37380 0.96875\n",
      "37381 1.0\n",
      "37384 1.0\n",
      "37390 1.0\n",
      "37400 0.971875\n",
      "37401 1.0\n",
      "37403 1.0\n",
      "37405 1.0\n",
      "37413 1.0\n",
      "37418 1.0\n",
      "37420 1.0\n",
      "37425 1.0\n",
      "37429 1.0\n",
      "37431 1.0\n",
      "37437 1.0\n",
      "37439 1.0\n",
      "37441 1.0\n",
      "37450 1.0\n",
      "37462 1.0\n",
      "37463 1.0\n",
      "37472 0.9791666666666666\n",
      "37478 1.0\n",
      "37479 1.0\n",
      "37485 1.0\n",
      "37499 1.0\n",
      "37500 1.0\n",
      "37506 1.0\n",
      "37508 1.0\n",
      "37510 1.0\n",
      "37511 1.0\n",
      "37518 1.0\n",
      "37521 1.0\n",
      "37523 1.0\n",
      "37533 1.0\n",
      "37536 1.0\n",
      "37537 1.0\n",
      "37539 1.0\n",
      "37541 1.0\n",
      "37545 0.984375\n",
      "37547 1.0\n",
      "37551 0.9643342391304348\n",
      "37553 1.0\n",
      "37555 1.0\n",
      "37556 1.0\n",
      "37564 1.0\n",
      "37565 1.0\n",
      "37568 1.0\n",
      "37574 1.0\n",
      "37577 1.0\n",
      "37582 1.0\n",
      "37586 0.962071718931475\n",
      "37593 1.0\n",
      "37597 1.0\n",
      "37600 1.0\n",
      "37605 0.921875\n",
      "37618 1.0\n",
      "37622 1.0\n",
      "37625 1.0\n",
      "37627 1.0\n",
      "37629 1.0\n",
      "37630 1.0\n",
      "37652 1.0\n",
      "37653 1.0\n",
      "37654 1.0\n",
      "37657 0.828125\n",
      "37658 1.0\n",
      "37665 1.0\n",
      "37668 1.0\n",
      "37671 1.0\n",
      "37677 1.0\n",
      "37686 1.0\n",
      "37687 1.0\n",
      "37688 0.9609375\n",
      "37704 1.0\n",
      "37708 1.0\n",
      "37714 0.9643342391304348\n",
      "37715 1.0\n",
      "37718 1.0\n",
      "37721 1.0\n",
      "37730 1.0\n",
      "37736 1.0\n",
      "37744 1.0\n",
      "37745 1.0\n",
      "37750 1.0\n",
      "37751 0.9270833333333334\n",
      "37753 1.0\n",
      "37754 0.953125\n",
      "37755 1.0\n",
      "37756 1.0\n",
      "37757 1.0\n",
      "37758 0.953125\n",
      "37760 1.0\n",
      "37761 1.0\n",
      "37762 1.0\n",
      "37768 0.9598214285714286\n",
      "37770 1.0\n",
      "37771 1.0\n",
      "37773 1.0\n",
      "37774 1.0\n",
      "37778 0.9791666666666666\n",
      "37779 1.0\n",
      "37784 1.0\n",
      "37785 1.0\n",
      "37788 0.9625\n",
      "37789 0.9526041666666667\n",
      "37801 1.0\n",
      "37804 1.0\n",
      "37812 1.0\n",
      "37813 1.0\n",
      "37815 1.0\n",
      "37817 1.0\n",
      "37818 1.0\n",
      "37823 1.0\n",
      "37825 0.9602272727272727\n",
      "37826 1.0\n",
      "37831 0.953125\n",
      "37835 1.0\n",
      "37836 1.0\n",
      "37838 0.9453125\n",
      "37839 1.0\n",
      "37841 1.0\n",
      "37852 1.0\n",
      "37858 1.0\n",
      "37860 1.0\n",
      "37864 1.0\n",
      "37865 1.0\n",
      "37869 1.0\n",
      "37874 0.9453125\n",
      "37876 1.0\n",
      "37883 1.0\n",
      "37885 1.0\n",
      "37888 1.0\n",
      "37892 0.9337121212121212\n",
      "37894 1.0\n",
      "37896 1.0\n",
      "37899 1.0\n",
      "37902 1.0\n",
      "37903 0.9578125\n",
      "37905 0.9337121212121212\n",
      "37906 1.0\n",
      "37914 1.0\n",
      "37915 0.984375\n",
      "37926 1.0\n",
      "37927 0.96875\n",
      "37931 1.0\n",
      "37932 0.9801377118644068\n",
      "37938 1.0\n",
      "37957 1.0\n",
      "37962 1.0\n",
      "37965 0.9665178571428571\n",
      "37971 1.0\n",
      "37982 1.0\n",
      "37989 1.0\n",
      "37992 0.9497767857142857\n",
      "37994 1.0\n",
      "37995 1.0\n",
      "37996 1.0\n",
      "37998 1.0\n",
      "37999 1.0\n",
      "38002 1.0\n",
      "38004 1.0\n",
      "38010 1.0\n",
      "38012 1.0\n",
      "38015 0.9754901960784313\n",
      "38022 1.0\n",
      "38023 0.9337121212121212\n",
      "38025 1.0\n",
      "38026 1.0\n",
      "38030 1.0\n",
      "38033 1.0\n",
      "38034 0.9296875\n",
      "38035 0.9625\n",
      "38036 1.0\n",
      "38040 1.0\n",
      "38041 1.0\n",
      "38048 1.0\n",
      "38052 1.0\n",
      "38054 0.9453125\n",
      "38057 1.0\n",
      "38061 1.0\n",
      "38065 1.0\n",
      "38066 1.0\n",
      "38067 1.0\n",
      "38082 1.0\n",
      "38087 1.0\n",
      "38098 1.0\n",
      "38102 0.9337121212121212\n",
      "38103 1.0\n",
      "38108 1.0\n",
      "38112 1.0\n",
      "38119 1.0\n",
      "38120 1.0\n",
      "38122 1.0\n",
      "38124 1.0\n",
      "38127 1.0\n",
      "38129 1.0\n",
      "38135 0.9505208333333334\n",
      "38137 0.9583333333333334\n",
      "38138 1.0\n",
      "38139 1.0\n",
      "38141 1.0\n",
      "38142 1.0\n",
      "38147 1.0\n",
      "38148 1.0\n",
      "38149 1.0\n",
      "38151 1.0\n",
      "38160 1.0\n",
      "38161 1.0\n",
      "38167 1.0\n",
      "38168 0.9427083333333334\n",
      "38170 1.0\n",
      "38173 1.0\n",
      "38176 0.9352678571428571\n",
      "38178 1.0\n",
      "38184 1.0\n",
      "38190 1.0\n",
      "38192 1.0\n",
      "38200 1.0\n",
      "38202 1.0\n",
      "38204 0.9609375\n",
      "38205 1.0\n",
      "38215 1.0\n",
      "38217 1.0\n",
      "38221 1.0\n",
      "38226 1.0\n",
      "38230 1.0\n",
      "38232 1.0\n",
      "38238 1.0\n",
      "38240 1.0\n",
      "38244 1.0\n",
      "38245 1.0\n",
      "38249 1.0\n",
      "38252 1.0\n",
      "38254 0.9801377118644068\n",
      "38258 1.0\n",
      "38264 0.9497767857142857\n",
      "38269 1.0\n",
      "38272 1.0\n",
      "38273 1.0\n",
      "38282 1.0\n",
      "38283 0.9609375\n",
      "38284 1.0\n",
      "38286 1.0\n",
      "38288 1.0\n",
      "38292 1.0\n",
      "38293 1.0\n",
      "38301 1.0\n",
      "38305 1.0\n",
      "38308 1.0\n",
      "38315 0.9556107954545454\n",
      "38322 1.0\n",
      "38323 1.0\n",
      "38325 1.0\n",
      "38330 1.0\n",
      "38332 1.0\n",
      "38343 1.0\n",
      "38345 1.0\n",
      "38347 1.0\n",
      "38348 0.9458333333333333\n",
      "38351 1.0\n",
      "38352 1.0\n",
      "38355 1.0\n",
      "38356 1.0\n",
      "38359 0.96875\n",
      "38367 0.9739583333333334\n",
      "38368 1.0\n",
      "38370 1.0\n",
      "38371 1.0\n",
      "38372 1.0\n",
      "38373 0.9583333333333334\n",
      "38382 1.0\n",
      "38384 1.0\n",
      "38385 1.0\n",
      "38392 1.0\n",
      "38393 1.0\n",
      "38396 1.0\n",
      "38397 1.0\n",
      "38398 1.0\n",
      "38407 1.0\n",
      "38411 1.0\n",
      "38412 1.0\n",
      "38413 1.0\n",
      "38422 1.0\n",
      "38426 0.9598214285714286\n",
      "38431 1.0\n",
      "38437 1.0\n",
      "38447 1.0\n",
      "38454 1.0\n",
      "38457 1.0\n",
      "38459 1.0\n",
      "38466 1.0\n",
      "38468 1.0\n",
      "38474 1.0\n",
      "38480 1.0\n",
      "38483 1.0\n",
      "38488 1.0\n",
      "38494 1.0\n",
      "38496 1.0\n",
      "38499 1.0\n",
      "38504 1.0\n",
      "38507 1.0\n",
      "38509 0.9635416666666666\n",
      "38512 0.9801377118644068\n",
      "38515 1.0\n",
      "38522 0.9140625\n",
      "38524 1.0\n",
      "38527 0.96875\n",
      "38528 1.0\n",
      "38531 1.0\n",
      "38534 1.0\n",
      "38535 1.0\n",
      "38537 0.9416666666666667\n",
      "38543 1.0\n",
      "38547 1.0\n",
      "38551 1.0\n",
      "38554 1.0\n",
      "38556 1.0\n",
      "38558 1.0\n",
      "38560 1.0\n",
      "38568 1.0\n",
      "38569 1.0\n",
      "38571 1.0\n",
      "38574 1.0\n",
      "38583 1.0\n",
      "38584 1.0\n",
      "38585 1.0\n",
      "38589 1.0\n",
      "38591 0.9801377118644068\n",
      "38595 0.9388020833333334\n",
      "38599 1.0\n",
      "38604 1.0\n",
      "38614 1.0\n",
      "38618 1.0\n",
      "38619 1.0\n",
      "38620 1.0\n",
      "38622 1.0\n",
      "38625 0.9638097426470589\n",
      "38626 1.0\n",
      "38629 1.0\n",
      "38637 1.0\n",
      "38641 0.96875\n",
      "38643 0.921875\n",
      "38648 1.0\n",
      "38650 1.0\n",
      "38651 1.0\n",
      "38653 1.0\n",
      "38655 0.9427083333333334\n",
      "38663 1.0\n",
      "38665 1.0\n",
      "38666 1.0\n",
      "38668 1.0\n",
      "38673 0.9621975806451613\n",
      "38674 1.0\n",
      "38676 1.0\n",
      "38679 1.0\n",
      "38681 0.9583333333333334\n",
      "38682 1.0\n",
      "38683 1.0\n",
      "38689 1.0\n",
      "38691 1.0\n",
      "38696 1.0\n",
      "38709 1.0\n",
      "38711 1.0\n",
      "38712 1.0\n",
      "38714 1.0\n",
      "38716 1.0\n",
      "38718 1.0\n",
      "38719 1.0\n",
      "38721 1.0\n",
      "38726 0.9625\n",
      "38727 1.0\n",
      "38729 1.0\n",
      "38730 1.0\n",
      "38736 1.0\n",
      "38738 1.0\n",
      "38739 1.0\n",
      "38742 1.0\n",
      "38747 0.953125\n",
      "38751 1.0\n",
      "38756 0.9665178571428571\n",
      "38762 1.0\n",
      "38764 1.0\n",
      "38767 1.0\n",
      "38775 1.0\n",
      "38779 1.0\n",
      "38780 1.0\n",
      "38782 1.0\n",
      "38783 1.0\n",
      "38784 1.0\n",
      "38786 1.0\n",
      "38789 1.0\n",
      "38791 1.0\n",
      "38793 1.0\n",
      "38794 1.0\n",
      "38796 1.0\n",
      "38797 0.9739583333333334\n",
      "38801 1.0\n",
      "38805 1.0\n",
      "38811 1.0\n",
      "38814 0.921875\n",
      "38817 1.0\n",
      "38822 1.0\n",
      "38832 1.0\n",
      "38836 1.0\n",
      "38838 0.9427083333333334\n",
      "38841 1.0\n",
      "38848 1.0\n",
      "38851 1.0\n",
      "38854 1.0\n",
      "38855 1.0\n",
      "38856 1.0\n",
      "38860 1.0\n",
      "38862 1.0\n",
      "38864 1.0\n",
      "38867 1.0\n",
      "38876 1.0\n",
      "38890 1.0\n",
      "38891 1.0\n",
      "38899 1.0\n",
      "38902 0.96875\n",
      "38906 1.0\n",
      "38924 1.0\n",
      "38925 0.953125\n",
      "38929 1.0\n",
      "38930 1.0\n",
      "38931 1.0\n",
      "38938 1.0\n",
      "38941 1.0\n",
      "38944 0.9453125\n",
      "38947 1.0\n",
      "38948 1.0\n",
      "38952 1.0\n",
      "38956 1.0\n",
      "38959 1.0\n",
      "38962 1.0\n",
      "38964 1.0\n",
      "38973 0.9791666666666666\n",
      "38975 1.0\n",
      "38983 1.0\n",
      "38989 1.0\n",
      "38994 1.0\n",
      "38995 1.0\n",
      "39003 1.0\n",
      "39006 1.0\n",
      "39007 1.0\n",
      "39008 1.0\n",
      "39012 0.953125\n",
      "39013 0.9375\n",
      "39016 1.0\n",
      "39019 1.0\n",
      "39028 1.0\n",
      "39032 1.0\n",
      "39033 1.0\n",
      "39034 1.0\n",
      "39036 1.0\n",
      "39040 0.971875\n",
      "39041 1.0\n",
      "39043 1.0\n",
      "39048 1.0\n",
      "39051 1.0\n",
      "39059 1.0\n",
      "39060 1.0\n",
      "39061 1.0\n",
      "39067 1.0\n",
      "39069 1.0\n",
      "39077 0.9638097426470589\n",
      "39083 1.0\n",
      "39093 0.962071718931475\n",
      "39100 0.9625\n",
      "39101 0.9621975806451613\n",
      "39107 1.0\n",
      "39109 1.0\n",
      "39112 1.0\n",
      "39115 1.0\n",
      "39116 1.0\n",
      "39119 1.0\n",
      "39121 0.9453125\n",
      "39123 1.0\n",
      "39131 1.0\n",
      "39132 1.0\n",
      "39135 1.0\n",
      "39136 1.0\n",
      "39142 1.0\n",
      "39143 1.0\n",
      "39150 1.0\n",
      "39155 0.75\n",
      "39162 1.0\n",
      "39167 1.0\n",
      "39174 1.0\n",
      "39176 1.0\n",
      "39178 1.0\n",
      "39180 1.0\n",
      "39184 1.0\n",
      "39185 1.0\n",
      "39188 1.0\n",
      "39192 1.0\n",
      "39194 1.0\n",
      "39199 1.0\n",
      "39210 1.0\n",
      "39213 1.0\n",
      "39216 1.0\n",
      "39226 1.0\n",
      "39232 1.0\n",
      "39237 1.0\n",
      "39242 1.0\n",
      "39248 1.0\n",
      "39264 1.0\n",
      "39266 0.9696691176470589\n",
      "39269 1.0\n",
      "39271 1.0\n",
      "39272 1.0\n",
      "39273 1.0\n",
      "39277 0.9765625\n",
      "39280 1.0\n",
      "39281 1.0\n",
      "39284 0.9230171783625731\n",
      "39285 1.0\n",
      "39291 1.0\n",
      "39293 1.0\n",
      "39298 1.0\n",
      "39299 1.0\n",
      "39318 0.90625\n",
      "39322 1.0\n",
      "39323 1.0\n",
      "39326 1.0\n",
      "39331 1.0\n",
      "39335 1.0\n",
      "39338 1.0\n",
      "39340 1.0\n",
      "39341 1.0\n",
      "39342 1.0\n",
      "39346 1.0\n",
      "39351 1.0\n",
      "39354 1.0\n",
      "39355 1.0\n",
      "39365 1.0\n",
      "39367 0.9921875\n",
      "39370 1.0\n",
      "39373 1.0\n",
      "39375 1.0\n",
      "39378 1.0\n",
      "39379 1.0\n",
      "39382 1.0\n",
      "39387 1.0\n",
      "39389 1.0\n",
      "39395 1.0\n",
      "39397 1.0\n",
      "39401 1.0\n",
      "39402 1.0\n",
      "39404 1.0\n",
      "39407 1.0\n",
      "39409 1.0\n",
      "39415 1.0\n",
      "39417 0.9583333333333334\n",
      "39422 1.0\n",
      "39424 1.0\n",
      "39432 0.9765625\n",
      "39434 1.0\n",
      "39438 1.0\n",
      "39439 1.0\n",
      "39444 1.0\n",
      "39445 1.0\n",
      "39448 1.0\n",
      "39450 1.0\n",
      "39456 1.0\n",
      "39458 1.0\n",
      "39459 1.0\n",
      "39460 0.9296875\n",
      "39463 1.0\n",
      "39464 1.0\n",
      "39470 1.0\n",
      "39476 1.0\n",
      "39477 1.0\n",
      "39485 1.0\n",
      "39488 1.0\n",
      "39496 1.0\n",
      "39498 1.0\n",
      "39501 0.962071718931475\n",
      "39506 0.9244791666666666\n",
      "39508 1.0\n",
      "39509 1.0\n",
      "39510 1.0\n",
      "39515 1.0\n",
      "39517 0.9739583333333334\n",
      "39519 1.0\n",
      "39520 1.0\n",
      "39523 1.0\n",
      "39524 1.0\n",
      "39526 1.0\n",
      "39530 1.0\n",
      "39534 1.0\n",
      "39535 1.0\n",
      "39536 1.0\n",
      "39542 1.0\n",
      "39543 1.0\n",
      "39544 1.0\n",
      "39545 1.0\n",
      "39549 1.0\n",
      "39554 0.9817708333333334\n",
      "39560 0.9140625\n",
      "39561 1.0\n",
      "39566 0.9588815789473685\n",
      "39567 1.0\n",
      "39570 1.0\n",
      "39573 1.0\n",
      "39575 1.0\n",
      "39578 1.0\n",
      "39580 0.962071718931475\n",
      "39584 1.0\n",
      "39594 1.0\n",
      "39597 1.0\n",
      "39607 1.0\n",
      "39611 1.0\n",
      "39621 1.0\n",
      "39622 1.0\n",
      "39625 1.0\n",
      "39626 1.0\n",
      "39627 1.0\n",
      "39628 1.0\n",
      "39630 0.96484375\n",
      "39631 0.9801377118644068\n",
      "39634 1.0\n",
      "39637 1.0\n",
      "39652 1.0\n",
      "39653 1.0\n",
      "39662 0.9783653846153846\n",
      "39664 1.0\n",
      "39666 1.0\n",
      "39667 1.0\n",
      "39669 1.0\n",
      "39674 1.0\n",
      "39677 1.0\n",
      "39682 1.0\n",
      "39692 1.0\n",
      "39696 1.0\n",
      "39698 0.9799107142857143\n",
      "39701 1.0\n",
      "39703 1.0\n",
      "39718 0.9806547619047619\n",
      "39719 1.0\n",
      "39727 1.0\n",
      "39730 1.0\n",
      "39732 1.0\n",
      "39738 1.0\n",
      "39741 1.0\n",
      "39747 1.0\n",
      "39750 1.0\n",
      "39754 1.0\n",
      "39759 1.0\n",
      "39760 0.9375\n",
      "39763 1.0\n",
      "39764 1.0\n",
      "39765 1.0\n",
      "39772 1.0\n",
      "39773 1.0\n",
      "39777 1.0\n",
      "39780 1.0\n",
      "39781 1.0\n",
      "39790 1.0\n",
      "39793 1.0\n",
      "39805 0.9241071428571429\n",
      "39815 1.0\n",
      "39817 1.0\n",
      "39819 1.0\n",
      "39821 1.0\n",
      "39830 1.0\n",
      "39833 0.9375\n",
      "39843 1.0\n",
      "39847 1.0\n",
      "39848 1.0\n",
      "39852 1.0\n",
      "39856 1.0\n",
      "39865 1.0\n",
      "39866 1.0\n",
      "39868 1.0\n",
      "39874 1.0\n",
      "39879 1.0\n",
      "39882 0.9609375\n",
      "39884 0.9613042840375586\n",
      "39886 1.0\n",
      "39890 1.0\n",
      "39891 1.0\n",
      "39892 1.0\n",
      "39898 0.95703125\n",
      "39902 1.0\n",
      "39903 1.0\n",
      "39906 1.0\n",
      "39911 1.0\n",
      "39917 1.0\n",
      "39923 1.0\n",
      "39929 1.0\n",
      "39932 0.9505494505494505\n",
      "39938 1.0\n",
      "39940 1.0\n",
      "39942 1.0\n",
      "39943 0.96875\n",
      "39948 1.0\n",
      "39949 1.0\n",
      "39950 1.0\n",
      "39953 1.0\n",
      "39962 1.0\n",
      "39963 1.0\n",
      "39967 1.0\n",
      "39968 0.9801377118644068\n",
      "39971 1.0\n",
      "39979 1.0\n",
      "39992 1.0\n",
      "40000 1.0\n",
      "40006 0.9739583333333334\n",
      "40009 1.0\n",
      "40012 1.0\n",
      "40016 1.0\n",
      "40020 1.0\n",
      "40022 1.0\n",
      "40023 1.0\n",
      "40028 1.0\n",
      "40029 1.0\n",
      "40039 1.0\n",
      "40040 1.0\n",
      "40041 0.9830013736263736\n",
      "40046 1.0\n",
      "40048 1.0\n",
      "40049 0.9375\n",
      "40050 1.0\n",
      "40054 1.0\n",
      "40061 1.0\n",
      "40063 1.0\n",
      "40071 1.0\n",
      "40077 1.0\n",
      "40078 0.9799107142857143\n",
      "40084 1.0\n",
      "40086 1.0\n",
      "40089 1.0\n",
      "40091 1.0\n",
      "40097 0.9921875\n",
      "40099 0.9556107954545454\n",
      "40106 1.0\n",
      "40112 0.9813988095238095\n",
      "40124 0.9484375\n",
      "40131 1.0\n",
      "40132 1.0\n",
      "40139 0.9541666666666667\n",
      "40143 1.0\n",
      "40149 1.0\n",
      "40153 1.0\n",
      "40155 1.0\n",
      "40157 0.9635416666666666\n",
      "40158 0.9666666666666667\n",
      "40161 1.0\n",
      "40165 1.0\n",
      "40166 1.0\n",
      "40169 1.0\n",
      "40172 1.0\n",
      "40173 1.0\n",
      "40180 1.0\n",
      "40182 0.9505494505494505\n",
      "40183 1.0\n",
      "40187 1.0\n",
      "40189 0.9337121212121212\n",
      "40191 1.0\n",
      "40192 1.0\n",
      "40197 1.0\n",
      "40198 1.0\n",
      "40201 1.0\n",
      "40203 0.9296875\n",
      "40207 1.0\n",
      "40214 0.9765625\n",
      "40226 1.0\n",
      "40229 1.0\n",
      "40232 1.0\n",
      "40233 1.0\n",
      "40236 0.9621975806451613\n",
      "40243 1.0\n",
      "40248 0.9244791666666666\n",
      "40252 0.9522569444444444\n",
      "40259 0.9801377118644068\n",
      "40263 0.9739583333333334\n",
      "40264 1.0\n",
      "40268 1.0\n",
      "40271 0.9643342391304348\n",
      "40273 1.0\n",
      "40278 1.0\n",
      "40286 0.9427083333333334\n",
      "40290 1.0\n",
      "40292 1.0\n",
      "40301 0.9765625\n",
      "40303 1.0\n",
      "40309 1.0\n",
      "40312 1.0\n",
      "40317 1.0\n",
      "40320 1.0\n",
      "40322 1.0\n",
      "40324 1.0\n",
      "40331 1.0\n",
      "40342 0.953125\n",
      "40344 1.0\n",
      "40345 0.97265625\n",
      "40347 1.0\n",
      "40349 1.0\n",
      "40358 1.0\n",
      "40359 1.0\n",
      "40360 1.0\n",
      "40364 0.984375\n",
      "40369 1.0\n",
      "40376 1.0\n",
      "40378 0.9598214285714286\n",
      "40380 1.0\n",
      "40381 1.0\n",
      "40384 1.0\n",
      "40392 1.0\n",
      "40395 1.0\n",
      "40398 1.0\n",
      "40402 0.9635416666666666\n",
      "40403 1.0\n",
      "40404 1.0\n",
      "40406 1.0\n",
      "40407 1.0\n",
      "40409 1.0\n",
      "40410 1.0\n",
      "40411 1.0\n",
      "40414 1.0\n",
      "40417 0.9388020833333334\n",
      "40419 0.9140625\n",
      "40420 1.0\n",
      "40427 1.0\n",
      "40428 1.0\n",
      "40430 1.0\n",
      "40431 1.0\n",
      "40433 1.0\n",
      "40437 1.0\n",
      "40438 1.0\n",
      "40439 1.0\n",
      "40440 1.0\n",
      "40456 1.0\n",
      "40458 1.0\n",
      "40460 1.0\n",
      "40465 1.0\n",
      "40468 1.0\n",
      "40477 1.0\n",
      "40478 1.0\n",
      "40484 1.0\n",
      "40491 0.9635416666666666\n",
      "40498 1.0\n",
      "40502 1.0\n",
      "40505 1.0\n",
      "40507 1.0\n",
      "40512 1.0\n",
      "40519 1.0\n",
      "40521 0.9375\n",
      "40532 1.0\n",
      "40538 1.0\n",
      "40539 1.0\n",
      "40545 1.0\n",
      "40546 1.0\n",
      "40547 1.0\n",
      "40548 0.98046875\n",
      "40550 1.0\n",
      "40551 1.0\n",
      "40552 1.0\n",
      "40556 1.0\n",
      "40559 0.9453125\n",
      "40567 1.0\n",
      "40571 1.0\n",
      "40583 0.9522569444444444\n",
      "40584 1.0\n",
      "40585 1.0\n",
      "40586 1.0\n",
      "40589 1.0\n",
      "40591 1.0\n",
      "40594 1.0\n",
      "40596 1.0\n",
      "40597 1.0\n",
      "40599 1.0\n",
      "40600 1.0\n",
      "40605 1.0\n",
      "40607 1.0\n",
      "40608 1.0\n",
      "40609 1.0\n",
      "40622 1.0\n",
      "40624 1.0\n",
      "40626 1.0\n",
      "40631 1.0\n",
      "40640 1.0\n",
      "40654 1.0\n",
      "40655 1.0\n",
      "40659 1.0\n",
      "40660 1.0\n",
      "40661 1.0\n",
      "40665 0.9375\n",
      "40672 1.0\n",
      "40693 1.0\n",
      "40696 1.0\n",
      "40697 1.0\n",
      "40699 0.9671875\n",
      "40705 0.9201388888888888\n",
      "40710 0.9765625\n",
      "40711 0.9635416666666666\n",
      "40714 1.0\n",
      "40716 1.0\n",
      "40718 1.0\n",
      "40724 1.0\n",
      "40730 1.0\n",
      "40734 1.0\n",
      "40735 1.0\n",
      "40741 1.0\n",
      "40744 0.9583333333333334\n",
      "40745 1.0\n",
      "40750 1.0\n",
      "40751 1.0\n",
      "40759 1.0\n",
      "40764 1.0\n",
      "40765 1.0\n",
      "40767 1.0\n",
      "40769 1.0\n",
      "40775 1.0\n",
      "40779 1.0\n",
      "40782 1.0\n",
      "40789 1.0\n",
      "40794 1.0\n",
      "40797 1.0\n",
      "40798 1.0\n",
      "40803 1.0\n",
      "40804 1.0\n",
      "40809 1.0\n",
      "40810 1.0\n",
      "40811 1.0\n",
      "40812 1.0\n",
      "40816 1.0\n",
      "40818 1.0\n",
      "40826 1.0\n",
      "40831 1.0\n",
      "40832 0.9375\n",
      "40834 1.0\n",
      "40841 0.9783653846153846\n",
      "40843 1.0\n",
      "40845 0.9638097426470589\n",
      "40849 1.0\n",
      "40854 1.0\n",
      "40855 1.0\n",
      "40860 1.0\n",
      "40865 1.0\n",
      "40871 0.921875\n",
      "40872 1.0\n",
      "40876 1.0\n",
      "40881 1.0\n",
      "40883 0.9643342391304348\n",
      "40890 1.0\n",
      "40891 1.0\n",
      "40894 1.0\n",
      "40898 1.0\n",
      "40899 0.9642857142857143\n",
      "40900 1.0\n",
      "40903 1.0\n",
      "40908 1.0\n",
      "40912 1.0\n",
      "40914 1.0\n",
      "40915 1.0\n",
      "40916 0.9583333333333334\n",
      "40917 1.0\n",
      "40919 0.9583333333333334\n",
      "40924 1.0\n",
      "40926 1.0\n",
      "40929 1.0\n",
      "40930 0.9635416666666666\n",
      "40933 1.0\n",
      "40936 0.9598214285714286\n",
      "40946 0.9375\n",
      "40949 1.0\n",
      "40953 0.921875\n",
      "40971 1.0\n",
      "40976 1.0\n",
      "40977 1.0\n",
      "40979 1.0\n",
      "40982 0.984375\n",
      "40983 1.0\n",
      "40984 1.0\n",
      "40989 1.0\n",
      "40994 1.0\n",
      "40995 0.9453125\n",
      "40996 0.9415922619047619\n",
      "40997 1.0\n",
      "40998 1.0\n",
      "41000 1.0\n",
      "41006 1.0\n",
      "41010 1.0\n",
      "41011 1.0\n",
      "41012 0.921875\n",
      "41026 1.0\n",
      "41028 1.0\n",
      "41038 1.0\n",
      "41048 0.9453125\n",
      "41049 1.0\n",
      "41054 1.0\n",
      "41055 1.0\n",
      "41057 1.0\n",
      "41059 1.0\n",
      "41060 1.0\n",
      "41072 1.0\n",
      "41073 0.9375\n",
      "41083 1.0\n",
      "41094 1.0\n",
      "41095 1.0\n",
      "41097 0.9609375\n",
      "41108 1.0\n",
      "41120 1.0\n",
      "41121 1.0\n",
      "41124 1.0\n",
      "41129 1.0\n",
      "41134 0.9375\n",
      "41136 1.0\n",
      "41138 1.0\n",
      "41139 1.0\n",
      "41141 1.0\n",
      "41145 1.0\n",
      "41148 1.0\n",
      "41152 1.0\n",
      "41153 1.0\n",
      "41154 1.0\n",
      "41156 1.0\n",
      "41160 1.0\n",
      "41165 1.0\n",
      "41167 1.0\n",
      "41170 1.0\n",
      "41175 1.0\n",
      "41177 1.0\n",
      "41183 1.0\n",
      "41185 1.0\n",
      "41187 1.0\n",
      "41195 1.0\n",
      "41196 1.0\n",
      "41198 1.0\n",
      "41201 1.0\n",
      "41206 1.0\n",
      "41210 0.96875\n",
      "41213 1.0\n",
      "41221 1.0\n",
      "41222 1.0\n",
      "41225 1.0\n",
      "41233 1.0\n",
      "41239 1.0\n",
      "41254 1.0\n",
      "41262 1.0\n",
      "41264 0.971875\n",
      "41269 0.96875\n",
      "41270 1.0\n",
      "41276 1.0\n",
      "41279 1.0\n",
      "41284 0.96484375\n",
      "41288 1.0\n",
      "41294 1.0\n",
      "41297 1.0\n",
      "41302 1.0\n",
      "41311 1.0\n",
      "41312 1.0\n",
      "41313 1.0\n",
      "41322 1.0\n",
      "41324 1.0\n",
      "41325 1.0\n",
      "41326 1.0\n",
      "41331 1.0\n",
      "41337 1.0\n",
      "41345 1.0\n",
      "41346 1.0\n",
      "41348 1.0\n",
      "41349 1.0\n",
      "41350 1.0\n",
      "41351 1.0\n",
      "41353 1.0\n",
      "41359 1.0\n",
      "41364 1.0\n",
      "41365 0.9666666666666667\n",
      "41367 1.0\n",
      "41368 1.0\n",
      "41371 1.0\n",
      "41372 1.0\n",
      "41378 1.0\n",
      "41381 0.9602272727272727\n",
      "41395 1.0\n",
      "41397 1.0\n",
      "41398 1.0\n",
      "41402 1.0\n",
      "41403 1.0\n",
      "41404 1.0\n",
      "41406 1.0\n",
      "41409 1.0\n",
      "41410 1.0\n",
      "41412 1.0\n",
      "41415 1.0\n",
      "41422 1.0\n",
      "41423 1.0\n",
      "41425 1.0\n",
      "41428 0.9765625\n",
      "41436 1.0\n",
      "41441 1.0\n",
      "41444 1.0\n",
      "41454 1.0\n",
      "41455 1.0\n",
      "41458 1.0\n",
      "41459 1.0\n",
      "41460 1.0\n",
      "41462 0.962071718931475\n",
      "41463 1.0\n",
      "41464 1.0\n",
      "41472 1.0\n",
      "41474 1.0\n",
      "41477 1.0\n",
      "41478 1.0\n",
      "41482 1.0\n",
      "41483 0.962071718931475\n",
      "41484 0.9583333333333334\n",
      "41497 1.0\n",
      "41501 1.0\n",
      "41502 1.0\n",
      "41503 1.0\n",
      "41506 1.0\n",
      "41507 1.0\n",
      "41509 1.0\n",
      "41512 1.0\n",
      "41516 1.0\n",
      "41517 0.9479166666666666\n",
      "41521 0.9548277243589743\n",
      "41522 1.0\n",
      "41526 0.9453125\n",
      "41527 0.890625\n",
      "41528 1.0\n",
      "41534 1.0\n",
      "41541 1.0\n",
      "41542 1.0\n",
      "41544 1.0\n",
      "41551 1.0\n",
      "41555 1.0\n",
      "41559 1.0\n",
      "41562 1.0\n",
      "41564 1.0\n",
      "41567 1.0\n",
      "41574 1.0\n",
      "41575 1.0\n",
      "41580 1.0\n",
      "41582 1.0\n",
      "41585 1.0\n",
      "41587 0.9625\n",
      "41589 1.0\n",
      "41590 1.0\n",
      "41604 1.0\n",
      "41607 1.0\n",
      "41608 1.0\n",
      "41609 1.0\n",
      "41610 1.0\n",
      "41613 1.0\n",
      "41616 1.0\n",
      "41619 1.0\n",
      "41621 1.0\n",
      "41624 1.0\n",
      "41627 1.0\n",
      "41634 1.0\n",
      "41635 1.0\n",
      "41636 0.9505494505494505\n",
      "41638 1.0\n",
      "41643 1.0\n",
      "41645 0.9427083333333334\n",
      "41649 1.0\n",
      "41650 1.0\n",
      "41657 1.0\n",
      "41658 1.0\n",
      "41666 1.0\n",
      "41667 1.0\n",
      "41674 1.0\n",
      "41680 1.0\n",
      "41681 1.0\n",
      "41683 0.953125\n",
      "41684 1.0\n",
      "41686 1.0\n",
      "41688 1.0\n",
      "41690 1.0\n",
      "41691 1.0\n",
      "41696 0.9642857142857143\n",
      "41704 1.0\n",
      "41711 1.0\n",
      "41723 1.0\n",
      "41727 1.0\n",
      "41728 0.875\n",
      "41729 1.0\n",
      "41730 0.9296875\n",
      "41737 0.96875\n",
      "41739 1.0\n",
      "41740 1.0\n",
      "41752 1.0\n",
      "41753 1.0\n",
      "41765 1.0\n",
      "41767 1.0\n",
      "41770 1.0\n",
      "41773 1.0\n",
      "41774 1.0\n",
      "41775 1.0\n",
      "41779 1.0\n",
      "41780 1.0\n",
      "41784 1.0\n",
      "41785 1.0\n",
      "41792 1.0\n",
      "41800 1.0\n",
      "41801 1.0\n",
      "41803 1.0\n",
      "41804 1.0\n",
      "41807 1.0\n",
      "41811 0.828125\n",
      "41818 1.0\n",
      "41819 1.0\n",
      "41822 1.0\n",
      "41824 0.9598214285714286\n",
      "41825 1.0\n",
      "41831 1.0\n",
      "Overall Average Jaccard Similarity: 0.9997797687009623\n"
     ]
    }
   ],
   "source": [
    "sims = get_averege_jaccard_sim(replacement_candidates7, minhash_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S0', 'S2', 'S2_2', 'S2', 'S2_1', 'S2', 'S2_4', 'S2', 'S2_3', 'S2', 'S0', 'S6', 'S0', 'null']\n",
      "['S0', 'S2', 'S2_2', 'S2', 'S2_1', 'S2', 'S2_4', 'S2', 'S2_3', 'S2', 'S0', 'S4', 'S4_1', 'S4', 'S0', 'null']\n"
     ]
    }
   ],
   "source": [
    "keys_with_target_value = [key for key, value in sims.items() if value == min(sims.values())]\n",
    "get_servers(keys_with_target_value[0],data)\n",
    "get_servers(keys_with_target_value[1],data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import psutil\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Function to measure execution time and resource usage\n",
    "# def measure_performance(func, *args, **kwargs):\n",
    "#     start_time = time.time()\n",
    "#     process = psutil.Process()\n",
    "#     start_memory = process.memory_info().rss\n",
    "#     start_cpu = process.cpu_percent(interval=None)\n",
    "\n",
    "#     result = func(*args, **kwargs)\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     end_memory = process.memory_info().rss\n",
    "#     end_cpu = process.cpu_percent(interval=None)\n",
    "\n",
    "#     execution_time = end_time - start_time\n",
    "#     memory_usage = (end_memory - start_memory) / 1024 / 1024  # Convert to MB\n",
    "#     cpu_usage = end_cpu - start_cpu\n",
    "\n",
    "#     return execution_time, memory_usage, cpu_usage, result\n",
    "\n",
    "# # Example function to test performance\n",
    "# def example_function(n):\n",
    "#     total = 0\n",
    "#     for i in range(n):\n",
    "#         total += i ** 2\n",
    "#     return total\n",
    "\n",
    "# # Measure performance of the example function with a specific input\n",
    "# specific_input = 1000000\n",
    "# exec_time, mem_usage, cpu_usage, _ = measure_performance(example_function, specific_input)\n",
    "\n",
    "# # Plotting the results\n",
    "# labels = ['Execution Time (s)', 'Memory Usage (MB)', 'CPU Usage (%)']\n",
    "# values = [exec_time, mem_usage, cpu_usage]\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(labels, values, color=['red', 'blue', 'green'])\n",
    "\n",
    "# for i, v in enumerate(values):\n",
    "#     ax.text(i, v + 0.1, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "# plt.title(f'Computational Expense Analysis for input size {specific_input}')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import psutil\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Function to measure execution time and resource usage\n",
    "# def measure_performance(func, *args, **kwargs):\n",
    "#     start_time = time.time()\n",
    "#     process = psutil.Process()\n",
    "#     start_memory = process.memory_info().rss\n",
    "#     start_cpu = process.cpu_percent(interval=None)\n",
    "\n",
    "#     result = func(*args, **kwargs)\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     end_memory = process.memory_info().rss\n",
    "#     end_cpu = process.cpu_percent(interval=None)\n",
    "\n",
    "#     execution_time = end_time - start_time\n",
    "#     memory_usage = (end_memory - start_memory) / 1024 / 1024  # Convert to MB\n",
    "#     cpu_usage = end_cpu - start_cpu\n",
    "\n",
    "#     return execution_time, memory_usage, cpu_usage, result\n",
    "\n",
    "# # Example function to test performance\n",
    "# def example_function(n):\n",
    "#     total = 0\n",
    "#     for i in range(n):\n",
    "#         total += i ** 2\n",
    "#     return total\n",
    "\n",
    "# # Measure performance of the example function with different inputs\n",
    "# inputs = [10000, 100000, 500000, 1000000]\n",
    "# times = []\n",
    "# memories = []\n",
    "# cpus = []\n",
    "\n",
    "# for input_val in inputs:\n",
    "#     exec_time, mem_usage, cpu_usage, _ = measure_performance(example_function, input_val)\n",
    "#     times.append(exec_time)\n",
    "#     memories.append(mem_usage)\n",
    "#     cpus.append(cpu_usage)\n",
    "\n",
    "# # Plotting the results\n",
    "# fig, ax1 = plt.subplots()\n",
    "\n",
    "# color = 'tab:red'\n",
    "# ax1.set_xlabel('Input Size')\n",
    "# ax1.set_ylabel('Execution Time (s)', color=color)\n",
    "# ax1.plot(inputs, times, color=color, marker='o', label='Time')\n",
    "# ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "# color = 'tab:blue'\n",
    "# ax2.set_ylabel('Memory Usage (MB)', color=color)  # we already handled the x-label with ax1\n",
    "# ax2.plot(inputs, memories, color=color, marker='x', linestyle='--', label='Memory')\n",
    "# ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "# plt.title('Computational Expense Analysis')\n",
    "\n",
    "# # Optional: Add a secondary y-axis for CPU usage\n",
    "# ax3 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "# ax3.spines['right'].set_position(('outward', 60))  # offset the third axis\n",
    "# color = 'tab:green'\n",
    "# ax3.set_ylabel('CPU Usage (%)', color=color)\n",
    "# ax3.plot(inputs, cpus, color=color, marker='s', linestyle=':', label='CPU')\n",
    "# ax3.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "# plt.title('Computational Expense Analysis')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_part1(\"data/SDG_dataset2.csv\",3,0.95)\n",
    "# output_part1(\"data/SDG_dataset2.csv\",5,0.95)\n",
    "output_part1(\"data/SDG_dataset2.csv\",7,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning for Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[213], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans()\n\u001b[1;32m     21\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(kmeans, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminhashes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m best_param \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m     26\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:841\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    835\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    836\u001b[0m         all_candidate_params, n_splits, all_out,\n\u001b[1;32m    837\u001b[0m         all_more_results)\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 841\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    845\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1288\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1288\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:795\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    793\u001b[0m               n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits))\n\u001b[0;32m--> 795\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    813\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    814\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:1044\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1044\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:859\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 859\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:777\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    776\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 777\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py:222\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:591\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    593\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1023\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[0;32m-> 1023\u001b[0m labels, inertia, centers, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m inertia \u001b[38;5;241m<\u001b[39m best_inertia:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:385\u001b[0m, in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, sample_weight, centers_init, max_iter, verbose, x_squared_norms, tol, n_threads)\u001b[0m\n\u001b[1;32m    382\u001b[0m strict_convergence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[0;32m--> 385\u001b[0m     \u001b[43melkan_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m               \u001b[49m\u001b[43mweight_in_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_half_distances\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdistance_next_center\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m               \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_shift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# compute new pairwise distances between centers and closest other\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# center of each center for next iterations\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     center_half_distances \u001b[38;5;241m=\u001b[39m euclidean_distances(centers_new) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/23 02:41:15 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 7211405 ms exceeds timeout 120000 ms\n",
      "24/06/23 02:41:15 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "24/06/23 02:41:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/06/23 02:41:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/06/23 02:41:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 02:41:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 02:41:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 02:41:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 02:41:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 02:41:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 02:41:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 02:41:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 04:18:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 04:18:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 04:18:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 04:18:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 06:10:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 06:10:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 06:10:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 06:10:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 08:10:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 08:10:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 08:27:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 08:27:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 08:27:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 08:27:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:18:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:18:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:18:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:18:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:18:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:18:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:18:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:18:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:18:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:18:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:19:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:20:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:21:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:22:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:23:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:24:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:25:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:26:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:26:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.178.177:63973\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/06/23 09:26:09 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "minhashes = []\n",
    "user_ids = []\n",
    "final_buckets = {}\n",
    "for features in df_grouped.collect():\n",
    "    shingles = shingle(features[\"features\"], 5)\n",
    "    m = MinHash(num_perm=128)\n",
    "    for shingle_item in shingles:\n",
    "        m.update(shingle_item.encode(\"utf8\"))\n",
    "    minhashes.append(m.hashvalues)\n",
    "    user_ids.append(int(features[\"user_id\"]))\n",
    "\n",
    "param_grid = {\n",
    "    'n_clusters': [100, 250, 500],\n",
    "    'max_iter': [100, 500, 1000],\n",
    "}\n",
    "\n",
    "kmeans = KMeans()\n",
    "\n",
    "grid_search = GridSearchCV(kmeans, param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(minhashes)\n",
    "\n",
    "best_param = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"The best parameters are: \" , best_param )\n",
    "print(\"The best model is: \", best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Find and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41833\n",
      "11381\n"
     ]
    }
   ],
   "source": [
    "replacement_candidates = minhash_lsh(df_grouped,5,0.7)\n",
    "new_process_dictionary = bucketing(replacement_candidates)\n",
    "print(len(replacement_candidates))\n",
    "print(len(new_process_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Find/cluster similar items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "users = []\n",
    "for key in new_process_dictionary:\n",
    "    users.append(key)\n",
    "\n",
    "filtered_df = df_grouped[df_grouped['user_id'].isin(users)]\n",
    "\n",
    "final_buckets, minhashes = kmeans_clustering(filtered_df,500,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <datasketch.minhash.MinHash at 0x7fc769ff2d30>,\n",
       " 3: <datasketch.minhash.MinHash at 0x7fc71195b880>,\n",
       " 5: <datasketch.minhash.MinHash at 0x7fc71195ba90>,\n",
       " 9: <datasketch.minhash.MinHash at 0x7fc7117fe370>,\n",
       " 12: <datasketch.minhash.MinHash at 0x7fc7117fe3d0>,\n",
       " 15: <datasketch.minhash.MinHash at 0x7fc7112b3a60>,\n",
       " 16: <datasketch.minhash.MinHash at 0x7fc7112b3af0>,\n",
       " 17: <datasketch.minhash.MinHash at 0x7fc7112b3b50>,\n",
       " 20: <datasketch.minhash.MinHash at 0x7fc7112b3bb0>,\n",
       " 22: <datasketch.minhash.MinHash at 0x7fc7112b3c10>,\n",
       " 26: <datasketch.minhash.MinHash at 0x7fc7112b3c70>,\n",
       " 27: <datasketch.minhash.MinHash at 0x7fc7112b3cd0>,\n",
       " 28: <datasketch.minhash.MinHash at 0x7fc7112b3d30>,\n",
       " 31: <datasketch.minhash.MinHash at 0x7fc7112b3d90>,\n",
       " 34: <datasketch.minhash.MinHash at 0x7fc7112b3df0>,\n",
       " 37: <datasketch.minhash.MinHash at 0x7fc7112b3e50>,\n",
       " 38: <datasketch.minhash.MinHash at 0x7fc7112b3f10>,\n",
       " 44: <datasketch.minhash.MinHash at 0x7fc7112b3ee0>,\n",
       " 47: <datasketch.minhash.MinHash at 0x7fc7112b3f70>,\n",
       " 49: <datasketch.minhash.MinHash at 0x7fc7112b3fd0>,\n",
       " 50: <datasketch.minhash.MinHash at 0x7fc7112b3fa0>,\n",
       " 52: <datasketch.minhash.MinHash at 0x7fc718b170a0>,\n",
       " 53: <datasketch.minhash.MinHash at 0x7fc718b17100>,\n",
       " 60: <datasketch.minhash.MinHash at 0x7fc718b171f0>,\n",
       " 65: <datasketch.minhash.MinHash at 0x7fc718b171c0>,\n",
       " 76: <datasketch.minhash.MinHash at 0x7fc718b17250>,\n",
       " 78: <datasketch.minhash.MinHash at 0x7fc718b17310>,\n",
       " 80: <datasketch.minhash.MinHash at 0x7fc718b172e0>,\n",
       " 81: <datasketch.minhash.MinHash at 0x7fc718b17370>,\n",
       " 82: <datasketch.minhash.MinHash at 0x7fc718b173d0>,\n",
       " 84: <datasketch.minhash.MinHash at 0x7fc718b17430>,\n",
       " 85: <datasketch.minhash.MinHash at 0x7fc718b17490>,\n",
       " 86: <datasketch.minhash.MinHash at 0x7fc718b174f0>,\n",
       " 88: <datasketch.minhash.MinHash at 0x7fc718b17550>,\n",
       " 91: <datasketch.minhash.MinHash at 0x7fc718b175b0>,\n",
       " 92: <datasketch.minhash.MinHash at 0x7fc718b17670>,\n",
       " 93: <datasketch.minhash.MinHash at 0x7fc718b17640>,\n",
       " 96: <datasketch.minhash.MinHash at 0x7fc718b176d0>,\n",
       " 101: <datasketch.minhash.MinHash at 0x7fc718b17730>,\n",
       " 102: <datasketch.minhash.MinHash at 0x7fc718b17790>,\n",
       " 103: <datasketch.minhash.MinHash at 0x7fc718b177f0>,\n",
       " 108: <datasketch.minhash.MinHash at 0x7fc718b17850>,\n",
       " 111: <datasketch.minhash.MinHash at 0x7fc718b17910>,\n",
       " 115: <datasketch.minhash.MinHash at 0x7fc718b178e0>,\n",
       " 118: <datasketch.minhash.MinHash at 0x7fc718b17970>,\n",
       " 122: <datasketch.minhash.MinHash at 0x7fc718b179d0>,\n",
       " 126: <datasketch.minhash.MinHash at 0x7fc718b17a30>,\n",
       " 127: <datasketch.minhash.MinHash at 0x7fc718b17a90>,\n",
       " 128: <datasketch.minhash.MinHash at 0x7fc718b17af0>,\n",
       " 129: <datasketch.minhash.MinHash at 0x7fc718b17b50>,\n",
       " 132: <datasketch.minhash.MinHash at 0x7fc718b17bb0>,\n",
       " 133: <datasketch.minhash.MinHash at 0x7fc718b17c10>,\n",
       " 137: <datasketch.minhash.MinHash at 0x7fc718b17c70>,\n",
       " 139: <datasketch.minhash.MinHash at 0x7fc718b17cd0>,\n",
       " 140: <datasketch.minhash.MinHash at 0x7fc718b17d30>,\n",
       " 142: <datasketch.minhash.MinHash at 0x7fc718b17d90>,\n",
       " 144: <datasketch.minhash.MinHash at 0x7fc718b17df0>,\n",
       " 145: <datasketch.minhash.MinHash at 0x7fc718b17e50>,\n",
       " 146: <datasketch.minhash.MinHash at 0x7fc718b17eb0>,\n",
       " 148: <datasketch.minhash.MinHash at 0x7fc718b17f10>,\n",
       " 152: <datasketch.minhash.MinHash at 0x7fc718b17f70>,\n",
       " 155: <datasketch.minhash.MinHash at 0x7fc718b17fd0>,\n",
       " 157: <datasketch.minhash.MinHash at 0x7fc718b17fa0>,\n",
       " 159: <datasketch.minhash.MinHash at 0x7fc718b300a0>,\n",
       " 163: <datasketch.minhash.MinHash at 0x7fc718b30190>,\n",
       " 169: <datasketch.minhash.MinHash at 0x7fc718b30160>,\n",
       " 175: <datasketch.minhash.MinHash at 0x7fc718b301f0>,\n",
       " 177: <datasketch.minhash.MinHash at 0x7fc718b30250>,\n",
       " 182: <datasketch.minhash.MinHash at 0x7fc718b302b0>,\n",
       " 183: <datasketch.minhash.MinHash at 0x7fc718b30310>,\n",
       " 185: <datasketch.minhash.MinHash at 0x7fc718b30370>,\n",
       " 189: <datasketch.minhash.MinHash at 0x7fc718b303d0>,\n",
       " 190: <datasketch.minhash.MinHash at 0x7fc718b30430>,\n",
       " 192: <datasketch.minhash.MinHash at 0x7fc718b30490>,\n",
       " 193: <datasketch.minhash.MinHash at 0x7fc718b304f0>,\n",
       " 195: <datasketch.minhash.MinHash at 0x7fc718b30550>,\n",
       " 197: <datasketch.minhash.MinHash at 0x7fc718b305b0>,\n",
       " 205: <datasketch.minhash.MinHash at 0x7fc718b30610>,\n",
       " 206: <datasketch.minhash.MinHash at 0x7fc718b30670>,\n",
       " 209: <datasketch.minhash.MinHash at 0x7fc718b306d0>,\n",
       " 210: <datasketch.minhash.MinHash at 0x7fc718b30730>,\n",
       " 211: <datasketch.minhash.MinHash at 0x7fc718b30790>,\n",
       " 218: <datasketch.minhash.MinHash at 0x7fc718b307f0>,\n",
       " 222: <datasketch.minhash.MinHash at 0x7fc718b30850>,\n",
       " 223: <datasketch.minhash.MinHash at 0x7fc718b308b0>,\n",
       " 224: <datasketch.minhash.MinHash at 0x7fc718b30910>,\n",
       " 225: <datasketch.minhash.MinHash at 0x7fc718b30970>,\n",
       " 227: <datasketch.minhash.MinHash at 0x7fc718b309d0>,\n",
       " 230: <datasketch.minhash.MinHash at 0x7fc718b30a30>,\n",
       " 232: <datasketch.minhash.MinHash at 0x7fc718b30a90>,\n",
       " 233: <datasketch.minhash.MinHash at 0x7fc718b30b50>,\n",
       " 236: <datasketch.minhash.MinHash at 0x7fc718b30b20>,\n",
       " 239: <datasketch.minhash.MinHash at 0x7fc718b30c10>,\n",
       " 242: <datasketch.minhash.MinHash at 0x7fc718b30be0>,\n",
       " 243: <datasketch.minhash.MinHash at 0x7fc718b30c70>,\n",
       " 246: <datasketch.minhash.MinHash at 0x7fc718b30cd0>,\n",
       " 248: <datasketch.minhash.MinHash at 0x7fc718b30d30>,\n",
       " 249: <datasketch.minhash.MinHash at 0x7fc718b30d90>,\n",
       " 251: <datasketch.minhash.MinHash at 0x7fc718b30df0>,\n",
       " 252: <datasketch.minhash.MinHash at 0x7fc718b30e50>,\n",
       " 253: <datasketch.minhash.MinHash at 0x7fc718b30eb0>,\n",
       " 255: <datasketch.minhash.MinHash at 0x7fc718b30f10>,\n",
       " 258: <datasketch.minhash.MinHash at 0x7fc718b30f70>,\n",
       " 259: <datasketch.minhash.MinHash at 0x7fc718b30fd0>,\n",
       " 262: <datasketch.minhash.MinHash at 0x7fc718b30fa0>,\n",
       " 264: <datasketch.minhash.MinHash at 0x7fc718b2c0a0>,\n",
       " 266: <datasketch.minhash.MinHash at 0x7fc718b2c100>,\n",
       " 268: <datasketch.minhash.MinHash at 0x7fc718b2c190>,\n",
       " 271: <datasketch.minhash.MinHash at 0x7fc718b2c1f0>,\n",
       " 273: <datasketch.minhash.MinHash at 0x7fc718b2c250>,\n",
       " 274: <datasketch.minhash.MinHash at 0x7fc718b2c2b0>,\n",
       " 279: <datasketch.minhash.MinHash at 0x7fc718b2c310>,\n",
       " 280: <datasketch.minhash.MinHash at 0x7fc718b2c370>,\n",
       " 285: <datasketch.minhash.MinHash at 0x7fc718b2c3d0>,\n",
       " 292: <datasketch.minhash.MinHash at 0x7fc718b2c430>,\n",
       " 294: <datasketch.minhash.MinHash at 0x7fc718b2c490>,\n",
       " 295: <datasketch.minhash.MinHash at 0x7fc718b2c4f0>,\n",
       " 296: <datasketch.minhash.MinHash at 0x7fc718b2c550>,\n",
       " 297: <datasketch.minhash.MinHash at 0x7fc718b2c5b0>,\n",
       " 300: <datasketch.minhash.MinHash at 0x7fc718b2c670>,\n",
       " 305: <datasketch.minhash.MinHash at 0x7fc718b2c640>,\n",
       " 308: <datasketch.minhash.MinHash at 0x7fc718b2c6d0>,\n",
       " 309: <datasketch.minhash.MinHash at 0x7fc718b2c730>,\n",
       " 316: <datasketch.minhash.MinHash at 0x7fc718b2c790>,\n",
       " 318: <datasketch.minhash.MinHash at 0x7fc718b2c7f0>,\n",
       " 319: <datasketch.minhash.MinHash at 0x7fc718b2c850>,\n",
       " 321: <datasketch.minhash.MinHash at 0x7fc718b2c8b0>,\n",
       " 322: <datasketch.minhash.MinHash at 0x7fc718b2c910>,\n",
       " 325: <datasketch.minhash.MinHash at 0x7fc718b2c970>,\n",
       " 326: <datasketch.minhash.MinHash at 0x7fc718b2c9d0>,\n",
       " 327: <datasketch.minhash.MinHash at 0x7fc718b2ca90>,\n",
       " 329: <datasketch.minhash.MinHash at 0x7fc718b2ca60>,\n",
       " 330: <datasketch.minhash.MinHash at 0x7fc718b2caf0>,\n",
       " 332: <datasketch.minhash.MinHash at 0x7fc718b2cb50>,\n",
       " 333: <datasketch.minhash.MinHash at 0x7fc718b2cbb0>,\n",
       " 336: <datasketch.minhash.MinHash at 0x7fc718b2cc10>,\n",
       " 339: <datasketch.minhash.MinHash at 0x7fc718b2cc70>,\n",
       " 348: <datasketch.minhash.MinHash at 0x7fc718b2ccd0>,\n",
       " 349: <datasketch.minhash.MinHash at 0x7fc718b2cd90>,\n",
       " 350: <datasketch.minhash.MinHash at 0x7fc718b2cdf0>,\n",
       " 353: <datasketch.minhash.MinHash at 0x7fc718b2cdc0>,\n",
       " 355: <datasketch.minhash.MinHash at 0x7fc718b2ce50>,\n",
       " 356: <datasketch.minhash.MinHash at 0x7fc718b2cf10>,\n",
       " 358: <datasketch.minhash.MinHash at 0x7fc718b2cee0>,\n",
       " 360: <datasketch.minhash.MinHash at 0x7fc718b2cf70>,\n",
       " 362: <datasketch.minhash.MinHash at 0x7fc718b2cfd0>,\n",
       " 363: <datasketch.minhash.MinHash at 0x7fc718b2cfa0>,\n",
       " 367: <datasketch.minhash.MinHash at 0x7fc718b160a0>,\n",
       " 368: <datasketch.minhash.MinHash at 0x7fc718b16100>,\n",
       " 372: <datasketch.minhash.MinHash at 0x7fc718b16190>,\n",
       " 374: <datasketch.minhash.MinHash at 0x7fc718b161f0>,\n",
       " 375: <datasketch.minhash.MinHash at 0x7fc718b16250>,\n",
       " 380: <datasketch.minhash.MinHash at 0x7fc718b162b0>,\n",
       " 383: <datasketch.minhash.MinHash at 0x7fc718b16310>,\n",
       " 384: <datasketch.minhash.MinHash at 0x7fc718b16370>,\n",
       " 385: <datasketch.minhash.MinHash at 0x7fc718b163d0>,\n",
       " 386: <datasketch.minhash.MinHash at 0x7fc718b16430>,\n",
       " 388: <datasketch.minhash.MinHash at 0x7fc718b16490>,\n",
       " 389: <datasketch.minhash.MinHash at 0x7fc718b16550>,\n",
       " 392: <datasketch.minhash.MinHash at 0x7fc718b16520>,\n",
       " 394: <datasketch.minhash.MinHash at 0x7fc718b165b0>,\n",
       " 397: <datasketch.minhash.MinHash at 0x7fc718b16610>,\n",
       " 402: <datasketch.minhash.MinHash at 0x7fc718b16670>,\n",
       " 404: <datasketch.minhash.MinHash at 0x7fc718b16730>,\n",
       " 406: <datasketch.minhash.MinHash at 0x7fc718b16700>,\n",
       " 409: <datasketch.minhash.MinHash at 0x7fc718b16790>,\n",
       " 412: <datasketch.minhash.MinHash at 0x7fc718b167f0>,\n",
       " 415: <datasketch.minhash.MinHash at 0x7fc718b16850>,\n",
       " 416: <datasketch.minhash.MinHash at 0x7fc718b168b0>,\n",
       " 417: <datasketch.minhash.MinHash at 0x7fc718b16910>,\n",
       " 419: <datasketch.minhash.MinHash at 0x7fc718b16970>,\n",
       " 425: <datasketch.minhash.MinHash at 0x7fc718b169d0>,\n",
       " 430: <datasketch.minhash.MinHash at 0x7fc718b16a30>,\n",
       " 431: <datasketch.minhash.MinHash at 0x7fc718b16a90>,\n",
       " 432: <datasketch.minhash.MinHash at 0x7fc718b16af0>,\n",
       " 435: <datasketch.minhash.MinHash at 0x7fc718b16b50>,\n",
       " 436: <datasketch.minhash.MinHash at 0x7fc718b16bb0>,\n",
       " 440: <datasketch.minhash.MinHash at 0x7fc718b16c10>,\n",
       " 442: <datasketch.minhash.MinHash at 0x7fc718b16c70>,\n",
       " 444: <datasketch.minhash.MinHash at 0x7fc718b16cd0>,\n",
       " 448: <datasketch.minhash.MinHash at 0x7fc718b16d30>,\n",
       " 451: <datasketch.minhash.MinHash at 0x7fc718b16d90>,\n",
       " 458: <datasketch.minhash.MinHash at 0x7fc718b16df0>,\n",
       " 459: <datasketch.minhash.MinHash at 0x7fc718b16e50>,\n",
       " 460: <datasketch.minhash.MinHash at 0x7fc718b16eb0>,\n",
       " 461: <datasketch.minhash.MinHash at 0x7fc718b16f10>,\n",
       " 462: <datasketch.minhash.MinHash at 0x7fc718b16f70>,\n",
       " 463: <datasketch.minhash.MinHash at 0x7fc718b16fd0>,\n",
       " 465: <datasketch.minhash.MinHash at 0x7fc718b16fa0>,\n",
       " 470: <datasketch.minhash.MinHash at 0x7fc718b2a0a0>,\n",
       " 471: <datasketch.minhash.MinHash at 0x7fc718b2a130>,\n",
       " 472: <datasketch.minhash.MinHash at 0x7fc718b2a190>,\n",
       " 473: <datasketch.minhash.MinHash at 0x7fc718b2a1f0>,\n",
       " 476: <datasketch.minhash.MinHash at 0x7fc718b2a250>,\n",
       " 479: <datasketch.minhash.MinHash at 0x7fc718b2a2b0>,\n",
       " 481: <datasketch.minhash.MinHash at 0x7fc718b2a310>,\n",
       " 485: <datasketch.minhash.MinHash at 0x7fc718b2a370>,\n",
       " 486: <datasketch.minhash.MinHash at 0x7fc718b2a3d0>,\n",
       " 489: <datasketch.minhash.MinHash at 0x7fc718b2a430>,\n",
       " 493: <datasketch.minhash.MinHash at 0x7fc718b2a490>,\n",
       " 496: <datasketch.minhash.MinHash at 0x7fc718b2a4f0>,\n",
       " 498: <datasketch.minhash.MinHash at 0x7fc718b2a550>,\n",
       " 500: <datasketch.minhash.MinHash at 0x7fc718b2a5b0>,\n",
       " 501: <datasketch.minhash.MinHash at 0x7fc718b2a610>,\n",
       " 502: <datasketch.minhash.MinHash at 0x7fc718b2a670>,\n",
       " 509: <datasketch.minhash.MinHash at 0x7fc718b2a6d0>,\n",
       " 510: <datasketch.minhash.MinHash at 0x7fc718b2a730>,\n",
       " 511: <datasketch.minhash.MinHash at 0x7fc718b2a790>,\n",
       " 512: <datasketch.minhash.MinHash at 0x7fc718b2a7f0>,\n",
       " 513: <datasketch.minhash.MinHash at 0x7fc718b2a850>,\n",
       " 516: <datasketch.minhash.MinHash at 0x7fc718b2a910>,\n",
       " 519: <datasketch.minhash.MinHash at 0x7fc718b2a8e0>,\n",
       " 524: <datasketch.minhash.MinHash at 0x7fc718b2a970>,\n",
       " 530: <datasketch.minhash.MinHash at 0x7fc718b2a9d0>,\n",
       " 539: <datasketch.minhash.MinHash at 0x7fc718b2aa30>,\n",
       " 542: <datasketch.minhash.MinHash at 0x7fc718b2aa90>,\n",
       " 545: <datasketch.minhash.MinHash at 0x7fc718b2aaf0>,\n",
       " 548: <datasketch.minhash.MinHash at 0x7fc718b2ab50>,\n",
       " 551: <datasketch.minhash.MinHash at 0x7fc718b2abb0>,\n",
       " 555: <datasketch.minhash.MinHash at 0x7fc718b2ac10>,\n",
       " 556: <datasketch.minhash.MinHash at 0x7fc718b2ac70>,\n",
       " 558: <datasketch.minhash.MinHash at 0x7fc718b2acd0>,\n",
       " 563: <datasketch.minhash.MinHash at 0x7fc718b2ad30>,\n",
       " 577: <datasketch.minhash.MinHash at 0x7fc718b2ad90>,\n",
       " 578: <datasketch.minhash.MinHash at 0x7fc718b2adf0>,\n",
       " 580: <datasketch.minhash.MinHash at 0x7fc718b2ae50>,\n",
       " 581: <datasketch.minhash.MinHash at 0x7fc718b2aeb0>,\n",
       " 582: <datasketch.minhash.MinHash at 0x7fc718b2af10>,\n",
       " 584: <datasketch.minhash.MinHash at 0x7fc718b2af70>,\n",
       " 585: <datasketch.minhash.MinHash at 0x7fc718b2afd0>,\n",
       " 587: <datasketch.minhash.MinHash at 0x7fc718b2afa0>,\n",
       " 588: <datasketch.minhash.MinHash at 0x7fc718b180a0>,\n",
       " 590: <datasketch.minhash.MinHash at 0x7fc718b18130>,\n",
       " 591: <datasketch.minhash.MinHash at 0x7fc718b18190>,\n",
       " 592: <datasketch.minhash.MinHash at 0x7fc718b181f0>,\n",
       " 593: <datasketch.minhash.MinHash at 0x7fc718b18250>,\n",
       " 596: <datasketch.minhash.MinHash at 0x7fc718b182b0>,\n",
       " 597: <datasketch.minhash.MinHash at 0x7fc718b18310>,\n",
       " 599: <datasketch.minhash.MinHash at 0x7fc718b18370>,\n",
       " 601: <datasketch.minhash.MinHash at 0x7fc718b183d0>,\n",
       " 602: <datasketch.minhash.MinHash at 0x7fc718b18430>,\n",
       " 603: <datasketch.minhash.MinHash at 0x7fc718b18490>,\n",
       " 604: <datasketch.minhash.MinHash at 0x7fc718b184f0>,\n",
       " 606: <datasketch.minhash.MinHash at 0x7fc718b18550>,\n",
       " 607: <datasketch.minhash.MinHash at 0x7fc718b185b0>,\n",
       " 613: <datasketch.minhash.MinHash at 0x7fc718b18610>,\n",
       " 615: <datasketch.minhash.MinHash at 0x7fc718b18670>,\n",
       " 618: <datasketch.minhash.MinHash at 0x7fc718b186d0>,\n",
       " 623: <datasketch.minhash.MinHash at 0x7fc718b18730>,\n",
       " 626: <datasketch.minhash.MinHash at 0x7fc718b187f0>,\n",
       " 627: <datasketch.minhash.MinHash at 0x7fc718b187c0>,\n",
       " 631: <datasketch.minhash.MinHash at 0x7fc718b18850>,\n",
       " 633: <datasketch.minhash.MinHash at 0x7fc718b188b0>,\n",
       " 636: <datasketch.minhash.MinHash at 0x7fc718b18910>,\n",
       " 642: <datasketch.minhash.MinHash at 0x7fc718b18970>,\n",
       " 644: <datasketch.minhash.MinHash at 0x7fc718b189d0>,\n",
       " 646: <datasketch.minhash.MinHash at 0x7fc718b18a30>,\n",
       " 648: <datasketch.minhash.MinHash at 0x7fc718b18a90>,\n",
       " 650: <datasketch.minhash.MinHash at 0x7fc718b18af0>,\n",
       " 653: <datasketch.minhash.MinHash at 0x7fc718b18b50>,\n",
       " 654: <datasketch.minhash.MinHash at 0x7fc718b18bb0>,\n",
       " 660: <datasketch.minhash.MinHash at 0x7fc718b18c70>,\n",
       " 663: <datasketch.minhash.MinHash at 0x7fc718b18c40>,\n",
       " 665: <datasketch.minhash.MinHash at 0x7fc718b18cd0>,\n",
       " 666: <datasketch.minhash.MinHash at 0x7fc718b18d30>,\n",
       " 667: <datasketch.minhash.MinHash at 0x7fc718b18d90>,\n",
       " 671: <datasketch.minhash.MinHash at 0x7fc718b18df0>,\n",
       " 673: <datasketch.minhash.MinHash at 0x7fc718b18e50>,\n",
       " 674: <datasketch.minhash.MinHash at 0x7fc718b18eb0>,\n",
       " 679: <datasketch.minhash.MinHash at 0x7fc718b18f10>,\n",
       " 683: <datasketch.minhash.MinHash at 0x7fc718b18f70>,\n",
       " 685: <datasketch.minhash.MinHash at 0x7fc718b18fd0>,\n",
       " 686: <datasketch.minhash.MinHash at 0x7fc718b18fa0>,\n",
       " 688: <datasketch.minhash.MinHash at 0x7fc7192780a0>,\n",
       " 693: <datasketch.minhash.MinHash at 0x7fc719278100>,\n",
       " 694: <datasketch.minhash.MinHash at 0x7fc719278190>,\n",
       " 695: <datasketch.minhash.MinHash at 0x7fc7192781f0>,\n",
       " 696: <datasketch.minhash.MinHash at 0x7fc719278250>,\n",
       " 700: <datasketch.minhash.MinHash at 0x7fc7192782b0>,\n",
       " 704: <datasketch.minhash.MinHash at 0x7fc719278310>,\n",
       " 706: <datasketch.minhash.MinHash at 0x7fc7192783d0>,\n",
       " 707: <datasketch.minhash.MinHash at 0x7fc7192783a0>,\n",
       " 709: <datasketch.minhash.MinHash at 0x7fc719278430>,\n",
       " 711: <datasketch.minhash.MinHash at 0x7fc719278490>,\n",
       " 720: <datasketch.minhash.MinHash at 0x7fc7192784f0>,\n",
       " 721: <datasketch.minhash.MinHash at 0x7fc719278550>,\n",
       " 723: <datasketch.minhash.MinHash at 0x7fc7192785b0>,\n",
       " 725: <datasketch.minhash.MinHash at 0x7fc719278610>,\n",
       " 727: <datasketch.minhash.MinHash at 0x7fc719278670>,\n",
       " 729: <datasketch.minhash.MinHash at 0x7fc7192786d0>,\n",
       " 731: <datasketch.minhash.MinHash at 0x7fc719278730>,\n",
       " 732: <datasketch.minhash.MinHash at 0x7fc719278790>,\n",
       " 736: <datasketch.minhash.MinHash at 0x7fc7192787f0>,\n",
       " 737: <datasketch.minhash.MinHash at 0x7fc7192788b0>,\n",
       " 738: <datasketch.minhash.MinHash at 0x7fc719278880>,\n",
       " 743: <datasketch.minhash.MinHash at 0x7fc719278910>,\n",
       " 744: <datasketch.minhash.MinHash at 0x7fc719278970>,\n",
       " 747: <datasketch.minhash.MinHash at 0x7fc719278a60>,\n",
       " 753: <datasketch.minhash.MinHash at 0x7fc719278a30>,\n",
       " 756: <datasketch.minhash.MinHash at 0x7fc719278ac0>,\n",
       " 758: <datasketch.minhash.MinHash at 0x7fc719278b20>,\n",
       " 759: <datasketch.minhash.MinHash at 0x7fc719278b80>,\n",
       " 760: <datasketch.minhash.MinHash at 0x7fc719278be0>,\n",
       " 762: <datasketch.minhash.MinHash at 0x7fc719278c40>,\n",
       " 764: <datasketch.minhash.MinHash at 0x7fc719278d00>,\n",
       " 768: <datasketch.minhash.MinHash at 0x7fc719278cd0>,\n",
       " 770: <datasketch.minhash.MinHash at 0x7fc719278d60>,\n",
       " 772: <datasketch.minhash.MinHash at 0x7fc719278dc0>,\n",
       " 774: <datasketch.minhash.MinHash at 0x7fc719278e20>,\n",
       " 777: <datasketch.minhash.MinHash at 0x7fc719278e80>,\n",
       " 784: <datasketch.minhash.MinHash at 0x7fc719278ee0>,\n",
       " 787: <datasketch.minhash.MinHash at 0x7fc719278f40>,\n",
       " 796: <datasketch.minhash.MinHash at 0x7fc719278fd0>,\n",
       " 797: <datasketch.minhash.MinHash at 0x7fc719278a00>,\n",
       " 799: <datasketch.minhash.MinHash at 0x7fc719284040>,\n",
       " 800: <datasketch.minhash.MinHash at 0x7fc7192840d0>,\n",
       " 802: <datasketch.minhash.MinHash at 0x7fc719284130>,\n",
       " 804: <datasketch.minhash.MinHash at 0x7fc7192841c0>,\n",
       " 806: <datasketch.minhash.MinHash at 0x7fc719284220>,\n",
       " 808: <datasketch.minhash.MinHash at 0x7fc719284280>,\n",
       " 811: <datasketch.minhash.MinHash at 0x7fc7192842e0>,\n",
       " 819: <datasketch.minhash.MinHash at 0x7fc719284340>,\n",
       " 822: <datasketch.minhash.MinHash at 0x7fc7192843a0>,\n",
       " 827: <datasketch.minhash.MinHash at 0x7fc719284400>,\n",
       " 830: <datasketch.minhash.MinHash at 0x7fc7192844c0>,\n",
       " 831: <datasketch.minhash.MinHash at 0x7fc719284490>,\n",
       " 833: <datasketch.minhash.MinHash at 0x7fc719284520>,\n",
       " 834: <datasketch.minhash.MinHash at 0x7fc719284580>,\n",
       " 839: <datasketch.minhash.MinHash at 0x7fc7192845e0>,\n",
       " 842: <datasketch.minhash.MinHash at 0x7fc719284640>,\n",
       " 843: <datasketch.minhash.MinHash at 0x7fc7192846a0>,\n",
       " 844: <datasketch.minhash.MinHash at 0x7fc719284700>,\n",
       " 845: <datasketch.minhash.MinHash at 0x7fc719284760>,\n",
       " 846: <datasketch.minhash.MinHash at 0x7fc7192847c0>,\n",
       " 847: <datasketch.minhash.MinHash at 0x7fc719284820>,\n",
       " 853: <datasketch.minhash.MinHash at 0x7fc719284880>,\n",
       " 854: <datasketch.minhash.MinHash at 0x7fc719284940>,\n",
       " 855: <datasketch.minhash.MinHash at 0x7fc719284910>,\n",
       " 857: <datasketch.minhash.MinHash at 0x7fc7192849a0>,\n",
       " 858: <datasketch.minhash.MinHash at 0x7fc719284a60>,\n",
       " 860: <datasketch.minhash.MinHash at 0x7fc719284a30>,\n",
       " 861: <datasketch.minhash.MinHash at 0x7fc719284b20>,\n",
       " 862: <datasketch.minhash.MinHash at 0x7fc719284af0>,\n",
       " 863: <datasketch.minhash.MinHash at 0x7fc719284b80>,\n",
       " 871: <datasketch.minhash.MinHash at 0x7fc719284be0>,\n",
       " 874: <datasketch.minhash.MinHash at 0x7fc719284c40>,\n",
       " 875: <datasketch.minhash.MinHash at 0x7fc719284ca0>,\n",
       " 876: <datasketch.minhash.MinHash at 0x7fc719284d00>,\n",
       " 877: <datasketch.minhash.MinHash at 0x7fc719284d60>,\n",
       " 879: <datasketch.minhash.MinHash at 0x7fc719284dc0>,\n",
       " 881: <datasketch.minhash.MinHash at 0x7fc719284e20>,\n",
       " 882: <datasketch.minhash.MinHash at 0x7fc719284e80>,\n",
       " 884: <datasketch.minhash.MinHash at 0x7fc719284ee0>,\n",
       " 887: <datasketch.minhash.MinHash at 0x7fc719284f40>,\n",
       " 891: <datasketch.minhash.MinHash at 0x7fc719284fd0>,\n",
       " 892: <datasketch.minhash.MinHash at 0x7fc719284fa0>,\n",
       " 896: <datasketch.minhash.MinHash at 0x7fc719293070>,\n",
       " 897: <datasketch.minhash.MinHash at 0x7fc719293100>,\n",
       " 898: <datasketch.minhash.MinHash at 0x7fc719293160>,\n",
       " 904: <datasketch.minhash.MinHash at 0x7fc7192931c0>,\n",
       " 906: <datasketch.minhash.MinHash at 0x7fc719293220>,\n",
       " 908: <datasketch.minhash.MinHash at 0x7fc7192932e0>,\n",
       " 912: <datasketch.minhash.MinHash at 0x7fc7192932b0>,\n",
       " 914: <datasketch.minhash.MinHash at 0x7fc719293340>,\n",
       " 916: <datasketch.minhash.MinHash at 0x7fc7192933a0>,\n",
       " 918: <datasketch.minhash.MinHash at 0x7fc719293400>,\n",
       " 922: <datasketch.minhash.MinHash at 0x7fc719293460>,\n",
       " 924: <datasketch.minhash.MinHash at 0x7fc7192934c0>,\n",
       " 926: <datasketch.minhash.MinHash at 0x7fc719293520>,\n",
       " 935: <datasketch.minhash.MinHash at 0x7fc7192935e0>,\n",
       " 936: <datasketch.minhash.MinHash at 0x7fc7192935b0>,\n",
       " 939: <datasketch.minhash.MinHash at 0x7fc719293640>,\n",
       " 950: <datasketch.minhash.MinHash at 0x7fc7192936a0>,\n",
       " 951: <datasketch.minhash.MinHash at 0x7fc719293700>,\n",
       " 953: <datasketch.minhash.MinHash at 0x7fc719293760>,\n",
       " 955: <datasketch.minhash.MinHash at 0x7fc7192937c0>,\n",
       " 958: <datasketch.minhash.MinHash at 0x7fc719293820>,\n",
       " 959: <datasketch.minhash.MinHash at 0x7fc719293880>,\n",
       " 961: <datasketch.minhash.MinHash at 0x7fc7192938e0>,\n",
       " 969: <datasketch.minhash.MinHash at 0x7fc719293940>,\n",
       " 970: <datasketch.minhash.MinHash at 0x7fc7192939a0>,\n",
       " 973: <datasketch.minhash.MinHash at 0x7fc719293a00>,\n",
       " 974: <datasketch.minhash.MinHash at 0x7fc719293a60>,\n",
       " 976: <datasketch.minhash.MinHash at 0x7fc719293ac0>,\n",
       " 980: <datasketch.minhash.MinHash at 0x7fc719293b20>,\n",
       " 988: <datasketch.minhash.MinHash at 0x7fc719293b80>,\n",
       " 992: <datasketch.minhash.MinHash at 0x7fc719293be0>,\n",
       " 995: <datasketch.minhash.MinHash at 0x7fc719293c40>,\n",
       " 998: <datasketch.minhash.MinHash at 0x7fc719293ca0>,\n",
       " 1002: <datasketch.minhash.MinHash at 0x7fc719293d00>,\n",
       " 1003: <datasketch.minhash.MinHash at 0x7fc719293d60>,\n",
       " 1005: <datasketch.minhash.MinHash at 0x7fc719293dc0>,\n",
       " 1008: <datasketch.minhash.MinHash at 0x7fc719293e20>,\n",
       " 1010: <datasketch.minhash.MinHash at 0x7fc719293e80>,\n",
       " 1012: <datasketch.minhash.MinHash at 0x7fc719293ee0>,\n",
       " 1016: <datasketch.minhash.MinHash at 0x7fc719293f40>,\n",
       " 1019: <datasketch.minhash.MinHash at 0x7fc719293fd0>,\n",
       " 1021: <datasketch.minhash.MinHash at 0x7fc719293fa0>,\n",
       " 1025: <datasketch.minhash.MinHash at 0x7fc71926a070>,\n",
       " 1027: <datasketch.minhash.MinHash at 0x7fc71926a100>,\n",
       " 1028: <datasketch.minhash.MinHash at 0x7fc71926a160>,\n",
       " 1030: <datasketch.minhash.MinHash at 0x7fc71926a1c0>,\n",
       " 1031: <datasketch.minhash.MinHash at 0x7fc71926a220>,\n",
       " 1034: <datasketch.minhash.MinHash at 0x7fc71926a280>,\n",
       " 1036: <datasketch.minhash.MinHash at 0x7fc71926a2e0>,\n",
       " 1037: <datasketch.minhash.MinHash at 0x7fc71926a340>,\n",
       " 1039: <datasketch.minhash.MinHash at 0x7fc71926a3a0>,\n",
       " 1043: <datasketch.minhash.MinHash at 0x7fc71926a400>,\n",
       " 1044: <datasketch.minhash.MinHash at 0x7fc71926a460>,\n",
       " 1046: <datasketch.minhash.MinHash at 0x7fc71926a4c0>,\n",
       " 1048: <datasketch.minhash.MinHash at 0x7fc71926a520>,\n",
       " 1050: <datasketch.minhash.MinHash at 0x7fc71926a580>,\n",
       " 1051: <datasketch.minhash.MinHash at 0x7fc71926a5e0>,\n",
       " 1052: <datasketch.minhash.MinHash at 0x7fc71926a640>,\n",
       " 1055: <datasketch.minhash.MinHash at 0x7fc71926a6a0>,\n",
       " 1056: <datasketch.minhash.MinHash at 0x7fc71926a700>,\n",
       " 1060: <datasketch.minhash.MinHash at 0x7fc71926a760>,\n",
       " 1061: <datasketch.minhash.MinHash at 0x7fc71926a7c0>,\n",
       " 1064: <datasketch.minhash.MinHash at 0x7fc71926a820>,\n",
       " 1065: <datasketch.minhash.MinHash at 0x7fc71926a880>,\n",
       " 1068: <datasketch.minhash.MinHash at 0x7fc71926a8e0>,\n",
       " 1069: <datasketch.minhash.MinHash at 0x7fc71926a940>,\n",
       " 1072: <datasketch.minhash.MinHash at 0x7fc71926a9a0>,\n",
       " 1074: <datasketch.minhash.MinHash at 0x7fc71926aa00>,\n",
       " 1077: <datasketch.minhash.MinHash at 0x7fc71926aa60>,\n",
       " 1083: <datasketch.minhash.MinHash at 0x7fc71926aac0>,\n",
       " 1084: <datasketch.minhash.MinHash at 0x7fc71926ab20>,\n",
       " 1085: <datasketch.minhash.MinHash at 0x7fc71926ab80>,\n",
       " 1088: <datasketch.minhash.MinHash at 0x7fc71926abe0>,\n",
       " 1093: <datasketch.minhash.MinHash at 0x7fc71926ac40>,\n",
       " 1100: <datasketch.minhash.MinHash at 0x7fc71926aca0>,\n",
       " 1101: <datasketch.minhash.MinHash at 0x7fc71926ad00>,\n",
       " 1108: <datasketch.minhash.MinHash at 0x7fc71926ad60>,\n",
       " 1114: <datasketch.minhash.MinHash at 0x7fc71926adc0>,\n",
       " 1121: <datasketch.minhash.MinHash at 0x7fc71926ae20>,\n",
       " 1125: <datasketch.minhash.MinHash at 0x7fc71926ae80>,\n",
       " 1127: <datasketch.minhash.MinHash at 0x7fc71926aee0>,\n",
       " 1128: <datasketch.minhash.MinHash at 0x7fc71926af40>,\n",
       " 1133: <datasketch.minhash.MinHash at 0x7fc71926afd0>,\n",
       " 1135: <datasketch.minhash.MinHash at 0x7fc71926afa0>,\n",
       " 1139: <datasketch.minhash.MinHash at 0x7fc71926d070>,\n",
       " 1143: <datasketch.minhash.MinHash at 0x7fc71926d100>,\n",
       " 1144: <datasketch.minhash.MinHash at 0x7fc71926d160>,\n",
       " 1145: <datasketch.minhash.MinHash at 0x7fc71926d1c0>,\n",
       " 1148: <datasketch.minhash.MinHash at 0x7fc71926d220>,\n",
       " 1156: <datasketch.minhash.MinHash at 0x7fc71926d280>,\n",
       " 1157: <datasketch.minhash.MinHash at 0x7fc71926d2e0>,\n",
       " 1159: <datasketch.minhash.MinHash at 0x7fc71926d340>,\n",
       " 1160: <datasketch.minhash.MinHash at 0x7fc71926d3a0>,\n",
       " 1163: <datasketch.minhash.MinHash at 0x7fc71926d400>,\n",
       " 1164: <datasketch.minhash.MinHash at 0x7fc71926d460>,\n",
       " 1165: <datasketch.minhash.MinHash at 0x7fc71926d4c0>,\n",
       " 1167: <datasketch.minhash.MinHash at 0x7fc71926d520>,\n",
       " 1170: <datasketch.minhash.MinHash at 0x7fc71926d580>,\n",
       " 1171: <datasketch.minhash.MinHash at 0x7fc71926d5e0>,\n",
       " 1172: <datasketch.minhash.MinHash at 0x7fc71926d640>,\n",
       " 1174: <datasketch.minhash.MinHash at 0x7fc71926d6a0>,\n",
       " 1175: <datasketch.minhash.MinHash at 0x7fc71926d700>,\n",
       " 1176: <datasketch.minhash.MinHash at 0x7fc71926d760>,\n",
       " 1177: <datasketch.minhash.MinHash at 0x7fc71926d7c0>,\n",
       " 1183: <datasketch.minhash.MinHash at 0x7fc71926d820>,\n",
       " 1189: <datasketch.minhash.MinHash at 0x7fc71926d880>,\n",
       " 1190: <datasketch.minhash.MinHash at 0x7fc71926d8e0>,\n",
       " 1197: <datasketch.minhash.MinHash at 0x7fc71926d940>,\n",
       " 1198: <datasketch.minhash.MinHash at 0x7fc71926d9a0>,\n",
       " 1199: <datasketch.minhash.MinHash at 0x7fc719278fa0>,\n",
       " 1200: <datasketch.minhash.MinHash at 0x7fc71926d9d0>,\n",
       " 1201: <datasketch.minhash.MinHash at 0x7fc71926da00>,\n",
       " 1206: <datasketch.minhash.MinHash at 0x7fc71926daf0>,\n",
       " 1207: <datasketch.minhash.MinHash at 0x7fc71926db50>,\n",
       " 1208: <datasketch.minhash.MinHash at 0x7fc71926dbb0>,\n",
       " 1210: <datasketch.minhash.MinHash at 0x7fc71926dc10>,\n",
       " 1211: <datasketch.minhash.MinHash at 0x7fc71926dc70>,\n",
       " 1213: <datasketch.minhash.MinHash at 0x7fc71926dcd0>,\n",
       " 1214: <datasketch.minhash.MinHash at 0x7fc71926dd30>,\n",
       " 1215: <datasketch.minhash.MinHash at 0x7fc71926dd90>,\n",
       " 1216: <datasketch.minhash.MinHash at 0x7fc71926ddf0>,\n",
       " 1222: <datasketch.minhash.MinHash at 0x7fc71926de50>,\n",
       " 1223: <datasketch.minhash.MinHash at 0x7fc71926df10>,\n",
       " 1226: <datasketch.minhash.MinHash at 0x7fc71926dee0>,\n",
       " 1227: <datasketch.minhash.MinHash at 0x7fc71926dfd0>,\n",
       " 1230: <datasketch.minhash.MinHash at 0x7fc71926dfa0>,\n",
       " 1232: <datasketch.minhash.MinHash at 0x7fc71926df70>,\n",
       " 1235: <datasketch.minhash.MinHash at 0x7fc728ed20a0>,\n",
       " 1238: <datasketch.minhash.MinHash at 0x7fc728ed2130>,\n",
       " 1243: <datasketch.minhash.MinHash at 0x7fc728ed2190>,\n",
       " 1244: <datasketch.minhash.MinHash at 0x7fc728ed21f0>,\n",
       " 1245: <datasketch.minhash.MinHash at 0x7fc728ed2250>,\n",
       " 1247: <datasketch.minhash.MinHash at 0x7fc728ed22b0>,\n",
       " 1248: <datasketch.minhash.MinHash at 0x7fc728ed2310>,\n",
       " 1249: <datasketch.minhash.MinHash at 0x7fc728ed2370>,\n",
       " 1250: <datasketch.minhash.MinHash at 0x7fc728ed23d0>,\n",
       " 1252: <datasketch.minhash.MinHash at 0x7fc728ed2430>,\n",
       " 1255: <datasketch.minhash.MinHash at 0x7fc728ed24f0>,\n",
       " 1259: <datasketch.minhash.MinHash at 0x7fc728ed24c0>,\n",
       " 1260: <datasketch.minhash.MinHash at 0x7fc728ed2550>,\n",
       " 1262: <datasketch.minhash.MinHash at 0x7fc728ed25b0>,\n",
       " 1265: <datasketch.minhash.MinHash at 0x7fc728ed2610>,\n",
       " 1266: <datasketch.minhash.MinHash at 0x7fc728ed2670>,\n",
       " 1269: <datasketch.minhash.MinHash at 0x7fc728ed26d0>,\n",
       " 1270: <datasketch.minhash.MinHash at 0x7fc728ed2730>,\n",
       " 1272: <datasketch.minhash.MinHash at 0x7fc728ed2790>,\n",
       " 1273: <datasketch.minhash.MinHash at 0x7fc728ed27f0>,\n",
       " 1274: <datasketch.minhash.MinHash at 0x7fc728ed2850>,\n",
       " 1276: <datasketch.minhash.MinHash at 0x7fc728ed28b0>,\n",
       " 1278: <datasketch.minhash.MinHash at 0x7fc728ed2910>,\n",
       " 1280: <datasketch.minhash.MinHash at 0x7fc728ed2970>,\n",
       " 1281: <datasketch.minhash.MinHash at 0x7fc728ed29d0>,\n",
       " 1287: <datasketch.minhash.MinHash at 0x7fc728ed2a30>,\n",
       " 1288: <datasketch.minhash.MinHash at 0x7fc728ed2a90>,\n",
       " 1290: <datasketch.minhash.MinHash at 0x7fc728ed2af0>,\n",
       " 1291: <datasketch.minhash.MinHash at 0x7fc728ed2b50>,\n",
       " 1292: <datasketch.minhash.MinHash at 0x7fc728ed2bb0>,\n",
       " 1294: <datasketch.minhash.MinHash at 0x7fc728ed2c10>,\n",
       " 1295: <datasketch.minhash.MinHash at 0x7fc728ed2c70>,\n",
       " 1296: <datasketch.minhash.MinHash at 0x7fc728ed2cd0>,\n",
       " 1298: <datasketch.minhash.MinHash at 0x7fc728ed2d30>,\n",
       " 1299: <datasketch.minhash.MinHash at 0x7fc728ed2d90>,\n",
       " 1300: <datasketch.minhash.MinHash at 0x7fc728ed2df0>,\n",
       " 1301: <datasketch.minhash.MinHash at 0x7fc728ed2e50>,\n",
       " 1302: <datasketch.minhash.MinHash at 0x7fc728ed2eb0>,\n",
       " 1303: <datasketch.minhash.MinHash at 0x7fc728ed2f10>,\n",
       " 1304: <datasketch.minhash.MinHash at 0x7fc728ed2f70>,\n",
       " 1306: <datasketch.minhash.MinHash at 0x7fc728ed2fd0>,\n",
       " 1307: <datasketch.minhash.MinHash at 0x7fc728ed2fa0>,\n",
       " 1310: <datasketch.minhash.MinHash at 0x7fc728ec10a0>,\n",
       " 1311: <datasketch.minhash.MinHash at 0x7fc728ec1100>,\n",
       " 1317: <datasketch.minhash.MinHash at 0x7fc728ec1190>,\n",
       " 1322: <datasketch.minhash.MinHash at 0x7fc728ec11c0>,\n",
       " 1324: <datasketch.minhash.MinHash at 0x7fc728ec1250>,\n",
       " 1326: <datasketch.minhash.MinHash at 0x7fc728ec12b0>,\n",
       " 1331: <datasketch.minhash.MinHash at 0x7fc728ec1310>,\n",
       " 1332: <datasketch.minhash.MinHash at 0x7fc728ec1370>,\n",
       " 1334: <datasketch.minhash.MinHash at 0x7fc728ec13d0>,\n",
       " 1339: <datasketch.minhash.MinHash at 0x7fc728ec1430>,\n",
       " 1342: <datasketch.minhash.MinHash at 0x7fc728ec1490>,\n",
       " 1344: <datasketch.minhash.MinHash at 0x7fc728ec14f0>,\n",
       " 1349: <datasketch.minhash.MinHash at 0x7fc728ec1550>,\n",
       " 1350: <datasketch.minhash.MinHash at 0x7fc728ec15b0>,\n",
       " 1352: <datasketch.minhash.MinHash at 0x7fc728ec1610>,\n",
       " 1355: <datasketch.minhash.MinHash at 0x7fc728ec1670>,\n",
       " 1356: <datasketch.minhash.MinHash at 0x7fc728ec16d0>,\n",
       " 1358: <datasketch.minhash.MinHash at 0x7fc728ec1730>,\n",
       " 1362: <datasketch.minhash.MinHash at 0x7fc728ec1790>,\n",
       " 1363: <datasketch.minhash.MinHash at 0x7fc728ec17f0>,\n",
       " 1366: <datasketch.minhash.MinHash at 0x7fc728ec1850>,\n",
       " 1367: <datasketch.minhash.MinHash at 0x7fc728ec18b0>,\n",
       " 1371: <datasketch.minhash.MinHash at 0x7fc728ec1910>,\n",
       " 1372: <datasketch.minhash.MinHash at 0x7fc728ec1970>,\n",
       " 1375: <datasketch.minhash.MinHash at 0x7fc728ec19d0>,\n",
       " 1378: <datasketch.minhash.MinHash at 0x7fc728ec1a30>,\n",
       " 1380: <datasketch.minhash.MinHash at 0x7fc728ec1a90>,\n",
       " 1382: <datasketch.minhash.MinHash at 0x7fc728ec1af0>,\n",
       " 1390: <datasketch.minhash.MinHash at 0x7fc728ec1b50>,\n",
       " 1391: <datasketch.minhash.MinHash at 0x7fc728ec1bb0>,\n",
       " 1394: <datasketch.minhash.MinHash at 0x7fc728ec1c10>,\n",
       " 1395: <datasketch.minhash.MinHash at 0x7fc728ec1c70>,\n",
       " 1398: <datasketch.minhash.MinHash at 0x7fc728ec1cd0>,\n",
       " 1399: <datasketch.minhash.MinHash at 0x7fc728ec1d30>,\n",
       " 1404: <datasketch.minhash.MinHash at 0x7fc728ec1d60>,\n",
       " 1406: <datasketch.minhash.MinHash at 0x7fc728ec1df0>,\n",
       " 1415: <datasketch.minhash.MinHash at 0x7fc728ec1e50>,\n",
       " 1417: <datasketch.minhash.MinHash at 0x7fc728ec1eb0>,\n",
       " 1418: <datasketch.minhash.MinHash at 0x7fc728ec1f10>,\n",
       " 1419: <datasketch.minhash.MinHash at 0x7fc728ec1f70>,\n",
       " 1420: <datasketch.minhash.MinHash at 0x7fc728ec1fd0>,\n",
       " 1425: <datasketch.minhash.MinHash at 0x7fc728ec1fa0>,\n",
       " 1426: <datasketch.minhash.MinHash at 0x7fc728ee50a0>,\n",
       " 1427: <datasketch.minhash.MinHash at 0x7fc728ee5130>,\n",
       " 1441: <datasketch.minhash.MinHash at 0x7fc728ee5190>,\n",
       " 1451: <datasketch.minhash.MinHash at 0x7fc728ee51f0>,\n",
       " 1452: <datasketch.minhash.MinHash at 0x7fc728ee5250>,\n",
       " 1456: <datasketch.minhash.MinHash at 0x7fc728ee52b0>,\n",
       " 1457: <datasketch.minhash.MinHash at 0x7fc728ee5310>,\n",
       " 1458: <datasketch.minhash.MinHash at 0x7fc728ee5370>,\n",
       " 1460: <datasketch.minhash.MinHash at 0x7fc728ee53a0>,\n",
       " 1461: <datasketch.minhash.MinHash at 0x7fc728ee5400>,\n",
       " 1466: <datasketch.minhash.MinHash at 0x7fc728ee5490>,\n",
       " 1468: <datasketch.minhash.MinHash at 0x7fc728ee5460>,\n",
       " 1469: <datasketch.minhash.MinHash at 0x7fc728ee54f0>,\n",
       " 1470: <datasketch.minhash.MinHash at 0x7fc728ee5580>,\n",
       " 1477: <datasketch.minhash.MinHash at 0x7fc728ee55e0>,\n",
       " 1480: <datasketch.minhash.MinHash at 0x7fc728ee56d0>,\n",
       " 1485: <datasketch.minhash.MinHash at 0x7fc728ee5760>,\n",
       " 1488: <datasketch.minhash.MinHash at 0x7fc728ee5700>,\n",
       " 1489: <datasketch.minhash.MinHash at 0x7fc728ee5730>,\n",
       " 1490: <datasketch.minhash.MinHash at 0x7fc728ee5790>,\n",
       " 1491: <datasketch.minhash.MinHash at 0x7fc728ee58b0>,\n",
       " 1492: <datasketch.minhash.MinHash at 0x7fc728ee5850>,\n",
       " 1493: <datasketch.minhash.MinHash at 0x7fc728ee58e0>,\n",
       " 1496: <datasketch.minhash.MinHash at 0x7fc728ee5940>,\n",
       " 1499: <datasketch.minhash.MinHash at 0x7fc728ee59d0>,\n",
       " 1500: <datasketch.minhash.MinHash at 0x7fc728ee5a30>,\n",
       " 1504: <datasketch.minhash.MinHash at 0x7fc728ee5a90>,\n",
       " 1505: <datasketch.minhash.MinHash at 0x7fc728ee5af0>,\n",
       " 1506: <datasketch.minhash.MinHash at 0x7fc728ee5b50>,\n",
       " 1507: <datasketch.minhash.MinHash at 0x7fc728ee5bb0>,\n",
       " 1510: <datasketch.minhash.MinHash at 0x7fc728ee5c10>,\n",
       " 1512: <datasketch.minhash.MinHash at 0x7fc728ee5c70>,\n",
       " 1515: <datasketch.minhash.MinHash at 0x7fc728ee5cd0>,\n",
       " 1516: <datasketch.minhash.MinHash at 0x7fc728ee5d30>,\n",
       " 1518: <datasketch.minhash.MinHash at 0x7fc728ee5d90>,\n",
       " 1520: <datasketch.minhash.MinHash at 0x7fc728ee5df0>,\n",
       " 1522: <datasketch.minhash.MinHash at 0x7fc728ee5e50>,\n",
       " 1525: <datasketch.minhash.MinHash at 0x7fc728ee5eb0>,\n",
       " 1533: <datasketch.minhash.MinHash at 0x7fc728ee5f10>,\n",
       " 1537: <datasketch.minhash.MinHash at 0x7fc728ee5f70>,\n",
       " 1538: <datasketch.minhash.MinHash at 0x7fc728ee5fd0>,\n",
       " 1541: <datasketch.minhash.MinHash at 0x7fc728ee5fa0>,\n",
       " 1542: <datasketch.minhash.MinHash at 0x7fc728ecf0a0>,\n",
       " 1545: <datasketch.minhash.MinHash at 0x7fc728ecf190>,\n",
       " 1546: <datasketch.minhash.MinHash at 0x7fc728ecf160>,\n",
       " 1550: <datasketch.minhash.MinHash at 0x7fc728ecf1f0>,\n",
       " 1551: <datasketch.minhash.MinHash at 0x7fc728ecf250>,\n",
       " 1553: <datasketch.minhash.MinHash at 0x7fc728ecf2b0>,\n",
       " 1556: <datasketch.minhash.MinHash at 0x7fc728ecf310>,\n",
       " 1560: <datasketch.minhash.MinHash at 0x7fc728ecf370>,\n",
       " 1561: <datasketch.minhash.MinHash at 0x7fc728ecf3d0>,\n",
       " 1564: <datasketch.minhash.MinHash at 0x7fc728ecf430>,\n",
       " 1574: <datasketch.minhash.MinHash at 0x7fc728ecf490>,\n",
       " 1580: <datasketch.minhash.MinHash at 0x7fc728ecf4f0>,\n",
       " 1582: <datasketch.minhash.MinHash at 0x7fc728ecf550>,\n",
       " 1583: <datasketch.minhash.MinHash at 0x7fc728ecf5b0>,\n",
       " 1586: <datasketch.minhash.MinHash at 0x7fc728ecf610>,\n",
       " 1590: <datasketch.minhash.MinHash at 0x7fc728ecf670>,\n",
       " 1591: <datasketch.minhash.MinHash at 0x7fc728ecf6d0>,\n",
       " 1593: <datasketch.minhash.MinHash at 0x7fc728ecf730>,\n",
       " 1595: <datasketch.minhash.MinHash at 0x7fc728ecf790>,\n",
       " 1599: <datasketch.minhash.MinHash at 0x7fc728ecf7f0>,\n",
       " 1605: <datasketch.minhash.MinHash at 0x7fc728ecf850>,\n",
       " 1613: <datasketch.minhash.MinHash at 0x7fc728ecf8b0>,\n",
       " 1614: <datasketch.minhash.MinHash at 0x7fc728ecf910>,\n",
       " 1615: <datasketch.minhash.MinHash at 0x7fc728ecf970>,\n",
       " 1616: <datasketch.minhash.MinHash at 0x7fc728ecf9d0>,\n",
       " 1618: <datasketch.minhash.MinHash at 0x7fc728ecfa30>,\n",
       " 1620: <datasketch.minhash.MinHash at 0x7fc728ecfaf0>,\n",
       " 1621: <datasketch.minhash.MinHash at 0x7fc728ecfac0>,\n",
       " 1623: <datasketch.minhash.MinHash at 0x7fc728ecfb50>,\n",
       " 1626: <datasketch.minhash.MinHash at 0x7fc728ecfbb0>,\n",
       " 1628: <datasketch.minhash.MinHash at 0x7fc728ecfc10>,\n",
       " 1632: <datasketch.minhash.MinHash at 0x7fc728ecfc70>,\n",
       " 1633: <datasketch.minhash.MinHash at 0x7fc728ecfcd0>,\n",
       " 1634: <datasketch.minhash.MinHash at 0x7fc728ecfd30>,\n",
       " 1635: <datasketch.minhash.MinHash at 0x7fc728ecfd90>,\n",
       " 1641: <datasketch.minhash.MinHash at 0x7fc728ecfe50>,\n",
       " 1645: <datasketch.minhash.MinHash at 0x7fc728ecfe20>,\n",
       " 1646: <datasketch.minhash.MinHash at 0x7fc728ecfeb0>,\n",
       " 1650: <datasketch.minhash.MinHash at 0x7fc728ecff10>,\n",
       " 1652: <datasketch.minhash.MinHash at 0x7fc728ecff70>,\n",
       " 1653: <datasketch.minhash.MinHash at 0x7fc728ecffd0>,\n",
       " 1654: <datasketch.minhash.MinHash at 0x7fc728ecffa0>,\n",
       " 1656: <datasketch.minhash.MinHash at 0x7fc728ee00a0>,\n",
       " 1659: <datasketch.minhash.MinHash at 0x7fc728ee0130>,\n",
       " 1663: <datasketch.minhash.MinHash at 0x7fc728ee0190>,\n",
       " 1664: <datasketch.minhash.MinHash at 0x7fc728ee01f0>,\n",
       " 1667: <datasketch.minhash.MinHash at 0x7fc728ee0250>,\n",
       " 1670: <datasketch.minhash.MinHash at 0x7fc728ee02b0>,\n",
       " 1675: <datasketch.minhash.MinHash at 0x7fc728ee0310>,\n",
       " 1677: <datasketch.minhash.MinHash at 0x7fc728ee0370>,\n",
       " 1681: <datasketch.minhash.MinHash at 0x7fc728ee03d0>,\n",
       " 1682: <datasketch.minhash.MinHash at 0x7fc728ee0430>,\n",
       " 1683: <datasketch.minhash.MinHash at 0x7fc728ee0490>,\n",
       " 1688: <datasketch.minhash.MinHash at 0x7fc728ee04f0>,\n",
       " 1689: <datasketch.minhash.MinHash at 0x7fc728ee0550>,\n",
       " 1694: <datasketch.minhash.MinHash at 0x7fc728ee0610>,\n",
       " 1699: <datasketch.minhash.MinHash at 0x7fc728ee05e0>,\n",
       " 1700: <datasketch.minhash.MinHash at 0x7fc728ee0670>,\n",
       " 1701: <datasketch.minhash.MinHash at 0x7fc728ee06d0>,\n",
       " 1702: <datasketch.minhash.MinHash at 0x7fc728ee0730>,\n",
       " 1703: <datasketch.minhash.MinHash at 0x7fc728ee0790>,\n",
       " 1708: <datasketch.minhash.MinHash at 0x7fc728ee07f0>,\n",
       " 1711: <datasketch.minhash.MinHash at 0x7fc728ee0850>,\n",
       " 1715: <datasketch.minhash.MinHash at 0x7fc728ee08b0>,\n",
       " 1716: <datasketch.minhash.MinHash at 0x7fc728ee0910>,\n",
       " 1718: <datasketch.minhash.MinHash at 0x7fc728ee0970>,\n",
       " 1720: <datasketch.minhash.MinHash at 0x7fc728ee09d0>,\n",
       " 1721: <datasketch.minhash.MinHash at 0x7fc728ee0a30>,\n",
       " 1722: <datasketch.minhash.MinHash at 0x7fc728ee0a90>,\n",
       " 1723: <datasketch.minhash.MinHash at 0x7fc728ee0af0>,\n",
       " 1729: <datasketch.minhash.MinHash at 0x7fc728ee0b50>,\n",
       " 1730: <datasketch.minhash.MinHash at 0x7fc728ee0bb0>,\n",
       " 1731: <datasketch.minhash.MinHash at 0x7fc728ee0c10>,\n",
       " 1732: <datasketch.minhash.MinHash at 0x7fc728ee0c70>,\n",
       " 1737: <datasketch.minhash.MinHash at 0x7fc728ee0d60>,\n",
       " 1743: <datasketch.minhash.MinHash at 0x7fc728ee0d90>,\n",
       " 1744: <datasketch.minhash.MinHash at 0x7fc728ee0cd0>,\n",
       " 1745: <datasketch.minhash.MinHash at 0x7fc728ee0df0>,\n",
       " 1747: <datasketch.minhash.MinHash at 0x7fc728ee0e50>,\n",
       " 1752: <datasketch.minhash.MinHash at 0x7fc728ee0eb0>,\n",
       " 1754: <datasketch.minhash.MinHash at 0x7fc728ee0f10>,\n",
       " 1758: <datasketch.minhash.MinHash at 0x7fc728ee0f70>,\n",
       " 1759: <datasketch.minhash.MinHash at 0x7fc728ee0fd0>,\n",
       " 1761: <datasketch.minhash.MinHash at 0x7fc728ee0fa0>,\n",
       " 1766: <datasketch.minhash.MinHash at 0x7fc728ec90a0>,\n",
       " 1769: <datasketch.minhash.MinHash at 0x7fc728ec9190>,\n",
       " 1770: <datasketch.minhash.MinHash at 0x7fc728ec9160>,\n",
       " 1771: <datasketch.minhash.MinHash at 0x7fc728ec91f0>,\n",
       " 1772: <datasketch.minhash.MinHash at 0x7fc728ec9280>,\n",
       " 1773: <datasketch.minhash.MinHash at 0x7fc728ec92e0>,\n",
       " 1774: <datasketch.minhash.MinHash at 0x7fc728ec9340>,\n",
       " 1775: <datasketch.minhash.MinHash at 0x7fc728ec93a0>,\n",
       " 1777: <datasketch.minhash.MinHash at 0x7fc728ec9400>,\n",
       " 1780: <datasketch.minhash.MinHash at 0x7fc728ec9460>,\n",
       " 1783: <datasketch.minhash.MinHash at 0x7fc728ec94c0>,\n",
       " 1785: <datasketch.minhash.MinHash at 0x7fc728ec9520>,\n",
       " 1786: <datasketch.minhash.MinHash at 0x7fc728ec9580>,\n",
       " 1796: <datasketch.minhash.MinHash at 0x7fc728ec95e0>,\n",
       " 1798: <datasketch.minhash.MinHash at 0x7fc728ec9640>,\n",
       " 1802: <datasketch.minhash.MinHash at 0x7fc728ec96a0>,\n",
       " 1804: <datasketch.minhash.MinHash at 0x7fc728ec9700>,\n",
       " 1808: <datasketch.minhash.MinHash at 0x7fc728ec97c0>,\n",
       " 1812: <datasketch.minhash.MinHash at 0x7fc728ec9790>,\n",
       " 1816: <datasketch.minhash.MinHash at 0x7fc728ec9820>,\n",
       " 1817: <datasketch.minhash.MinHash at 0x7fc728ec9880>,\n",
       " 1818: <datasketch.minhash.MinHash at 0x7fc728ec98e0>,\n",
       " 1819: <datasketch.minhash.MinHash at 0x7fc728ec9940>,\n",
       " 1820: <datasketch.minhash.MinHash at 0x7fc728ec99a0>,\n",
       " 1823: <datasketch.minhash.MinHash at 0x7fc728ec9a00>,\n",
       " 1824: <datasketch.minhash.MinHash at 0x7fc728ec9a60>,\n",
       " 1825: <datasketch.minhash.MinHash at 0x7fc728ec9ac0>,\n",
       " 1826: <datasketch.minhash.MinHash at 0x7fc728ec9b80>,\n",
       " 1827: <datasketch.minhash.MinHash at 0x7fc728ec9b50>,\n",
       " 1829: <datasketch.minhash.MinHash at 0x7fc728ec9be0>,\n",
       " 1833: <datasketch.minhash.MinHash at 0x7fc728ec9c40>,\n",
       " 1834: <datasketch.minhash.MinHash at 0x7fc728ec9d00>,\n",
       " 1838: <datasketch.minhash.MinHash at 0x7fc728ec9d60>,\n",
       " 1840: <datasketch.minhash.MinHash at 0x7fc728ec9d30>,\n",
       " 1841: <datasketch.minhash.MinHash at 0x7fc728ec9dc0>,\n",
       " 1843: <datasketch.minhash.MinHash at 0x7fc728ec9e20>,\n",
       " 1848: <datasketch.minhash.MinHash at 0x7fc728ec9e80>,\n",
       " 1849: <datasketch.minhash.MinHash at 0x7fc728ec9ee0>,\n",
       " 1855: <datasketch.minhash.MinHash at 0x7fc728ec9fa0>,\n",
       " 1856: <datasketch.minhash.MinHash at 0x7fc728ec9fd0>,\n",
       " 1858: <datasketch.minhash.MinHash at 0x7fc728ec9f70>,\n",
       " 1863: <datasketch.minhash.MinHash at 0x7fc770ed7070>,\n",
       " 1866: <datasketch.minhash.MinHash at 0x7fc770ed7100>,\n",
       " 1867: <datasketch.minhash.MinHash at 0x7fc770ed7160>,\n",
       " 1869: <datasketch.minhash.MinHash at 0x7fc770ed71c0>,\n",
       " 1871: <datasketch.minhash.MinHash at 0x7fc770ed7220>,\n",
       " 1873: <datasketch.minhash.MinHash at 0x7fc770ed7280>,\n",
       " 1874: <datasketch.minhash.MinHash at 0x7fc770ed72e0>,\n",
       " 1875: <datasketch.minhash.MinHash at 0x7fc770ed73a0>,\n",
       " 1877: <datasketch.minhash.MinHash at 0x7fc770ed7370>,\n",
       " 1878: <datasketch.minhash.MinHash at 0x7fc770ed7400>,\n",
       " 1880: <datasketch.minhash.MinHash at 0x7fc770ed7460>,\n",
       " 1884: <datasketch.minhash.MinHash at 0x7fc770ed74c0>,\n",
       " 1887: <datasketch.minhash.MinHash at 0x7fc770ed7580>,\n",
       " 1888: <datasketch.minhash.MinHash at 0x7fc770ed7550>,\n",
       " 1890: <datasketch.minhash.MinHash at 0x7fc770ed75e0>,\n",
       " 1895: <datasketch.minhash.MinHash at 0x7fc770ed7640>,\n",
       " 1899: <datasketch.minhash.MinHash at 0x7fc770ed76a0>,\n",
       " 1902: <datasketch.minhash.MinHash at 0x7fc770ed7700>,\n",
       " 1903: <datasketch.minhash.MinHash at 0x7fc770ed7760>,\n",
       " 1906: <datasketch.minhash.MinHash at 0x7fc770ed77c0>,\n",
       " 1908: <datasketch.minhash.MinHash at 0x7fc770ed7820>,\n",
       " 1913: <datasketch.minhash.MinHash at 0x7fc770ed7880>,\n",
       " 1921: <datasketch.minhash.MinHash at 0x7fc770ed78e0>,\n",
       " 1924: <datasketch.minhash.MinHash at 0x7fc770ed7940>,\n",
       " 1925: <datasketch.minhash.MinHash at 0x7fc770ed79a0>,\n",
       " 1927: <datasketch.minhash.MinHash at 0x7fc770ed7a00>,\n",
       " 1928: <datasketch.minhash.MinHash at 0x7fc770ed7a60>,\n",
       " 1934: <datasketch.minhash.MinHash at 0x7fc770ed7ac0>,\n",
       " 1936: <datasketch.minhash.MinHash at 0x7fc770ed7b20>,\n",
       " 1938: <datasketch.minhash.MinHash at 0x7fc770ed7b80>,\n",
       " 1942: <datasketch.minhash.MinHash at 0x7fc770ed7be0>,\n",
       " 1944: <datasketch.minhash.MinHash at 0x7fc770ed7c40>,\n",
       " 1946: <datasketch.minhash.MinHash at 0x7fc770ed7ca0>,\n",
       " 1949: <datasketch.minhash.MinHash at 0x7fc770ed7d00>,\n",
       " 1952: <datasketch.minhash.MinHash at 0x7fc770ed7d60>,\n",
       " 1955: <datasketch.minhash.MinHash at 0x7fc770ed7dc0>,\n",
       " 1957: <datasketch.minhash.MinHash at 0x7fc770ed7e20>,\n",
       " 1959: <datasketch.minhash.MinHash at 0x7fc770ed7e80>,\n",
       " 1960: <datasketch.minhash.MinHash at 0x7fc770ed7ee0>,\n",
       " 1961: <datasketch.minhash.MinHash at 0x7fc770ed7f40>,\n",
       " 1966: <datasketch.minhash.MinHash at 0x7fc770ed7fd0>,\n",
       " 1967: <datasketch.minhash.MinHash at 0x7fc728ec91c0>,\n",
       " 1972: <datasketch.minhash.MinHash at 0x7fc770ef0070>,\n",
       " 1974: <datasketch.minhash.MinHash at 0x7fc770ef0100>,\n",
       " 1975: <datasketch.minhash.MinHash at 0x7fc770ef0160>,\n",
       " 1977: <datasketch.minhash.MinHash at 0x7fc770ed7fa0>,\n",
       " 1978: <datasketch.minhash.MinHash at 0x7fc770ef0190>,\n",
       " 1982: <datasketch.minhash.MinHash at 0x7fc770ef0250>,\n",
       " 1984: <datasketch.minhash.MinHash at 0x7fc770ef02b0>,\n",
       " 1988: <datasketch.minhash.MinHash at 0x7fc770ef0310>,\n",
       " 1990: <datasketch.minhash.MinHash at 0x7fc770ef0370>,\n",
       " 1997: <datasketch.minhash.MinHash at 0x7fc770ef03d0>,\n",
       " 2003: <datasketch.minhash.MinHash at 0x7fc770ef0430>,\n",
       " 2004: <datasketch.minhash.MinHash at 0x7fc770ef0490>,\n",
       " 2006: <datasketch.minhash.MinHash at 0x7fc770ef04f0>,\n",
       " 2007: <datasketch.minhash.MinHash at 0x7fc770ef0550>,\n",
       " 2008: <datasketch.minhash.MinHash at 0x7fc770ef05b0>,\n",
       " 2012: <datasketch.minhash.MinHash at 0x7fc770ef0610>,\n",
       " 2013: <datasketch.minhash.MinHash at 0x7fc770ef06d0>,\n",
       " 2014: <datasketch.minhash.MinHash at 0x7fc770ef06a0>,\n",
       " 2015: <datasketch.minhash.MinHash at 0x7fc770ef0730>,\n",
       " 2016: <datasketch.minhash.MinHash at 0x7fc770ef0790>,\n",
       " 2018: <datasketch.minhash.MinHash at 0x7fc770ef07f0>,\n",
       " 2019: <datasketch.minhash.MinHash at 0x7fc770ef0850>,\n",
       " 2022: <datasketch.minhash.MinHash at 0x7fc770ef08b0>,\n",
       " 2025: <datasketch.minhash.MinHash at 0x7fc770ef0910>,\n",
       " 2027: <datasketch.minhash.MinHash at 0x7fc770ef0970>,\n",
       " 2031: <datasketch.minhash.MinHash at 0x7fc770ef09d0>,\n",
       " 2032: <datasketch.minhash.MinHash at 0x7fc770ef0a30>,\n",
       " 2035: <datasketch.minhash.MinHash at 0x7fc770ef0a90>,\n",
       " 2036: <datasketch.minhash.MinHash at 0x7fc770ef0af0>,\n",
       " 2037: <datasketch.minhash.MinHash at 0x7fc770ef0b20>,\n",
       " 2038: <datasketch.minhash.MinHash at 0x7fc770ef0bb0>,\n",
       " 2040: <datasketch.minhash.MinHash at 0x7fc770ef0c10>,\n",
       " 2041: <datasketch.minhash.MinHash at 0x7fc770ef0c70>,\n",
       " 2042: <datasketch.minhash.MinHash at 0x7fc770ef0cd0>,\n",
       " 2044: <datasketch.minhash.MinHash at 0x7fc770ef0d30>,\n",
       " 2045: <datasketch.minhash.MinHash at 0x7fc770ef0d90>,\n",
       " 2047: <datasketch.minhash.MinHash at 0x7fc770ef0df0>,\n",
       " 2051: <datasketch.minhash.MinHash at 0x7fc770ef0e50>,\n",
       " 2052: <datasketch.minhash.MinHash at 0x7fc770ef0eb0>,\n",
       " 2054: <datasketch.minhash.MinHash at 0x7fc770ef0f10>,\n",
       " 2055: <datasketch.minhash.MinHash at 0x7fc770ef0f70>,\n",
       " 2056: <datasketch.minhash.MinHash at 0x7fc770ef0fd0>,\n",
       " 2060: <datasketch.minhash.MinHash at 0x7fc770ef0fa0>,\n",
       " 2062: <datasketch.minhash.MinHash at 0x7fc770ecc0a0>,\n",
       " 2064: <datasketch.minhash.MinHash at 0x7fc770ecc130>,\n",
       " 2067: <datasketch.minhash.MinHash at 0x7fc770ecc1f0>,\n",
       " 2068: <datasketch.minhash.MinHash at 0x7fc770ecc1c0>,\n",
       " 2069: <datasketch.minhash.MinHash at 0x7fc770ecc250>,\n",
       " 2071: <datasketch.minhash.MinHash at 0x7fc770ecc2b0>,\n",
       " 2076: <datasketch.minhash.MinHash at 0x7fc770ecc310>,\n",
       " 2078: <datasketch.minhash.MinHash at 0x7fc770ecc370>,\n",
       " 2081: <datasketch.minhash.MinHash at 0x7fc770ecc3d0>,\n",
       " 2082: <datasketch.minhash.MinHash at 0x7fc770ecc430>,\n",
       " 2090: <datasketch.minhash.MinHash at 0x7fc770ecc460>,\n",
       " 2091: <datasketch.minhash.MinHash at 0x7fc770ecc550>,\n",
       " 2092: <datasketch.minhash.MinHash at 0x7fc770ecc520>,\n",
       " 2094: <datasketch.minhash.MinHash at 0x7fc770ecc5b0>,\n",
       " 2106: <datasketch.minhash.MinHash at 0x7fc770ecc610>,\n",
       " 2107: <datasketch.minhash.MinHash at 0x7fc770ecc670>,\n",
       " 2108: <datasketch.minhash.MinHash at 0x7fc770ecc6d0>,\n",
       " 2109: <datasketch.minhash.MinHash at 0x7fc770ecc730>,\n",
       " 2113: <datasketch.minhash.MinHash at 0x7fc770ecc7c0>,\n",
       " 2122: <datasketch.minhash.MinHash at 0x7fc770ecc820>,\n",
       " 2124: <datasketch.minhash.MinHash at 0x7fc770ecc880>,\n",
       " 2129: <datasketch.minhash.MinHash at 0x7fc770ecc8e0>,\n",
       " 2131: <datasketch.minhash.MinHash at 0x7fc770ecc940>,\n",
       " 2134: <datasketch.minhash.MinHash at 0x7fc770ecc9a0>,\n",
       " 2138: <datasketch.minhash.MinHash at 0x7fc770ecca00>,\n",
       " 2141: <datasketch.minhash.MinHash at 0x7fc770ecca60>,\n",
       " 2142: <datasketch.minhash.MinHash at 0x7fc770eccac0>,\n",
       " 2148: <datasketch.minhash.MinHash at 0x7fc770eccb20>,\n",
       " 2149: <datasketch.minhash.MinHash at 0x7fc770eccb80>,\n",
       " 2155: <datasketch.minhash.MinHash at 0x7fc770eccbe0>,\n",
       " 2157: <datasketch.minhash.MinHash at 0x7fc770eccc40>,\n",
       " 2159: <datasketch.minhash.MinHash at 0x7fc770eccca0>,\n",
       " 2163: <datasketch.minhash.MinHash at 0x7fc770eccd00>,\n",
       " 2168: <datasketch.minhash.MinHash at 0x7fc770eccdc0>,\n",
       " 2169: <datasketch.minhash.MinHash at 0x7fc770eccd90>,\n",
       " 2173: <datasketch.minhash.MinHash at 0x7fc770ecce20>,\n",
       " 2174: <datasketch.minhash.MinHash at 0x7fc770ecce80>,\n",
       " 2178: <datasketch.minhash.MinHash at 0x7fc770eccee0>,\n",
       " 2180: <datasketch.minhash.MinHash at 0x7fc770eccf40>,\n",
       " 2183: <datasketch.minhash.MinHash at 0x7fc770eccfd0>,\n",
       " 2189: <datasketch.minhash.MinHash at 0x7fc770eccfa0>,\n",
       " 2191: <datasketch.minhash.MinHash at 0x7fc770efa040>,\n",
       " 2192: <datasketch.minhash.MinHash at 0x7fc770efa0d0>,\n",
       " 2193: <datasketch.minhash.MinHash at 0x7fc770efa130>,\n",
       " 2200: <datasketch.minhash.MinHash at 0x7fc770efa1c0>,\n",
       " 2203: <datasketch.minhash.MinHash at 0x7fc770efa220>,\n",
       " 2204: <datasketch.minhash.MinHash at 0x7fc770efa280>,\n",
       " 2209: <datasketch.minhash.MinHash at 0x7fc770efa2e0>,\n",
       " 2210: <datasketch.minhash.MinHash at 0x7fc770efa340>,\n",
       " 2212: <datasketch.minhash.MinHash at 0x7fc770efa3a0>,\n",
       " 2213: <datasketch.minhash.MinHash at 0x7fc770efa400>,\n",
       " 2225: <datasketch.minhash.MinHash at 0x7fc770efa460>,\n",
       " 2227: <datasketch.minhash.MinHash at 0x7fc770efa4c0>,\n",
       " 2228: <datasketch.minhash.MinHash at 0x7fc770efa580>,\n",
       " 2230: <datasketch.minhash.MinHash at 0x7fc770efa550>,\n",
       " 2231: <datasketch.minhash.MinHash at 0x7fc770efa5e0>,\n",
       " 2232: <datasketch.minhash.MinHash at 0x7fc770efa640>,\n",
       " 2235: <datasketch.minhash.MinHash at 0x7fc770efa6a0>,\n",
       " 2236: <datasketch.minhash.MinHash at 0x7fc770efa700>,\n",
       " 2237: <datasketch.minhash.MinHash at 0x7fc770efa760>,\n",
       " 2238: <datasketch.minhash.MinHash at 0x7fc770efa7c0>,\n",
       " 2239: <datasketch.minhash.MinHash at 0x7fc770efa820>,\n",
       " 2240: <datasketch.minhash.MinHash at 0x7fc770efa880>,\n",
       " 2241: <datasketch.minhash.MinHash at 0x7fc770efa8e0>,\n",
       " 2242: <datasketch.minhash.MinHash at 0x7fc770efa940>,\n",
       " 2244: <datasketch.minhash.MinHash at 0x7fc770efaa00>,\n",
       " 2247: <datasketch.minhash.MinHash at 0x7fc770efa9d0>,\n",
       " 2249: <datasketch.minhash.MinHash at 0x7fc770efaa60>,\n",
       " 2250: <datasketch.minhash.MinHash at 0x7fc770efaac0>,\n",
       " 2252: <datasketch.minhash.MinHash at 0x7fc770efab20>,\n",
       " 2255: <datasketch.minhash.MinHash at 0x7fc770efab80>,\n",
       " 2259: <datasketch.minhash.MinHash at 0x7fc770efabe0>,\n",
       " 2261: <datasketch.minhash.MinHash at 0x7fc770efac40>,\n",
       " 2268: <datasketch.minhash.MinHash at 0x7fc770efaca0>,\n",
       " 2271: <datasketch.minhash.MinHash at 0x7fc770efad00>,\n",
       " 2273: <datasketch.minhash.MinHash at 0x7fc770efad60>,\n",
       " 2274: <datasketch.minhash.MinHash at 0x7fc770efadc0>,\n",
       " 2275: <datasketch.minhash.MinHash at 0x7fc770efae20>,\n",
       " 2280: <datasketch.minhash.MinHash at 0x7fc770efae80>,\n",
       " 2281: <datasketch.minhash.MinHash at 0x7fc770efaee0>,\n",
       " 2284: <datasketch.minhash.MinHash at 0x7fc770efaf40>,\n",
       " 2286: <datasketch.minhash.MinHash at 0x7fc770efafd0>,\n",
       " 2288: <datasketch.minhash.MinHash at 0x7fc770efafa0>,\n",
       " 2292: <datasketch.minhash.MinHash at 0x7fc770ec3070>,\n",
       " 2294: <datasketch.minhash.MinHash at 0x7fc770ec30d0>,\n",
       " 2296: <datasketch.minhash.MinHash at 0x7fc770ec3160>,\n",
       " 2301: <datasketch.minhash.MinHash at 0x7fc770ecc700>,\n",
       " 2304: <datasketch.minhash.MinHash at 0x7fc770ec3190>,\n",
       " 2306: <datasketch.minhash.MinHash at 0x7fc770ec31c0>,\n",
       " 2312: <datasketch.minhash.MinHash at 0x7fc770ec32b0>,\n",
       " 2313: <datasketch.minhash.MinHash at 0x7fc770ec3310>,\n",
       " 2320: <datasketch.minhash.MinHash at 0x7fc770ec3370>,\n",
       " 2322: <datasketch.minhash.MinHash at 0x7fc770ec33d0>,\n",
       " 2323: <datasketch.minhash.MinHash at 0x7fc770ec3430>,\n",
       " 2326: <datasketch.minhash.MinHash at 0x7fc770ec3490>,\n",
       " 2329: <datasketch.minhash.MinHash at 0x7fc770ec34f0>,\n",
       " 2331: <datasketch.minhash.MinHash at 0x7fc770ec3550>,\n",
       " 2335: <datasketch.minhash.MinHash at 0x7fc770ec35b0>,\n",
       " 2336: <datasketch.minhash.MinHash at 0x7fc770ec3610>,\n",
       " 2337: <datasketch.minhash.MinHash at 0x7fc770ec3670>,\n",
       " 2339: <datasketch.minhash.MinHash at 0x7fc770ec36d0>,\n",
       " 2341: <datasketch.minhash.MinHash at 0x7fc770ec3730>,\n",
       " 2343: <datasketch.minhash.MinHash at 0x7fc770ec3790>,\n",
       " 2344: <datasketch.minhash.MinHash at 0x7fc770ec37f0>,\n",
       " 2346: <datasketch.minhash.MinHash at 0x7fc770ec3850>,\n",
       " 2349: <datasketch.minhash.MinHash at 0x7fc770ec38b0>,\n",
       " 2354: <datasketch.minhash.MinHash at 0x7fc770ec3910>,\n",
       " 2355: <datasketch.minhash.MinHash at 0x7fc770ec3970>,\n",
       " 2357: <datasketch.minhash.MinHash at 0x7fc770ec39d0>,\n",
       " 2358: <datasketch.minhash.MinHash at 0x7fc770ec3a00>,\n",
       " 2363: <datasketch.minhash.MinHash at 0x7fc770ec3a60>,\n",
       " 2364: <datasketch.minhash.MinHash at 0x7fc770ec3af0>,\n",
       " 2366: <datasketch.minhash.MinHash at 0x7fc770ec3b20>,\n",
       " 2369: <datasketch.minhash.MinHash at 0x7fc770ec3bb0>,\n",
       " 2371: <datasketch.minhash.MinHash at 0x7fc770ec3c10>,\n",
       " 2374: <datasketch.minhash.MinHash at 0x7fc770ec3c70>,\n",
       " 2375: <datasketch.minhash.MinHash at 0x7fc770ec3cd0>,\n",
       " 2384: <datasketch.minhash.MinHash at 0x7fc770ec3d30>,\n",
       " 2386: <datasketch.minhash.MinHash at 0x7fc770ec3d90>,\n",
       " 2391: <datasketch.minhash.MinHash at 0x7fc770ec3df0>,\n",
       " 2392: <datasketch.minhash.MinHash at 0x7fc770ec3e50>,\n",
       " 2393: <datasketch.minhash.MinHash at 0x7fc770ec3eb0>,\n",
       " 2396: <datasketch.minhash.MinHash at 0x7fc770ec3f10>,\n",
       " 2397: <datasketch.minhash.MinHash at 0x7fc770ec3f70>,\n",
       " 2398: <datasketch.minhash.MinHash at 0x7fc770ec3fd0>,\n",
       " 2403: <datasketch.minhash.MinHash at 0x7fc770ec3fa0>,\n",
       " 2404: <datasketch.minhash.MinHash at 0x7fc770ece0a0>,\n",
       " 2405: <datasketch.minhash.MinHash at 0x7fc770ece130>,\n",
       " 2409: <datasketch.minhash.MinHash at 0x7fc770ece190>,\n",
       " 2410: <datasketch.minhash.MinHash at 0x7fc770ece250>,\n",
       " 2428: <datasketch.minhash.MinHash at 0x7fc770ece220>,\n",
       " 2429: <datasketch.minhash.MinHash at 0x7fc770ece2b0>,\n",
       " 2433: <datasketch.minhash.MinHash at 0x7fc770ece310>,\n",
       " 2434: <datasketch.minhash.MinHash at 0x7fc770ece370>,\n",
       " 2437: <datasketch.minhash.MinHash at 0x7fc770ece430>,\n",
       " 2439: <datasketch.minhash.MinHash at 0x7fc770ece400>,\n",
       " 2440: <datasketch.minhash.MinHash at 0x7fc770ece4f0>,\n",
       " 2443: <datasketch.minhash.MinHash at 0x7fc770ece4c0>,\n",
       " 2444: <datasketch.minhash.MinHash at 0x7fc770ece550>,\n",
       " 2447: <datasketch.minhash.MinHash at 0x7fc770ece580>,\n",
       " 2455: <datasketch.minhash.MinHash at 0x7fc770ece670>,\n",
       " 2458: <datasketch.minhash.MinHash at 0x7fc770ece640>,\n",
       " 2463: <datasketch.minhash.MinHash at 0x7fc770ece730>,\n",
       " 2464: <datasketch.minhash.MinHash at 0x7fc770ece700>,\n",
       " 2466: <datasketch.minhash.MinHash at 0x7fc770ece7f0>,\n",
       " 2467: <datasketch.minhash.MinHash at 0x7fc770ece7c0>,\n",
       " 2473: <datasketch.minhash.MinHash at 0x7fc770ece850>,\n",
       " 2475: <datasketch.minhash.MinHash at 0x7fc770ece8b0>,\n",
       " 2479: <datasketch.minhash.MinHash at 0x7fc770ece910>,\n",
       " 2483: <datasketch.minhash.MinHash at 0x7fc770ece970>,\n",
       " 2484: <datasketch.minhash.MinHash at 0x7fc770ece9d0>,\n",
       " 2488: <datasketch.minhash.MinHash at 0x7fc770ecea30>,\n",
       " 2489: <datasketch.minhash.MinHash at 0x7fc770ecea90>,\n",
       " 2494: <datasketch.minhash.MinHash at 0x7fc770eceaf0>,\n",
       " 2495: <datasketch.minhash.MinHash at 0x7fc770eceb50>,\n",
       " 2496: <datasketch.minhash.MinHash at 0x7fc770ecebb0>,\n",
       " 2497: <datasketch.minhash.MinHash at 0x7fc770ecec70>,\n",
       " 2499: <datasketch.minhash.MinHash at 0x7fc770ecec40>,\n",
       " 2501: <datasketch.minhash.MinHash at 0x7fc770ececd0>,\n",
       " 2502: <datasketch.minhash.MinHash at 0x7fc770eced30>,\n",
       " 2506: <datasketch.minhash.MinHash at 0x7fc770eced90>,\n",
       " 2513: <datasketch.minhash.MinHash at 0x7fc770ecedf0>,\n",
       " 2517: <datasketch.minhash.MinHash at 0x7fc770ecee50>,\n",
       " 2521: <datasketch.minhash.MinHash at 0x7fc770eceeb0>,\n",
       " 2522: <datasketch.minhash.MinHash at 0x7fc770ecef70>,\n",
       " 2525: <datasketch.minhash.MinHash at 0x7fc770ecefd0>,\n",
       " 2526: <datasketch.minhash.MinHash at 0x7fc770ecefa0>,\n",
       " 2530: <datasketch.minhash.MinHash at 0x7fc770ecef40>,\n",
       " 2531: <datasketch.minhash.MinHash at 0x7fc710e530a0>,\n",
       " 2532: <datasketch.minhash.MinHash at 0x7fc710e53100>,\n",
       " 2535: <datasketch.minhash.MinHash at 0x7fc710e53190>,\n",
       " 2536: <datasketch.minhash.MinHash at 0x7fc710e531f0>,\n",
       " 2537: <datasketch.minhash.MinHash at 0x7fc710e53250>,\n",
       " 2539: <datasketch.minhash.MinHash at 0x7fc710e532b0>,\n",
       " 2540: <datasketch.minhash.MinHash at 0x7fc710e53370>,\n",
       " 2542: <datasketch.minhash.MinHash at 0x7fc710e53340>,\n",
       " 2545: <datasketch.minhash.MinHash at 0x7fc710e533d0>,\n",
       " 2549: <datasketch.minhash.MinHash at 0x7fc710e53430>,\n",
       " 2552: <datasketch.minhash.MinHash at 0x7fc710e53490>,\n",
       " 2554: <datasketch.minhash.MinHash at 0x7fc710e534f0>,\n",
       " 2556: <datasketch.minhash.MinHash at 0x7fc710e53550>,\n",
       " ...}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final_buckets #\n",
    "minhashes  #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_averege_jaccard_sim(final_buckets, minhashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexer = StringIndexer(inputCol=\"features\", outputCol=\"from_to_type_index\")\n",
    "# indexed_data = indexer.fit(actual_routes_feature).transform(actual_routes_feature)\n",
    "# assembler = VectorAssembler(inputCols=[\"from_to_type_index\"], outputCol=\"vector\")\n",
    "# actual_feature_data = assembler.transform(indexed_data)\n",
    "\n",
    "# actual_feature_data.show()\n",
    "# # def is_non_zero_vector(vector):\n",
    "# #     return vector.numNonzeros() > 0\n",
    "\n",
    "# # is_non_zero_vector_udf = udf(is_non_zero_vector, BooleanType())\n",
    "\n",
    "# # filtered_data = actual_feature_data.filter(is_non_zero_vector_udf(col(\"vector\")))\n",
    "\n",
    "\n",
    "# mh = MinHashLSH(inputCol=\"vector\", outputCol=\"hashes\", numHashTables=5, seed=1003)\n",
    "# model = mh.fit(actual_feature_data)\n",
    "\n",
    "# #transformed_filtered_data = model.transform(actual_feature_data).head()\n",
    "# test = model.approxNearestNeighbors()\n",
    "\n",
    "# # transformed_filtered_data.show(truncate=False, n=50)\n",
    "\n",
    "\n",
    "# #similar_items.show(truncate=False)\n",
    "\n",
    "# def is_non_zero_vector(vector):\n",
    "#     return vector.numNonzeros() > 0\n",
    "\n",
    "# from collections import defaultdict\n",
    "\n",
    "# representative_mapping = {}\n",
    "\n",
    "# group_mapping = defaultdict(list)\n",
    "\n",
    "# # Iterate over the user neighbors dictionary\n",
    "# for user, neighbors in new_process_dictionary.items():\n",
    "#     neighbors_sorted = tuple(sorted(neighbors))\n",
    "#     if neighbors_sorted in representative_mapping:\n",
    "#         representative = representative_mapping[neighbors_sorted]\n",
    "#     else:\n",
    "#         representative = neighbors_sorted[0]\n",
    "#         for neighbor in neighbors_sorted:\n",
    "#             representative_mapping[neighbor] = representative\n",
    "    \n",
    "#     representative_mapping[user] = representative\n",
    "#     group_mapping[representative].append(user)\n",
    "\n",
    "# new_user_neighbors = {}\n",
    "# for representative, users in group_mapping.items():\n",
    "#     new_user_neighbors[representative] = users\n",
    "\n",
    "# #print(new_user_neighbors)\n",
    "# new_users = []\n",
    "# for key, value in new_user_neighbors.items():\n",
    "#     new_users.append(key)\n",
    "\n",
    "# print(len(new_users))\n",
    "# filtered_df = df_grouped[df_grouped['user_id'].isin(new_users)]\n",
    "# print(f\"Amount of processes: {filtered_df.count()}\")\n",
    "#     shingles = shingle(features[\"features\"], 5)\n",
    "#     m = MinHash(num_perm=128)\n",
    "#     for shingle_item in shingles:\n",
    "#         m.update(shingle_item.encode(\"utf8\"))\n",
    "#     minhashes[int(features[\"user_id\"])] = m\n",
    "#     lsh.insert(int(features[\"user_id\"]), m)\n",
    "#     neigbours = lsh.query(m)\n",
    "#     print(features[\"user_id\"], neigbours)\n",
    "#     final_buckets[features[\"user_id\"]] = neigbours\n",
    "\n",
    "# print(final_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
