{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_case(tasks, case_id, start_time):\n",
    "    case = []\n",
    "    time = start_time\n",
    "    case.append(['null','S0',time,'Req',case_id])\n",
    "    \n",
    "    for task,subtasks in tasks.items():\n",
    "        server = f\"S{list(tasks.keys()).index(task)+1}\" #SX\n",
    "        case.append(['S0',server,time,'Req',case_id])\n",
    "        if subtasks[0]=='one':\n",
    "            #print('one')\n",
    "            service_task = random.choice(subtasks[1])\n",
    "            #print(service_task)\n",
    "            new_server = f\"{server}_{subtasks[1].index(service_task)+1}\"\n",
    "            case.append([server, new_server,time,'Req',case_id])\n",
    "            #Response\n",
    "            time += timedelta(microseconds=subtasks[-1]*1000)\n",
    "            case.append([new_server,server,time,'Res',case_id]) #1 milisecond= 1000 microseconds\n",
    "            #Request\n",
    "            \n",
    "\n",
    "        elif subtasks[0] == 'rand':\n",
    "            #print('rand')\n",
    "            rand_tasks = random.sample(subtasks[1], random.randint(1, len(subtasks[1])))\n",
    "            for new_task in rand_tasks:\n",
    "                #print(new_task)\n",
    "                new_server = f\"{server}_{subtasks[1].index(new_task)+1}\"\n",
    "                #Request\n",
    "                case.append([server, new_server,time,'Req',case_id])\n",
    "                #Response\n",
    "                time += timedelta(microseconds=subtasks[-1]*1000)\n",
    "                case.append([new_server,server,time,'Res',case_id]) #1 milisecond= 1000 microseconds\n",
    "            #print(rand_tasks)\n",
    "            #print('#####')\n",
    "\n",
    "        elif subtasks[0] == 'all':\n",
    "            #print('all')\n",
    "            for new_task in subtasks[1]:\n",
    "                #print(new_task)\n",
    "                new_server = f\"{server}_{subtasks[1].index(new_task)+1}\"\n",
    "                #Request\n",
    "                case.append([server, new_server,time,'Req',case_id])\n",
    "                #Response\n",
    "                time += timedelta(microseconds=subtasks[-1]*1000)\n",
    "                case.append([new_server,server,time,'Res',case_id]) #1 milisecond= 1000 microseconds\n",
    "            #print('#####')\n",
    "\n",
    "        else:\n",
    "            print('smth wrong')\n",
    "            #raise Error\n",
    "        #print(subtask)\n",
    "        \n",
    "        case.append([server,'S0',time,'Res',case_id])\n",
    "    case.append(['S0','null',time,'Res',case_id])\n",
    "    return case\n",
    "\n",
    "#print(generate_case(tasks, user_id, start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random times\n",
    "def random_time(start_time,end_time):\n",
    "    delta = end_time - start_time\n",
    "    return start_time + timedelta(seconds=random.randint(0, int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_book_dataset(tasks, min_datapoints,start_time,end_time):\n",
    "    datapoints = 0\n",
    "    dataset = []\n",
    "    user_id = 1\n",
    "    while datapoints <= min_datapoints:\n",
    "        time = random_time(start_time,end_time)\n",
    "        case = generate_case(tasks, user_id, time)\n",
    "        dataset.extend(case)\n",
    "        datapoints+= len(case)\n",
    "        user_id+=1\n",
    "    \n",
    "    df = pd.DataFrame(dataset, columns=['from', 'to', 'timestamp', 'type', 'user_id'])\n",
    "\n",
    "    # Save to Excel (XLSX)\n",
    "    df.to_csv('./SGD_books.csv', index=False)  # Save to XLSX instead of CSV\n",
    "    #df.to_csv('./SGD_transfers.csv', index=False)  # Save to XLSX instead of CSV\n",
    "\n",
    "    # Display sample of the dataset\n",
    "    print(df.head())\n",
    "\n",
    "tasks = {'log_in': ['one',['credentials check','sing up','recover pw and log in'],3],\n",
    "            'search_book': ['rand',['history','fantasy','crime','poetry','biography'],5],\n",
    "            'shipment' : ['all',['adress','door number','zip code'],2],\n",
    "            'payment' : ['one',['visa','master card','revolut','paypal','apple pay'],10]\n",
    "}  \n",
    "\n",
    "start_time = datetime(2024, 4, 22, 9, 0, 0)  #begining of the course April 27, 2024, 08:00:00\n",
    "end_time = datetime(2024, 6, 18, 15, 0, 0) #day of the exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transfers_dataset(tasks, min_datapoints,start_time,end_time):\n",
    "    datapoints = 0\n",
    "    dataset = []\n",
    "    user_id = 1\n",
    "    while datapoints <= min_datapoints:\n",
    "        time = random_time(start_time,end_time)\n",
    "        case = generate_case(tasks, user_id, time)\n",
    "        dataset.extend(case)\n",
    "        datapoints+= len(case)\n",
    "        user_id+=1\n",
    "    \n",
    "    df = pd.DataFrame(dataset, columns=['from', 'to', 'timestamp', 'type', 'user_id'])\n",
    "\n",
    "    # Save to Excel (XLSX)\n",
    "    df.to_csv('./SGD_books.csv', index=False)  # Save to XLSX instead of CSV\n",
    "    #df.to_csv('./SGD_transfers.csv', index=False)  # Save to XLSX instead of CSV\n",
    "\n",
    "    # Display sample of the dataset\n",
    "    print(df.head())\n",
    "\n",
    "tasks = {\n",
    "    'log_in': ['one', ['credentials_check', 'sign_up', 'recover_password_ad_log_in'],3],\n",
    "    'initiate_transfer': ['all', ['enter_account_details', 'enter_amount', 'enter_recipient_details'],3],\n",
    "    'complete_transfer': ['one', ['Visa', 'Master_card', 'Revolut', 'Paypal'],4],\n",
    "    'verify_transfer': ['rand', ['sms_verification', 'email_verification', '2Fauthenticator_verification'],3]\n",
    "}\n",
    "\n",
    "start_time = datetime(2024, 4, 22, 9, 0, 0)  #begining of the course April 27, 2024, 08:00:00\n",
    "end_time = datetime(2024, 6, 18, 15, 0, 0) #day of the exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   from    to               timestamp type  user_id\n",
      "0  null    S0 2024-05-10 10:55:38.000  Req        1\n",
      "1    S0    S1 2024-05-10 10:55:38.000  Req        1\n",
      "2    S1  S1_2 2024-05-10 10:55:38.000  Req        1\n",
      "3  S1_2    S1 2024-05-10 10:55:38.003  Res        1\n",
      "4    S1    S0 2024-05-10 10:55:38.003  Res        1\n"
     ]
    }
   ],
   "source": [
    "generate_book_dataset(tasks, 1000000,start_time,end_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   from    to               timestamp type  user_id\n",
      "0  null    S0 2024-06-08 03:49:11.000  Req        1\n",
      "1    S0    S1 2024-06-08 03:49:11.000  Req        1\n",
      "2    S1  S1_1 2024-06-08 03:49:11.000  Req        1\n",
      "3  S1_1    S1 2024-06-08 03:49:11.003  Res        1\n",
      "4    S1    S0 2024-06-08 03:49:11.003  Res        1\n"
     ]
    }
   ],
   "source": [
    "generate_transfers_dataset(tasks, 1000000,start_time,end_time)  \n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m process\u001b[38;5;241m.\u001b[39miterrows())\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Step 2: Extract unique process cases\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m cases \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: process_to_set(x))\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Step 3: Compute Jaccard distance matrix\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjaccard_distance\u001b[39m(set1, set2):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
